{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Major Group Assignment: Comprehensive Business Intelligence EDA Project\n",
    "\n",
    "**Due Date:** Thursday, May 22, 2025  \n",
    "**Points:** 100 points  \n",
    "**Group Assignment:** Teams of 3-4 students  \n",
    "**Submission:** Upload completed notebook to course platform\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "As a data analysis consulting team, you've been hired by Olist's executive leadership to conduct a comprehensive business intelligence analysis. Your goal is to provide strategic insights that will guide key business decisions for the next quarter.\n",
    "\n",
    "## Business Context\n",
    "\n",
    "Olist connects small businesses to major marketplaces in Brazil. The company needs to understand:\n",
    "- Which customer segments drive the most value\n",
    "- How product categories perform across different regions\n",
    "- What seasonal patterns exist in their business\n",
    "- Where operational improvements can increase customer satisfaction\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Your analysis must integrate three major components:\n",
    "1. **Customer Intelligence** (35 points)\n",
    "2. **Product & Market Analysis** (35 points)\n",
    "3. **Time Series & Forecasting** (20 points)\n",
    "4. **Strategic Recommendations** (10 points)\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. **Executive Summary** (300-500 words)\n",
    "2. **Technical Analysis** (Code + Visualizations)\n",
    "3. **Strategic Recommendations** (Bullet points with supporting data)\n",
    "4. **Appendix** (Additional charts and technical details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Connection\n",
    "\n",
    "**Security Note:** Always use environment variables for database credentials. Never hardcode sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connection\n",
    "import psycopg2\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Time series\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up secure database connection using environment variables\n",
    "# IMPORTANT: Never hardcode credentials in your notebooks!\n",
    "\n",
    "# Set environment variables if not already set (for Colab)\n",
    "if 'SUPABASE_DB_HOST' not in os.environ:\n",
    "    # Ask your instructor for these credentials\n",
    "    os.environ['SUPABASE_DB_HOST'] = 'your-host-here'\n",
    "    os.environ['SUPABASE_DB_NAME'] = 'your-database-name'\n",
    "    os.environ['SUPABASE_DB_USER'] = 'your-username'\n",
    "    os.environ['SUPABASE_DB_PASSWORD'] = 'your-password'\n",
    "    os.environ['SUPABASE_DB_PORT'] = '5432'\n",
    "\n",
    "# Create database connection\n",
    "DATABASE_URL = f\"postgresql://{os.environ['SUPABASE_DB_USER']}:{os.environ['SUPABASE_DB_PASSWORD']}@{os.environ['SUPABASE_DB_HOST']}:{os.environ['SUPABASE_DB_PORT']}/{os.environ['SUPABASE_DB_NAME']}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "print(\"âœ… Database connection established successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Intelligence Analysis (35 points)\n",
    "\n",
    "### 1.1 RFM Analysis and Customer Segmentation (15 points)\n",
    "\n",
    "Perform a comprehensive RFM (Recency, Frequency, Monetary) analysis to identify customer segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load customer order data with payments and calculate RFM metrics\n",
    "# Hint: Join orders, order_items, order_payments, and customers tables\n",
    "\n",
    "customer_rfm_query = \"\"\"\n",
    "-- TODO: Write SQL query to calculate RFM metrics for each customer\n",
    "-- Requirements:\n",
    "-- 1. Recency: Days since last purchase (use '2018-10-17' as analysis date)\n",
    "-- 2. Frequency: Total number of orders per customer\n",
    "-- 3. Monetary: Total amount spent per customer\n",
    "-- 4. Include customer_state for geographic insights\n",
    "-- 5. Only include delivered orders\n",
    "\"\"\"\n",
    "\n",
    "# rfm_data = pd.read_sql_query(customer_rfm_query, engine)\n",
    "# print(f\"Loaded {len(rfm_data):,} customers for RFM analysis\")\n",
    "# rfm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create RFM scores (1-5 quintiles) and customer segments\n",
    "# Hint: Use pd.qcut() for scoring, then create segment labels\n",
    "\n",
    "# Calculate RFM scores\n",
    "# rfm_data['R_Score'] = pd.qcut(rfm_data['Recency'], 5, labels=[5,4,3,2,1])  # Lower recency = higher score\n",
    "# rfm_data['F_Score'] = pd.qcut(rfm_data['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "# rfm_data['M_Score'] = pd.qcut(rfm_data['Monetary'], 5, labels=[1,2,3,4,5])\n",
    "\n",
    "# Create segment labels\n",
    "# def get_rfm_segment(row):\n",
    "#     if row['R_Score'] >= 4 and row['F_Score'] >= 4 and row['M_Score'] >= 4:\n",
    "#         return 'Champions'\n",
    "#     elif row['R_Score'] >= 3 and row['F_Score'] >= 3 and row['M_Score'] >= 3:\n",
    "#         return 'Loyal Customers'\n",
    "#     # TODO: Add more segment logic\n",
    "#     else:\n",
    "#         return 'Others'\n",
    "\n",
    "# rfm_data['Segment'] = rfm_data.apply(get_rfm_segment, axis=1)\n",
    "# print(\"\\nCustomer Segments:\")\n",
    "# print(rfm_data['Segment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create comprehensive visualizations of RFM analysis\n",
    "# Requirements:\n",
    "# 1. RFM distribution plots\n",
    "# 2. Customer segment analysis\n",
    "# 3. Geographic distribution of segments\n",
    "# 4. Segment performance metrics\n",
    "\n",
    "# Create subplot layout\n",
    "# fig = make_subplots(\n",
    "#     rows=2, cols=2,\n",
    "#     subplot_titles=['RFM Distributions', 'Customer Segments', 'Geographic Analysis', 'Segment Performance'],\n",
    "#     specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "#            [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "# )\n",
    "\n",
    "# TODO: Add your visualization code here\n",
    "\n",
    "print(\"ðŸ“Š RFM Analysis Visualization\")\n",
    "print(\"TODO: Create comprehensive RFM visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Advanced Customer Clustering (10 points)\n",
    "\n",
    "Apply machine learning clustering to identify customer behavioral patterns beyond RFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extend customer analysis with additional behavioral metrics\n",
    "# Requirements:\n",
    "# 1. Average order value\n",
    "# 2. Purchase frequency patterns\n",
    "# 3. Product category preferences\n",
    "# 4. Time between orders\n",
    "# 5. Customer lifetime value\n",
    "\n",
    "advanced_customer_query = \"\"\"\n",
    "-- TODO: Create query with advanced customer behavioral metrics\n",
    "-- Include product category diversity, payment preferences, etc.\n",
    "\"\"\"\n",
    "\n",
    "# advanced_customer_data = pd.read_sql_query(advanced_customer_query, engine)\n",
    "print(\"TODO: Load advanced customer behavioral data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply K-means clustering with optimal cluster selection\n",
    "# Requirements:\n",
    "# 1. Use elbow method to determine optimal clusters\n",
    "# 2. Standardize features before clustering\n",
    "# 3. Apply PCA for dimensionality reduction\n",
    "# 4. Interpret cluster characteristics\n",
    "\n",
    "# Example structure:\n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features)\n",
    "# \n",
    "# # Elbow method\n",
    "# inertias = []\n",
    "# for k in range(2, 11):\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "#     kmeans.fit(features_scaled)\n",
    "#     inertias.append(kmeans.inertia_)\n",
    "\n",
    "print(\"TODO: Implement advanced customer clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Customer Lifetime Value Analysis (10 points)\n",
    "\n",
    "Calculate and analyze customer lifetime value across different segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate Customer Lifetime Value (CLV)\n",
    "# Requirements:\n",
    "# 1. Historical CLV calculation\n",
    "# 2. Predictive CLV modeling\n",
    "# 3. CLV by customer segment\n",
    "# 4. Geographic CLV analysis\n",
    "# 5. Retention rate analysis\n",
    "\n",
    "clv_query = \"\"\"\n",
    "-- TODO: Create query to calculate CLV components\n",
    "-- Include customer acquisition dates, order history, churn indicators\n",
    "\"\"\"\n",
    "\n",
    "print(\"TODO: Implement CLV analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Product & Market Analysis (35 points)\n",
    "\n",
    "### 2.1 Product Portfolio Analysis (15 points)\n",
    "\n",
    "Analyze product performance using portfolio management frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load product performance data\n",
    "# Requirements:\n",
    "# 1. Revenue by product category\n",
    "# 2. Growth rates\n",
    "# 3. Market share analysis\n",
    "# 4. Profitability metrics\n",
    "# 5. Customer satisfaction by category\n",
    "\n",
    "product_portfolio_query = \"\"\"\n",
    "-- TODO: Create comprehensive product performance query\n",
    "-- Include revenue, growth, market share, satisfaction metrics\n",
    "\"\"\"\n",
    "\n",
    "# product_data = pd.read_sql_query(product_portfolio_query, engine)\n",
    "print(\"TODO: Load product portfolio data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create BCG-style portfolio matrix\n",
    "# Requirements:\n",
    "# 1. Market growth vs market share analysis\n",
    "# 2. Classify products as Stars, Cash Cows, Question Marks, Dogs\n",
    "# 3. Revenue bubble chart visualization\n",
    "# 4. Strategic recommendations for each quadrant\n",
    "\n",
    "# Example BCG matrix structure:\n",
    "# fig = px.scatter(product_data, \n",
    "#                  x='market_share', \n",
    "#                  y='growth_rate',\n",
    "#                  size='revenue',\n",
    "#                  color='bcg_category',\n",
    "#                  hover_data=['product_category'],\n",
    "#                  title='Product Portfolio Matrix (BCG Style)')\n",
    "\n",
    "print(\"TODO: Create BCG portfolio matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Market Basket Analysis (10 points)\n",
    "\n",
    "Identify product associations and cross-selling opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement market basket analysis\n",
    "# Requirements:\n",
    "# 1. Calculate support, confidence, and lift for product associations\n",
    "# 2. Identify frequently bought together products\n",
    "# 3. Network analysis of product relationships\n",
    "# 4. Cross-selling recommendations\n",
    "\n",
    "# Market basket query\n",
    "basket_query = \"\"\"\n",
    "-- TODO: Create query to identify products bought together\n",
    "-- Group by order_id and collect product categories\n",
    "\"\"\"\n",
    "\n",
    "print(\"TODO: Implement market basket analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Geographic Market Analysis (10 points)\n",
    "\n",
    "Analyze product performance across different regions and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Geographic product performance analysis\n",
    "# Requirements:\n",
    "# 1. Revenue by state and region\n",
    "# 2. Product category preferences by geography\n",
    "# 3. Market penetration analysis\n",
    "# 4. Logistics and delivery performance\n",
    "# 5. Regional growth opportunities\n",
    "\n",
    "geographic_query = \"\"\"\n",
    "-- TODO: Create geographic analysis query\n",
    "-- Include state-level performance, delivery metrics\n",
    "\"\"\"\n",
    "\n",
    "print(\"TODO: Implement geographic market analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Time Series & Forecasting Analysis (20 points)\n",
    "\n",
    "### 3.1 Seasonal Pattern Analysis (10 points)\n",
    "\n",
    "Identify and analyze seasonal patterns in sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Time series analysis of sales patterns\n",
    "# Requirements:\n",
    "# 1. Daily, weekly, monthly sales trends\n",
    "# 2. Seasonal decomposition\n",
    "# 3. Holiday and special event analysis\n",
    "# 4. Category-specific seasonality\n",
    "# 5. Regional seasonal differences\n",
    "\n",
    "time_series_query = \"\"\"\n",
    "-- TODO: Create time series query\n",
    "-- Include daily sales, product categories, regions\n",
    "\"\"\"\n",
    "\n",
    "# time_series_data = pd.read_sql_query(time_series_query, engine)\n",
    "print(\"TODO: Load time series data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Seasonal decomposition analysis\n",
    "# Requirements:\n",
    "# 1. Trend, seasonal, and residual components\n",
    "# 2. Multiple seasonality detection (weekly, monthly, yearly)\n",
    "# 3. Seasonal strength metrics\n",
    "# 4. Anomaly detection in seasonal patterns\n",
    "\n",
    "# Example seasonal decomposition:\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# decomposition = seasonal_decompose(time_series_data['sales'], period=30)\n",
    "\n",
    "print(\"TODO: Implement seasonal decomposition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Forecasting and Business Planning (10 points)\n",
    "\n",
    "Create forecasts for business planning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement forecasting models\n",
    "# Requirements:\n",
    "# 1. Multiple forecasting approaches (moving average, exponential smoothing, ARIMA)\n",
    "# 2. Forecast accuracy metrics\n",
    "# 3. Confidence intervals\n",
    "# 4. Scenario planning (best/worst/most likely)\n",
    "# 5. Business impact projections\n",
    "\n",
    "# Example forecasting structure:\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "print(\"TODO: Implement forecasting models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Strategic Recommendations (10 points)\n",
    "\n",
    "### 4.1 Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Write your executive summary here (300-500 words)**\n",
    "\n",
    "Your executive summary should include:\n",
    "- Key findings from customer intelligence analysis\n",
    "- Critical insights from product/market analysis\n",
    "- Important patterns from time series analysis\n",
    "- Top 3 strategic recommendations\n",
    "- Expected business impact\n",
    "\n",
    "*Replace this text with your executive summary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Strategic Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Provide specific, actionable recommendations based on your analysis**\n",
    "\n",
    "#### Customer Strategy\n",
    "- **Recommendation 1:** [Based on RFM/clustering analysis]\n",
    "- **Supporting Data:** [Specific metrics and visualizations]\n",
    "- **Expected Impact:** [Quantified business impact]\n",
    "\n",
    "#### Product Strategy\n",
    "- **Recommendation 2:** [Based on portfolio/market analysis]\n",
    "- **Supporting Data:** [Specific metrics and visualizations]\n",
    "- **Expected Impact:** [Quantified business impact]\n",
    "\n",
    "#### Operational Strategy\n",
    "- **Recommendation 3:** [Based on time series/forecasting]\n",
    "- **Supporting Data:** [Specific metrics and visualizations]\n",
    "- **Expected Impact:** [Quantified business impact]\n",
    "\n",
    "*Replace this template with your specific recommendations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Implementation Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Create a timeline for implementing your recommendations**\n",
    "\n",
    "#### Phase 1 (Immediate - 0-3 months)\n",
    "- [ ] Action item 1\n",
    "- [ ] Action item 2\n",
    "- [ ] Action item 3\n",
    "\n",
    "#### Phase 2 (Short-term - 3-6 months)\n",
    "- [ ] Action item 1\n",
    "- [ ] Action item 2\n",
    "- [ ] Action item 3\n",
    "\n",
    "#### Phase 3 (Medium-term - 6-12 months)\n",
    "- [ ] Action item 1\n",
    "- [ ] Action item 2\n",
    "- [ ] Action item 3\n",
    "\n",
    "*Replace this template with your implementation roadmap*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Additional Analysis\n",
    "\n",
    "### A.1 Detailed Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Include additional statistical tests and analysis\n",
    "# Examples:\n",
    "# - Correlation analysis between key metrics\n",
    "# - Statistical significance tests\n",
    "# - Confidence intervals for key estimates\n",
    "# - Sensitivity analysis\n",
    "\n",
    "print(\"TODO: Add detailed statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Technical Implementation Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Document your technical approach and methodology\n",
    "# Include:\n",
    "# - Data quality checks performed\n",
    "# - Assumptions made in analysis\n",
    "# - Limitations of the analysis\n",
    "# - Validation steps taken\n",
    "\n",
    "print(\"TODO: Document technical implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Rubric (100 points total)\n",
    "\n",
    "### Customer Intelligence Analysis (35 points)\n",
    "- **RFM Analysis & Segmentation (15 points)**\n",
    "  - Excellent (13-15): Comprehensive RFM with clear segmentation and actionable insights\n",
    "  - Good (10-12): Solid RFM analysis with adequate segmentation\n",
    "  - Satisfactory (7-9): Basic RFM analysis with some segmentation issues\n",
    "  - Needs Improvement (0-6): Incomplete or incorrect RFM analysis\n",
    "\n",
    "- **Advanced Clustering (10 points)**\n",
    "  - Excellent (9-10): Sophisticated clustering with optimal selection and interpretation\n",
    "  - Good (7-8): Good clustering approach with reasonable interpretation\n",
    "  - Satisfactory (5-6): Basic clustering with limited interpretation\n",
    "  - Needs Improvement (0-4): Poor or missing clustering analysis\n",
    "\n",
    "- **CLV Analysis (10 points)**\n",
    "  - Excellent (9-10): Comprehensive CLV with predictive modeling and strategic insights\n",
    "  - Good (7-8): Solid CLV calculation with good analysis\n",
    "  - Satisfactory (5-6): Basic CLV calculation with limited insights\n",
    "  - Needs Improvement (0-4): Incomplete or incorrect CLV analysis\n",
    "\n",
    "### Product & Market Analysis (35 points)\n",
    "- **Portfolio Analysis (15 points)**\n",
    "  - Excellent (13-15): Sophisticated portfolio analysis with strategic framework\n",
    "  - Good (10-12): Good portfolio analysis with clear insights\n",
    "  - Satisfactory (7-9): Basic portfolio analysis\n",
    "  - Needs Improvement (0-6): Incomplete portfolio analysis\n",
    "\n",
    "- **Market Basket Analysis (10 points)**\n",
    "  - Excellent (9-10): Comprehensive association analysis with actionable recommendations\n",
    "  - Good (7-8): Good market basket analysis with insights\n",
    "  - Satisfactory (5-6): Basic association analysis\n",
    "  - Needs Improvement (0-4): Poor or missing market basket analysis\n",
    "\n",
    "- **Geographic Analysis (10 points)**\n",
    "  - Excellent (9-10): Thorough geographic analysis with regional insights\n",
    "  - Good (7-8): Good geographic analysis\n",
    "  - Satisfactory (5-6): Basic geographic analysis\n",
    "  - Needs Improvement (0-4): Incomplete geographic analysis\n",
    "\n",
    "### Time Series & Forecasting (20 points)\n",
    "- **Seasonal Analysis (10 points)**\n",
    "  - Excellent (9-10): Comprehensive seasonal decomposition with business insights\n",
    "  - Good (7-8): Good seasonal analysis\n",
    "  - Satisfactory (5-6): Basic seasonal patterns identified\n",
    "  - Needs Improvement (0-4): Poor seasonal analysis\n",
    "\n",
    "- **Forecasting (10 points)**\n",
    "  - Excellent (9-10): Multiple forecasting methods with accuracy assessment\n",
    "  - Good (7-8): Solid forecasting approach\n",
    "  - Satisfactory (5-6): Basic forecasting\n",
    "  - Needs Improvement (0-4): Poor or missing forecasting\n",
    "\n",
    "### Strategic Recommendations (10 points)\n",
    "- **Executive Summary & Recommendations (10 points)**\n",
    "  - Excellent (9-10): Clear, actionable recommendations with strong business justification\n",
    "  - Good (7-8): Good recommendations with adequate support\n",
    "  - Satisfactory (5-6): Basic recommendations\n",
    "  - Needs Improvement (0-4): Weak or missing recommendations\n",
    "\n",
    "### Additional Considerations\n",
    "- **Code Quality**: Clean, well-commented code with proper error handling\n",
    "- **Visualizations**: Professional, clear charts that support the analysis\n",
    "- **Business Understanding**: Demonstrates understanding of business context\n",
    "- **Team Collaboration**: Evidence of effective teamwork and contribution balance\n",
    "\n",
    "### Submission Requirements\n",
    "1. **Completed Jupyter Notebook** with all code cells executed\n",
    "2. **Team Member Contributions** document (who did what)\n",
    "3. **Presentation Slides** (10-15 slides) summarizing key findings\n",
    "4. **Data Files** (if you created any derived datasets)\n",
    "\n",
    "### Late Submission Policy\n",
    "- 10% penalty per day late\n",
    "- No submissions accepted after 3 days late\n",
    "- Contact instructor immediately if you anticipate difficulties\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your analysis! Remember to think like business consultants and provide actionable insights that Olist's leadership can implement.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}