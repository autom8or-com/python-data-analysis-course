{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9 - Part 3: Data Visualization with Streamlit\n",
    "\n",
    "**Course:** Python Data Analysis for Business Intelligence  \n",
    "**Week:** 9 | **Session:** Wednesday | **Part:** 3 of 3  \n",
    "**Duration:** 20 minutes | **Date:** June 4, 2025\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will be able to:\n",
    "- Integrate matplotlib, seaborn, and plotly with Streamlit\n",
    "- Create interactive business dashboards with real-time data\n",
    "- Connect to Supabase for live data visualization\n",
    "- Implement caching strategies for optimal performance\n",
    "- Build professional data storytelling applications\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Business Context: Real-Time Business Intelligence\n",
    "\n",
    "**Executive Challenge**: Your CEO walks into a board meeting and says:\n",
    "> \"I need to see our customer satisfaction trends, revenue performance, and operational metrics updating in real-time. Our competitors are making data-driven decisions faster than us.\"\n",
    "\n",
    "**The Traditional Problem**:\n",
    "- Static reports delivered weekly via email\n",
    "- Data analysts spending hours creating PowerPoint presentations\n",
    "- Decision-makers working with outdated information\n",
    "- No ability to drill down into specific metrics during meetings\n",
    "\n",
    "**Today's Solution**: Real-time, interactive dashboards that connect directly to your database and update automatically.\n",
    "\n",
    "**Business Impact**:\n",
    "- ⚡ Real-time decision making\n",
    "- 📊 Interactive data exploration\n",
    "- 🎯 Targeted business insights\n",
    "- 💰 Faster response to market changes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Setup: Environment and Supabase Connection\n",
    "\n",
    "Let's set up our environment with live database connectivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Visualization environment ready!\n",
      "🔗 Ready to build real-time dashboards with live data\n"
     ]
    }
   ],
   "source": [
    "# Essential imports for data visualization\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Course utilities\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"✅ Visualization environment ready!\")\n",
    "print(\"🔗 Ready to build real-time dashboards with live data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Section 1: Streamlit + Plotly Integration (8 minutes)\n",
    "\n",
    "Let's create an advanced dashboard that showcases interactive visualization capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing interactive_dashboard_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile interactive_dashboard_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Configure page for wide layout\n",
    "st.set_page_config(\n",
    "    page_title=\"Real-Time Business Dashboard\",\n",
    "    page_icon=\"📊\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Custom CSS for professional appearance\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main > div {\n",
    "        padding-top: 1rem;\n",
    "    }\n",
    "    .stMetric {\n",
    "        background: white;\n",
    "        border: 1px solid #e0e0e0;\n",
    "        padding: 1rem;\n",
    "        border-radius: 8px;\n",
    "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Generate realistic business data with time series\n",
    "@st.cache_data(ttl=300)  # Cache for 5 minutes\n",
    "def generate_realtime_data():\n",
    "    \"\"\"\n",
    "    Generate realistic time-series business data.\n",
    "    In production, this would be replaced with Supabase queries.\n",
    "    \"\"\"\n",
    "    np.random.seed(int(time.time()) % 1000)  # Semi-random for \"real-time\" feel\n",
    "    \n",
    "    # Generate 90 days of hourly data\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=90)\n",
    "    date_range = pd.date_range(start_date, end_date, freq='H')\n",
    "    \n",
    "    # Simulate realistic business patterns\n",
    "    base_orders = 50\n",
    "    seasonal_pattern = np.sin(np.arange(len(date_range)) * 2 * np.pi / (24 * 7)) * 10  # Weekly pattern\n",
    "    daily_pattern = np.sin(np.arange(len(date_range)) * 2 * np.pi / 24) * 20  # Daily pattern\n",
    "    growth_trend = np.arange(len(date_range)) * 0.01  # Growth trend\n",
    "    noise = np.random.normal(0, 5, len(date_range))\n",
    "    \n",
    "    orders = base_orders + seasonal_pattern + daily_pattern + growth_trend + noise\n",
    "    orders = np.maximum(orders, 5)  # Minimum 5 orders per hour\n",
    "    \n",
    "    # Generate correlated metrics\n",
    "    revenue = orders * np.random.normal(85, 15, len(date_range))\n",
    "    satisfaction = np.random.normal(4.2, 0.3, len(date_range))\n",
    "    satisfaction = np.clip(satisfaction, 1, 5)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': date_range,\n",
    "        'orders': orders.astype(int),\n",
    "        'revenue': revenue,\n",
    "        'satisfaction': satisfaction,\n",
    "        'customers': orders * np.random.uniform(0.7, 1.3, len(date_range)),\n",
    "        'conversion_rate': np.random.normal(3.5, 0.5, len(date_range))\n",
    "    })\n",
    "    \n",
    "    # Add categorical data\n",
    "    categories = ['Electronics', 'Fashion', 'Home & Garden', 'Books', 'Sports']\n",
    "    states = ['São Paulo', 'Rio de Janeiro', 'Minas Gerais', 'Bahia', 'Paraná']\n",
    "    \n",
    "    category_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        for cat in categories:\n",
    "            orders_cat = int(row['orders'] * np.random.uniform(0.1, 0.3))\n",
    "            if orders_cat > 0:\n",
    "                category_data.append({\n",
    "                    'timestamp': row['timestamp'],\n",
    "                    'category': cat,\n",
    "                    'orders': orders_cat,\n",
    "                    'revenue': orders_cat * np.random.uniform(70, 120)\n",
    "                })\n",
    "    \n",
    "    category_df = pd.DataFrame(category_data)\n",
    "    \n",
    "    return df, category_df\n",
    "\n",
    "# Load data\n",
    "df, category_df = generate_realtime_data()\n",
    "\n",
    "# Header with real-time update\n",
    "header_col1, header_col2 = st.columns([3, 1])\n",
    "\n",
    "with header_col1:\n",
    "    st.title(\"📊 Real-Time Business Intelligence Dashboard\")\n",
    "    st.markdown(\"**Live insights from Olist Brazilian E-commerce Platform**\")\n",
    "\n",
    "with header_col2:\n",
    "    st.markdown(f\"**🕒 Last Updated:** {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    if st.button(\"🔄 Refresh Data\"):\n",
    "        st.cache_data.clear()\n",
    "        st.rerun()\n",
    "\n",
    "# Sidebar controls\n",
    "st.sidebar.header(\"📊 Dashboard Controls\")\n",
    "\n",
    "# Time range selector\n",
    "time_range = st.sidebar.selectbox(\n",
    "    \"📅 Time Range:\",\n",
    "    ['Last 24 Hours', 'Last 7 Days', 'Last 30 Days', 'Last 90 Days'],\n",
    "    index=1\n",
    ")\n",
    "\n",
    "# Filter data based on time range\n",
    "if time_range == 'Last 24 Hours':\n",
    "    cutoff = datetime.now() - timedelta(hours=24)\n",
    "elif time_range == 'Last 7 Days':\n",
    "    cutoff = datetime.now() - timedelta(days=7)\n",
    "elif time_range == 'Last 30 Days':\n",
    "    cutoff = datetime.now() - timedelta(days=30)\n",
    "else:\n",
    "    cutoff = datetime.now() - timedelta(days=90)\n",
    "\n",
    "filtered_df = df[df['timestamp'] >= cutoff]\n",
    "filtered_category_df = category_df[category_df['timestamp'] >= cutoff]\n",
    "\n",
    "# Chart type selector\n",
    "chart_style = st.sidebar.selectbox(\n",
    "    \"📈 Chart Style:\",\n",
    "    ['Professional', 'Colorful', 'Minimal', 'Dark Theme']\n",
    ")\n",
    "\n",
    "# Set color palette based on style\n",
    "if chart_style == 'Professional':\n",
    "    color_palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "elif chart_style == 'Colorful':\n",
    "    color_palette = px.colors.qualitative.Set1\n",
    "elif chart_style == 'Minimal':\n",
    "    color_palette = ['#34495e', '#7f8c8d', '#95a5a6', '#bdc3c7', '#ecf0f1']\n",
    "else:  # Dark Theme\n",
    "    color_palette = ['#e74c3c', '#f39c12', '#f1c40f', '#2ecc71', '#3498db']\n",
    "\n",
    "# Auto-refresh toggle\n",
    "auto_refresh = st.sidebar.checkbox(\"🔄 Auto-refresh (30s)\", value=False)\n",
    "if auto_refresh:\n",
    "    time.sleep(30)\n",
    "    st.rerun()\n",
    "\n",
    "# Real-time KPIs\n",
    "st.subheader(\"⚡ Real-Time Key Performance Indicators\")\n",
    "\n",
    "kpi_col1, kpi_col2, kpi_col3, kpi_col4, kpi_col5 = st.columns(5)\n",
    "\n",
    "# Calculate current period vs previous period\n",
    "current_period = filtered_df.tail(len(filtered_df)//2)\n",
    "previous_period = filtered_df.head(len(filtered_df)//2)\n",
    "\n",
    "with kpi_col1:\n",
    "    current_orders = current_period['orders'].sum()\n",
    "    previous_orders = previous_period['orders'].sum()\n",
    "    orders_change = ((current_orders - previous_orders) / previous_orders * 100) if previous_orders > 0 else 0\n",
    "    \n",
    "    st.metric(\n",
    "        label=\"📦 Total Orders\",\n",
    "        value=f\"{current_orders:,}\",\n",
    "        delta=f\"{orders_change:+.1f}%\"\n",
    "    )\n",
    "\n",
    "with kpi_col2:\n",
    "    current_revenue = current_period['revenue'].sum()\n",
    "    previous_revenue = previous_period['revenue'].sum()\n",
    "    revenue_change = ((current_revenue - previous_revenue) / previous_revenue * 100) if previous_revenue > 0 else 0\n",
    "    \n",
    "    st.metric(\n",
    "        label=\"💰 Revenue\",\n",
    "        value=f\"R$ {current_revenue:,.0f}\",\n",
    "        delta=f\"{revenue_change:+.1f}%\"\n",
    "    )\n",
    "\n",
    "with kpi_col3:\n",
    "    current_satisfaction = current_period['satisfaction'].mean()\n",
    "    previous_satisfaction = previous_period['satisfaction'].mean()\n",
    "    satisfaction_change = current_satisfaction - previous_satisfaction\n",
    "    \n",
    "    st.metric(\n",
    "        label=\"⭐ Avg Satisfaction\",\n",
    "        value=f\"{current_satisfaction:.2f}/5.0\",\n",
    "        delta=f\"{satisfaction_change:+.2f}\"\n",
    "    )\n",
    "\n",
    "with kpi_col4:\n",
    "    current_customers = current_period['customers'].sum()\n",
    "    previous_customers = previous_period['customers'].sum()\n",
    "    customers_change = ((current_customers - previous_customers) / previous_customers * 100) if previous_customers > 0 else 0\n",
    "    \n",
    "    st.metric(\n",
    "        label=\"👥 Customers\",\n",
    "        value=f\"{current_customers:,.0f}\",\n",
    "        delta=f\"{customers_change:+.1f}%\"\n",
    "    )\n",
    "\n",
    "with kpi_col5:\n",
    "    current_conversion = current_period['conversion_rate'].mean()\n",
    "    previous_conversion = previous_period['conversion_rate'].mean()\n",
    "    conversion_change = current_conversion - previous_conversion\n",
    "    \n",
    "    st.metric(\n",
    "        label=\"🎯 Conversion Rate\",\n",
    "        value=f\"{current_conversion:.1f}%\",\n",
    "        delta=f\"{conversion_change:+.1f}%\"\n",
    "    )\n",
    "\n",
    "# Interactive Charts Section\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"📈 Interactive Business Analytics\")\n",
    "\n",
    "# Chart tabs for better organization\n",
    "chart_tab1, chart_tab2, chart_tab3, chart_tab4 = st.tabs([\n",
    "    \"📊 Time Series\", \"🏷️ Categories\", \"🗺️ Geographic\", \"📋 Summary\"\n",
    "])\n",
    "\n",
    "with chart_tab1:\n",
    "    # Time series charts\n",
    "    ts_col1, ts_col2 = st.columns(2)\n",
    "    \n",
    "    with ts_col1:\n",
    "        # Orders and Revenue over time\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            subplot_titles=['Orders Over Time', 'Revenue Over Time'],\n",
    "            vertical_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        # Group by day for cleaner visualization\n",
    "        daily_data = filtered_df.groupby(filtered_df['timestamp'].dt.date).agg({\n",
    "            'orders': 'sum',\n",
    "            'revenue': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_data['timestamp'],\n",
    "                y=daily_data['orders'],\n",
    "                mode='lines+markers',\n",
    "                name='Orders',\n",
    "                line=dict(color=color_palette[0], width=3)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_data['timestamp'],\n",
    "                y=daily_data['revenue'],\n",
    "                mode='lines+markers',\n",
    "                name='Revenue',\n",
    "                line=dict(color=color_palette[1], width=3)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=500,\n",
    "            title_text=\"Business Performance Trends\",\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with ts_col2:\n",
    "        # Customer satisfaction and conversion trends\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            subplot_titles=['Customer Satisfaction', 'Conversion Rate'],\n",
    "            vertical_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        daily_metrics = filtered_df.groupby(filtered_df['timestamp'].dt.date).agg({\n",
    "            'satisfaction': 'mean',\n",
    "            'conversion_rate': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_metrics['timestamp'],\n",
    "                y=daily_metrics['satisfaction'],\n",
    "                mode='lines+markers',\n",
    "                name='Satisfaction',\n",
    "                line=dict(color=color_palette[2], width=3),\n",
    "                fill='tonexty'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_metrics['timestamp'],\n",
    "                y=daily_metrics['conversion_rate'],\n",
    "                mode='lines+markers',\n",
    "                name='Conversion',\n",
    "                line=dict(color=color_palette[3], width=3)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=500,\n",
    "            title_text=\"Quality Metrics Trends\",\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "with chart_tab2:\n",
    "    # Category analysis\n",
    "    cat_col1, cat_col2 = st.columns(2)\n",
    "    \n",
    "    with cat_col1:\n",
    "        # Category performance pie chart\n",
    "        category_summary = filtered_category_df.groupby('category').agg({\n",
    "            'orders': 'sum',\n",
    "            'revenue': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig = px.pie(\n",
    "            category_summary,\n",
    "            values='revenue',\n",
    "            names='category',\n",
    "            title=\"Revenue by Product Category\",\n",
    "            color_discrete_sequence=color_palette\n",
    "        )\n",
    "        \n",
    "        fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with cat_col2:\n",
    "        # Category trends over time\n",
    "        category_daily = filtered_category_df.groupby([\n",
    "            filtered_category_df['timestamp'].dt.date, 'category'\n",
    "        ])['revenue'].sum().reset_index()\n",
    "        \n",
    "        fig = px.line(\n",
    "            category_daily,\n",
    "            x='timestamp',\n",
    "            y='revenue',\n",
    "            color='category',\n",
    "            title=\"Category Revenue Trends\",\n",
    "            color_discrete_sequence=color_palette\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=400)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    # Category performance table\n",
    "    st.subheader(\"📊 Category Performance Summary\")\n",
    "    \n",
    "    category_summary['avg_order_value'] = category_summary['revenue'] / category_summary['orders']\n",
    "    category_summary['revenue_share'] = (category_summary['revenue'] / category_summary['revenue'].sum() * 100)\n",
    "    \n",
    "    st.dataframe(\n",
    "        category_summary.style.format({\n",
    "            'orders': '{:,}',\n",
    "            'revenue': 'R$ {:,.0f}',\n",
    "            'avg_order_value': 'R$ {:.2f}',\n",
    "            'revenue_share': '{:.1f}%'\n",
    "        }),\n",
    "        use_container_width=True\n",
    "    )\n",
    "\n",
    "with chart_tab3:\n",
    "    # Geographic analysis (simulated)\n",
    "    st.subheader(\"🗺️ Geographic Performance\")\n",
    "    \n",
    "    # Generate sample geographic data\n",
    "    states = ['São Paulo', 'Rio de Janeiro', 'Minas Gerais', 'Bahia', 'Paraná', 'Santa Catarina']\n",
    "    geo_data = []\n",
    "    \n",
    "    for state in states:\n",
    "        orders = np.random.randint(1000, 5000)\n",
    "        revenue = orders * np.random.uniform(80, 120)\n",
    "        satisfaction = np.random.uniform(3.8, 4.5)\n",
    "        \n",
    "        geo_data.append({\n",
    "            'state': state,\n",
    "            'orders': orders,\n",
    "            'revenue': revenue,\n",
    "            'satisfaction': satisfaction\n",
    "        })\n",
    "    \n",
    "    geo_df = pd.DataFrame(geo_data)\n",
    "    \n",
    "    geo_col1, geo_col2 = st.columns(2)\n",
    "    \n",
    "    with geo_col1:\n",
    "        # Revenue by state\n",
    "        fig = px.bar(\n",
    "            geo_df.sort_values('revenue', ascending=True),\n",
    "            x='revenue',\n",
    "            y='state',\n",
    "            orientation='h',\n",
    "            title=\"Revenue by State\",\n",
    "            color='satisfaction',\n",
    "            color_continuous_scale='RdYlGn'\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=400)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    with geo_col2:\n",
    "        # Orders vs Satisfaction scatter\n",
    "        fig = px.scatter(\n",
    "            geo_df,\n",
    "            x='orders',\n",
    "            y='satisfaction',\n",
    "            size='revenue',\n",
    "            color='state',\n",
    "            title=\"Orders vs Satisfaction by State\",\n",
    "            hover_data=['revenue'],\n",
    "            color_discrete_sequence=color_palette\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=400)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "with chart_tab4:\n",
    "    # Summary dashboard\n",
    "    st.subheader(\"📋 Executive Summary\")\n",
    "    \n",
    "    summary_col1, summary_col2 = st.columns(2)\n",
    "    \n",
    "    with summary_col1:\n",
    "        # Key insights\n",
    "        st.markdown(\"### 🎯 Key Insights\")\n",
    "        \n",
    "        total_orders = filtered_df['orders'].sum()\n",
    "        total_revenue = filtered_df['revenue'].sum()\n",
    "        avg_satisfaction = filtered_df['satisfaction'].mean()\n",
    "        \n",
    "        st.info(f\"📊 **Total Orders**: {total_orders:,} in selected period\")\n",
    "        st.info(f\"💰 **Total Revenue**: R$ {total_revenue:,.0f}\")\n",
    "        st.info(f\"⭐ **Average Satisfaction**: {avg_satisfaction:.2f}/5.0\")\n",
    "        \n",
    "        # Performance indicators\n",
    "        if avg_satisfaction >= 4.0:\n",
    "            st.success(\"✅ Customer satisfaction is above target (4.0)\")\n",
    "        else:\n",
    "            st.warning(\"⚠️ Customer satisfaction needs attention\")\n",
    "        \n",
    "        if orders_change > 0:\n",
    "            st.success(f\"📈 Orders growing by {orders_change:.1f}%\")\n",
    "        else:\n",
    "            st.error(f\"📉 Orders declining by {abs(orders_change):.1f}%\")\n",
    "    \n",
    "    with summary_col2:\n",
    "        # Performance gauge\n",
    "        overall_score = (avg_satisfaction / 5.0) * 100\n",
    "        \n",
    "        fig = go.Figure(go.Indicator(\n",
    "            mode = \"gauge+number+delta\",\n",
    "            value = overall_score,\n",
    "            domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "            title = {'text': \"Overall Performance Score\"},\n",
    "            delta = {'reference': 80},\n",
    "            gauge = {\n",
    "                'axis': {'range': [None, 100]},\n",
    "                'bar': {'color': color_palette[0]},\n",
    "                'steps': [\n",
    "                    {'range': [0, 60], 'color': \"lightgray\"},\n",
    "                    {'range': [60, 80], 'color': \"yellow\"},\n",
    "                    {'range': [80, 100], 'color': \"lightgreen\"}\n",
    "                ],\n",
    "                'threshold': {\n",
    "                    'line': {'color': \"red\", 'width': 4},\n",
    "                    'thickness': 0.75,\n",
    "                    'value': 90\n",
    "                }\n",
    "            }\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(height=400)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"**📊 Real-Time Dashboard** | \"\n",
    "    \"Built with Streamlit & Plotly | \"\n",
    "    \"**🔗 Data Source**: Live Supabase Connection | \"\n",
    "    f\"**🕒 Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 Section 2: Supabase Integration Setup (7 minutes)\n",
    "\n",
    "Now let's connect to real Supabase data for live business intelligence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile supabase_integration_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Configure page\n",
    "st.set_page_config(\n",
    "    page_title=\"Live Supabase Dashboard\",\n",
    "    page_icon=\"🔗\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"🔗 Live Supabase Data Integration\")\n",
    "st.markdown(\"**Real-time business dashboard with live database connectivity**\")\n",
    "\n",
    "# Supabase connection helper\n",
    "@st.cache_resource\n",
    "def init_supabase_connection():\n",
    "    \"\"\"\n",
    "    Initialize Supabase connection using environment variables or Streamlit secrets.\n",
    "    In production, use st.secrets for secure credential management.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to get credentials from Streamlit secrets first\n",
    "        if hasattr(st, 'secrets') and 'supabase' in st.secrets:\n",
    "            url = st.secrets['supabase']['url']\n",
    "            key = st.secrets['supabase']['anon_key']\n",
    "        else:\n",
    "            # Fallback to environment variables\n",
    "            url = os.getenv('SUPABASE_URL')\n",
    "            key = os.getenv('SUPABASE_ANON_KEY')\n",
    "        \n",
    "        if not url or not key:\n",
    "            st.error(\"❌ Supabase credentials not found. Please set up your credentials.\")\n",
    "            st.info(\n",
    "                \"Add your Supabase URL and anon key to `.streamlit/secrets.toml` \"\n",
    "                \"or set SUPABASE_URL and SUPABASE_ANON_KEY environment variables.\"\n",
    "            )\n",
    "            return None\n",
    "        \n",
    "        # Note: In a real application, you would import and use the supabase client here\n",
    "        # from supabase import create_client, Client\n",
    "        # supabase: Client = create_client(url, key)\n",
    "        # return supabase\n",
    "        \n",
    "        # For this demo, we'll simulate the connection\n",
    "        st.success(\"✅ Supabase connection established!\")\n",
    "        return {'url': url, 'status': 'connected'}\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Failed to connect to Supabase: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Data loading functions that would query Supabase\n",
    "@st.cache_data(ttl=300)  # Cache for 5 minutes\n",
    "def load_orders_data(supabase_client, limit=1000):\n",
    "    \"\"\"\n",
    "    Load orders data from Supabase.\n",
    "    In production, this would execute actual Supabase queries.\n",
    "    \"\"\"\n",
    "    if not supabase_client:\n",
    "        return None\n",
    "    \n",
    "    # Simulated query: supabase_client.table('orders').select('*').limit(limit).execute()\n",
    "    # For demo, generate realistic data\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    dates = pd.date_range('2024-01-01', periods=limit, freq='H')\n",
    "    \n",
    "    data = {\n",
    "        'order_id': [f\"ORD_{i:08d}\" for i in range(1, limit + 1)],\n",
    "        'customer_id': [f\"CUST_{np.random.randint(1, 10000):06d}\" for _ in range(limit)],\n",
    "        'order_date': dates,\n",
    "        'product_category': np.random.choice([\n",
    "            'Electronics', 'Fashion', 'Home & Garden', 'Books', 'Sports',\n",
    "            'Beauty', 'Automotive', 'Toys', 'Health', 'Food'\n",
    "        ], limit),\n",
    "        'order_value': np.random.exponential(100, limit),\n",
    "        'customer_state': np.random.choice([\n",
    "            'SP', 'RJ', 'MG', 'BA', 'PR', 'RS', 'PE', 'CE', 'SC', 'GO'\n",
    "        ], limit),\n",
    "        'order_status': np.random.choice([\n",
    "            'completed', 'processing', 'shipped', 'cancelled'\n",
    "        ], limit, p=[0.8, 0.1, 0.08, 0.02]),\n",
    "        'satisfaction_score': np.random.choice([1, 2, 3, 4, 5], limit, p=[0.05, 0.1, 0.2, 0.35, 0.3])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['order_value'] = np.round(df['order_value'], 2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "@st.cache_data(ttl=300)\n",
    "def load_customer_metrics(supabase_client):\n",
    "    \"\"\"\n",
    "    Load customer metrics from Supabase.\n",
    "    \"\"\"\n",
    "    if not supabase_client:\n",
    "        return None\n",
    "    \n",
    "    # Simulated aggregated metrics query\n",
    "    metrics = {\n",
    "        'total_customers': 45230,\n",
    "        'new_customers_today': 127,\n",
    "        'customer_ltv': 485.50,\n",
    "        'churn_rate': 2.3,\n",
    "        'avg_satisfaction': 4.2,\n",
    "        'nps_score': 67\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize connection\n",
    "supabase_client = init_supabase_connection()\n",
    "\n",
    "if supabase_client:\n",
    "    # Sidebar controls\n",
    "    st.sidebar.header(\"🔧 Database Controls\")\n",
    "    \n",
    "    # Data refresh controls\n",
    "    if st.sidebar.button(\"🔄 Refresh Data\"):\n",
    "        st.cache_data.clear()\n",
    "        st.success(\"✅ Data refreshed from Supabase!\")\n",
    "        st.rerun()\n",
    "    \n",
    "    # Query limit\n",
    "    query_limit = st.sidebar.slider(\n",
    "        \"Query Limit:\",\n",
    "        min_value=100,\n",
    "        max_value=5000,\n",
    "        value=1000,\n",
    "        step=100,\n",
    "        help=\"Limit number of records to fetch for performance\"\n",
    "    )\n",
    "    \n",
    "    # Filter controls\n",
    "    st.sidebar.subheader(\"📊 Data Filters\")\n",
    "    \n",
    "    date_filter = st.sidebar.date_input(\n",
    "        \"Orders Since:\",\n",
    "        value=datetime.now().date() - timedelta(days=30),\n",
    "        help=\"Filter orders from this date forward\"\n",
    "    )\n",
    "    \n",
    "    status_filter = st.sidebar.multiselect(\n",
    "        \"Order Status:\",\n",
    "        ['completed', 'processing', 'shipped', 'cancelled'],\n",
    "        default=['completed', 'processing', 'shipped']\n",
    "    )\n",
    "    \n",
    "    # Load data\n",
    "    with st.spinner(\"🔄 Loading data from Supabase...\"):\n",
    "        orders_df = load_orders_data(supabase_client, query_limit)\n",
    "        customer_metrics = load_customer_metrics(supabase_client)\n",
    "    \n",
    "    if orders_df is not None and customer_metrics is not None:\n",
    "        # Apply filters\n",
    "        filtered_orders = orders_df[\n",
    "            (orders_df['order_date'].dt.date >= date_filter) &\n",
    "            (orders_df['order_status'].isin(status_filter))\n",
    "        ]\n",
    "        \n",
    "        # Display connection info\n",
    "        info_col1, info_col2, info_col3 = st.columns(3)\n",
    "        \n",
    "        with info_col1:\n",
    "            st.info(f\"🔗 **Connected to Supabase**\\n\\nRecords loaded: {len(orders_df):,}\")\n",
    "        \n",
    "        with info_col2:\n",
    "            st.info(f\"📊 **Filtered Dataset**\\n\\nRecords after filters: {len(filtered_orders):,}\")\n",
    "        \n",
    "        with info_col3:\n",
    "            st.info(f\"🕒 **Last Updated**\\n\\n{datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        # Live KPIs from Supabase\n",
    "        st.subheader(\"📊 Live Business Metrics\")\n",
    "        \n",
    "        kpi_col1, kpi_col2, kpi_col3, kpi_col4, kpi_col5, kpi_col6 = st.columns(6)\n",
    "        \n",
    "        with kpi_col1:\n",
    "            st.metric(\n",
    "                \"👥 Total Customers\",\n",
    "                f\"{customer_metrics['total_customers']:,}\",\n",
    "                f\"+{customer_metrics['new_customers_today']}\"\n",
    "            )\n",
    "        \n",
    "        with kpi_col2:\n",
    "            total_revenue = filtered_orders['order_value'].sum()\n",
    "            st.metric(\n",
    "                \"💰 Revenue\",\n",
    "                f\"R$ {total_revenue:,.0f}\",\n",
    "                \"Live data\"\n",
    "            )\n",
    "        \n",
    "        with kpi_col3:\n",
    "            avg_order_value = filtered_orders['order_value'].mean()\n",
    "            st.metric(\n",
    "                \"💳 Avg Order Value\",\n",
    "                f\"R$ {avg_order_value:.2f}\",\n",
    "                \"Real-time\"\n",
    "            )\n",
    "        \n",
    "        with kpi_col4:\n",
    "            st.metric(\n",
    "                \"⭐ Satisfaction\",\n",
    "                f\"{customer_metrics['avg_satisfaction']:.1f}/5.0\",\n",
    "                f\"NPS: {customer_metrics['nps_score']}\"\n",
    "            )\n",
    "        \n",
    "        with kpi_col5:\n",
    "            st.metric(\n",
    "                \"💼 Customer LTV\",\n",
    "                f\"R$ {customer_metrics['customer_ltv']:.2f}\",\n",
    "                \"Lifetime Value\"\n",
    "            )\n",
    "        \n",
    "        with kpi_col6:\n",
    "            st.metric(\n",
    "                \"📉 Churn Rate\",\n",
    "                f\"{customer_metrics['churn_rate']:.1f}%\",\n",
    "                \"Monthly\"\n",
    "            )\n",
    "        \n",
    "        # Interactive visualizations\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"📈 Live Data Visualizations\")\n",
    "        \n",
    "        viz_col1, viz_col2 = st.columns(2)\n",
    "        \n",
    "        with viz_col1:\n",
    "            # Revenue by category\n",
    "            category_revenue = filtered_orders.groupby('product_category')['order_value'].sum().reset_index()\n",
    "            category_revenue = category_revenue.sort_values('order_value', ascending=False)\n",
    "            \n",
    "            fig = px.bar(\n",
    "                category_revenue,\n",
    "                x='product_category',\n",
    "                y='order_value',\n",
    "                title=\"Revenue by Product Category (Live Data)\",\n",
    "                labels={'order_value': 'Revenue (R$)', 'product_category': 'Category'}\n",
    "            )\n",
    "            fig.update_xaxes(tickangle=45)\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        with viz_col2:\n",
    "            # Orders by state\n",
    "            state_orders = filtered_orders['customer_state'].value_counts().reset_index()\n",
    "            state_orders.columns = ['state', 'orders']\n",
    "            \n",
    "            fig = px.pie(\n",
    "                state_orders.head(8),  # Top 8 states\n",
    "                values='orders',\n",
    "                names='state',\n",
    "                title=\"Orders by State (Top 8)\"\n",
    "            )\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # Time series analysis\n",
    "        st.subheader(\"📊 Time Series Analysis\")\n",
    "        \n",
    "        # Daily revenue trend\n",
    "        daily_revenue = filtered_orders.groupby(\n",
    "            filtered_orders['order_date'].dt.date\n",
    "        ).agg({\n",
    "            'order_value': 'sum',\n",
    "            'order_id': 'count',\n",
    "            'satisfaction_score': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        daily_revenue.columns = ['date', 'revenue', 'orders', 'avg_satisfaction']\n",
    "        \n",
    "        # Create subplot with secondary y-axis\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Revenue line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_revenue['date'],\n",
    "                y=daily_revenue['revenue'],\n",
    "                mode='lines+markers',\n",
    "                name='Daily Revenue',\n",
    "                line=dict(color='#1f77b4', width=3)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"Daily Revenue Trend (Live Supabase Data)\",\n",
    "            xaxis_title=\"Date\",\n",
    "            yaxis_title=\"Revenue (R$)\",\n",
    "            height=400\n",
    "        )\n",
    "        \n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        # Data preview\n",
    "        st.subheader(\"📋 Live Data Preview\")\n",
    "        \n",
    "        preview_tabs = st.tabs([\"📦 Recent Orders\", \"📊 Summary Stats\", \"🔍 Raw Data\"])\n",
    "        \n",
    "        with preview_tabs[0]:\n",
    "            # Show recent orders\n",
    "            recent_orders = filtered_orders.nlargest(10, 'order_date')\n",
    "            st.dataframe(\n",
    "                recent_orders[[\n",
    "                    'order_id', 'order_date', 'product_category',\n",
    "                    'order_value', 'customer_state', 'order_status'\n",
    "                ]],\n",
    "                use_container_width=True\n",
    "            )\n",
    "        \n",
    "        with preview_tabs[1]:\n",
    "            # Summary statistics\n",
    "            stats_col1, stats_col2 = st.columns(2)\n",
    "            \n",
    "            with stats_col1:\n",
    "                st.markdown(\"**📊 Order Statistics**\")\n",
    "                st.write(f\"Total Orders: {len(filtered_orders):,}\")\n",
    "                st.write(f\"Total Revenue: R$ {filtered_orders['order_value'].sum():,.2f}\")\n",
    "                st.write(f\"Average Order Value: R$ {filtered_orders['order_value'].mean():.2f}\")\n",
    "                st.write(f\"Median Order Value: R$ {filtered_orders['order_value'].median():.2f}\")\n",
    "            \n",
    "            with stats_col2:\n",
    "                st.markdown(\"**⭐ Quality Metrics**\")\n",
    "                st.write(f\"Average Satisfaction: {filtered_orders['satisfaction_score'].mean():.2f}/5.0\")\n",
    "                completion_rate = (filtered_orders['order_status'] == 'completed').mean() * 100\n",
    "                st.write(f\"Completion Rate: {completion_rate:.1f}%\")\n",
    "                st.write(f\"Unique Customers: {filtered_orders['customer_id'].nunique():,}\")\n",
    "                st.write(f\"Product Categories: {filtered_orders['product_category'].nunique()}\")\n",
    "        \n",
    "        with preview_tabs[2]:\n",
    "            # Raw data with search\n",
    "            search_term = st.text_input(\"🔍 Search orders (by Order ID or Customer ID):\")\n",
    "            \n",
    "            if search_term:\n",
    "                search_results = filtered_orders[\n",
    "                    (filtered_orders['order_id'].str.contains(search_term, case=False)) |\n",
    "                    (filtered_orders['customer_id'].str.contains(search_term, case=False))\n",
    "                ]\n",
    "                st.dataframe(search_results, use_container_width=True)\n",
    "            else:\n",
    "                st.dataframe(filtered_orders.head(20), use_container_width=True)\n",
    "        \n",
    "        # Export functionality\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"💾 Data Export\")\n",
    "        \n",
    "        export_col1, export_col2, export_col3 = st.columns(3)\n",
    "        \n",
    "        with export_col1:\n",
    "            if st.button(\"📊 Export to CSV\"):\n",
    "                csv = filtered_orders.to_csv(index=False)\n",
    "                st.download_button(\n",
    "                    label=\"⬇️ Download CSV\",\n",
    "                    data=csv,\n",
    "                    file_name=f\"olist_orders_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
    "                    mime=\"text/csv\"\n",
    "                )\n",
    "        \n",
    "        with export_col2:\n",
    "            if st.button(\"📈 Export Summary Report\"):\n",
    "                summary_report = daily_revenue.to_csv(index=False)\n",
    "                st.download_button(\n",
    "                    label=\"⬇️ Download Report\",\n",
    "                    data=summary_report,\n",
    "                    file_name=f\"daily_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
    "                    mime=\"text/csv\"\n",
    "                )\n",
    "        \n",
    "        with export_col3:\n",
    "            if st.button(\"📧 Email Dashboard\"):\n",
    "                st.success(\"✅ Dashboard summary sent to stakeholders!\")\n",
    "                st.info(\"📧 Email functionality would be implemented here\")\n",
    "    \n",
    "    else:\n",
    "        st.error(\"❌ Failed to load data from Supabase\")\n",
    "        st.info(\"Please check your database connection and try again.\")\n",
    "\n",
    "else:\n",
    "    # Show connection setup instructions\n",
    "    st.warning(\"⚠️ Supabase connection not configured\")\n",
    "    \n",
    "    with st.expander(\"🔧 Setup Instructions\", expanded=True):\n",
    "        st.markdown(\"\"\"\n",
    "        ### Setting up Supabase Connection\n",
    "        \n",
    "        To connect this dashboard to live Supabase data:\n",
    "        \n",
    "        1. **Create a `.streamlit/secrets.toml` file** in your project root:\n",
    "        ```toml\n",
    "        [supabase]\n",
    "        url = \"https://your-project.supabase.co\"\n",
    "        anon_key = \"your-anon-key-here\"\n",
    "        ```\n",
    "        \n",
    "        2. **Or set environment variables**:\n",
    "        ```bash\n",
    "        export SUPABASE_URL=\"https://your-project.supabase.co\"\n",
    "        export SUPABASE_ANON_KEY=\"your-anon-key-here\"\n",
    "        ```\n",
    "        \n",
    "        3. **Install the Supabase client**:\n",
    "        ```bash\n",
    "        pip install supabase\n",
    "        ```\n",
    "        \n",
    "        4. **Ensure your Supabase tables match the expected schema**:\n",
    "        - `orders` table with columns: order_id, customer_id, order_date, product_category, order_value, customer_state, order_status, satisfaction_score\n",
    "        - Proper Row Level Security (RLS) policies for data access\n",
    "        \n",
    "        5. **Restart your Streamlit app** after configuration\n",
    "        \"\"\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"**🔗 Live Supabase Integration** | \"\n",
    "    \"Real-time business intelligence with secure database connectivity | \"\n",
    "    \"**📚 Next:** Advanced dashboard features and deployment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Section 3: Performance and Caching (5 minutes)\n",
    "\n",
    "Learn essential performance optimization techniques for production dashboards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization examples\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Example 1: Data Caching\n",
    "st.subheader(\"🚀 Performance Optimization Techniques\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### 1. Data Caching with `@st.cache_data`\n",
    "\n",
    "**Problem**: Database queries run on every user interaction  \n",
    "**Solution**: Cache expensive operations\n",
    "\n",
    "```python\n",
    "@st.cache_data(ttl=300)  # Cache for 5 minutes\n",
    "def load_sales_data():\n",
    "    # Expensive database query\n",
    "    return pd.read_sql(query, connection)\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### 2. Resource Caching with `@st.cache_resource`\n",
    "\n",
    "**Use for**: Database connections, ML models, global objects  \n",
    "\n",
    "```python\n",
    "@st.cache_resource\n",
    "def init_database_connection():\n",
    "    return create_supabase_client()\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### 3. Conditional Rendering\n",
    "\n",
    "**Avoid**: Rendering expensive components unnecessarily  \n",
    "\n",
    "```python\n",
    "if show_advanced_charts:\n",
    "    # Only create expensive charts when needed\n",
    "    create_complex_visualization()\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### 4. Efficient Data Filtering\n",
    "\n",
    "**Best Practice**: Filter at database level, not in Python  \n",
    "\n",
    "```python\n",
    "# Good: Filter in SQL\n",
    "query = \"SELECT * FROM orders WHERE date >= %s\"\n",
    "df = pd.read_sql(query, conn, params=[start_date])\n",
    "\n",
    "# Avoid: Loading all data then filtering\n",
    "df = pd.read_sql(\"SELECT * FROM orders\", conn)\n",
    "df = df[df['date'] >= start_date]\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "# Interactive performance demo\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"🔬 Performance Comparison Demo\")\n",
    "\n",
    "demo_col1, demo_col2 = st.columns(2)\n",
    "\n",
    "with demo_col1:\n",
    "    st.markdown(\"**Without Caching:**\")\n",
    "    if st.button(\"Load Data (No Cache)\"):\n",
    "        start_time = time.time()\n",
    "        # Simulate expensive operation\n",
    "        time.sleep(2)\n",
    "        data = pd.DataFrame({'x': range(1000), 'y': range(1000)})\n",
    "        end_time = time.time()\n",
    "        st.write(f\"⏱️ Time: {end_time - start_time:.2f} seconds\")\n",
    "        st.write(f\"📊 Loaded {len(data)} records\")\n",
    "\n",
    "with demo_col2:\n",
    "    st.markdown(\"**With Caching:**\")\n",
    "    \n",
    "    @st.cache_data\n",
    "    def load_cached_data():\n",
    "        time.sleep(2)  # Simulate expensive operation\n",
    "        return pd.DataFrame({'x': range(1000), 'y': range(1000)})\n",
    "    \n",
    "    if st.button(\"Load Data (Cached)\"):\n",
    "        start_time = time.time()\n",
    "        data = load_cached_data()\n",
    "        end_time = time.time()\n",
    "        st.write(f\"⏱️ Time: {end_time - start_time:.2f} seconds\")\n",
    "        st.write(f\"📊 Loaded {len(data)} records\")\n",
    "        st.info(\"🚀 Subsequent calls will be instant!\")\n",
    "\n",
    "print(\"✅ Performance optimization examples ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Key Takeaways\n",
    "\n",
    "✅ **Interactive Visualizations**: Plotly integration for professional charts  \n",
    "✅ **Live Data Connectivity**: Supabase integration for real-time dashboards  \n",
    "✅ **Performance Optimization**: Caching strategies for production apps  \n",
    "✅ **Business Intelligence**: Executive-level dashboard design  \n",
    "✅ **Data Export**: CSV downloads and sharing capabilities  \n",
    "\n",
    "## 🔜 What's Next\n",
    "\n",
    "Tomorrow (Thursday), we'll dive into advanced Streamlit features:\n",
    "\n",
    "**Thursday Topics:**\n",
    "- Multi-page applications and navigation\n",
    "- Advanced business dashboard patterns\n",
    "- Production deployment to Streamlit Cloud\n",
    "- Security and authentication considerations\n",
    "\n",
    "---\n",
    "\n",
    "## 💼 Today's Assignment: Basic Streamlit Dashboard\n",
    "\n",
    "**Create your first business intelligence dashboard:**\n",
    "\n",
    "### Requirements:\n",
    "1. **Data Source**: Connect to Olist sample data (provided)\n",
    "2. **KPI Metrics**: Display 4-6 key business metrics\n",
    "3. **Interactive Filters**: Date range, category, and state filters\n",
    "4. **Visualizations**: 2-3 charts showing business insights\n",
    "5. **Professional Design**: Clean layout with proper styling\n",
    "\n",
    "### Business Focus:\n",
    "- **Audience**: E-commerce operations manager\n",
    "- **Goal**: Daily performance monitoring\n",
    "- **Key Questions**: \n",
    "  - How are sales trending?\n",
    "  - Which categories perform best?\n",
    "  - What's our customer satisfaction?\n",
    "\n",
    "### Deliverable:\n",
    "- Working Streamlit app (`.py` file)\n",
    "- Screenshots of dashboard in action\n",
    "- Brief explanation of business insights discovered\n",
    "\n",
    "### Due: Before Thursday's class\n",
    "\n",
    "**Tip**: Start with the interactive dashboard template from today's session and customize it for the assignment requirements.\n",
    "\n",
    "---\n",
    "\n",
    "*Next: [Thursday - Advanced Streamlit Features →](02_streamlit_advanced_part1_business_dashboards.ipynb)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
