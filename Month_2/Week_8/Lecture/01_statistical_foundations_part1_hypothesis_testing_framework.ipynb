{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 - Statistical Foundations Part 1: Hypothesis Testing Framework\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will be able to:\n",
    "1. **Understand** the statistical hypothesis testing framework for business decisions\n",
    "2. **Apply** the scientific method to e-commerce data analysis\n",
    "3. **Interpret** p-values, confidence intervals, and statistical significance in business context\n",
    "4. **Distinguish** between statistical significance and business significance\n",
    "5. **Design** hypothesis tests for common business scenarios\n",
    "\n",
    "## Business Context: From Exploration to Validation\n",
    "\n",
    "In **Week 7**, we explored Olist data to discover patterns and insights through **Exploratory Data Analysis (EDA)**. We found interesting relationships and trends, but we couldn't be certain if these patterns were real or just coincidental.\n",
    "\n",
    "**Week 8** introduces **statistical rigor** to validate our discoveries. Instead of just observing patterns, we'll:\n",
    "- **Test hypotheses** about our business assumptions\n",
    "- **Quantify uncertainty** with confidence intervals\n",
    "- **Make data-driven decisions** with statistical backing\n",
    "- **Communicate findings** with statistical confidence\n",
    "\n",
    "Today we work with **Olist**, Brazil's largest e-commerce marketplace, to answer questions like:\n",
    "- Are customers in S√£o Paulo significantly more satisfied than those in other states?\n",
    "- Do credit card payments really lead to higher order values?\n",
    "- Is the difference in delivery times between regions statistically meaningful?\n",
    "\n",
    "## Real Business Impact\n",
    "\n",
    "Statistical testing enables **evidence-based business decisions**:\n",
    "- **Marketing**: Which channels actually convert better?\n",
    "- **Operations**: Are delivery improvements statistically significant?\n",
    "- **Product**: Do product changes actually increase satisfaction?\n",
    "- **Strategy**: Are regional differences real or random variation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis Environment Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Database connection\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Statistical analysis specific imports\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, chi2_contingency, f_oneway\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Statistical Analysis Environment Ready!\")\n",
    "print(f\"üìà SciPy version: {stats.__name__}\")\n",
    "print(f\"üêº Pandas version: {pd.__version__}\")\n",
    "print(\"üî¨ Ready to conduct rigorous statistical analysis on Olist marketplace data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection Setup\n",
    "\n",
    "We'll connect to the same Supabase database used in Weeks 6-7, continuing our analysis of the Olist Brazilian e-commerce dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secure Database Connection Using Environment Variables\n",
    "# Best practice: Never expose credentials in code\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Read database credentials from environment variables\n",
    "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
    "SUPABASE_KEY = os.getenv('SUPABASE_KEY')\n",
    "\n",
    "# Alternative: Use legacy postgres connection if needed\n",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '6543')\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DATABASE', 'postgres')\n",
    "POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "# Construct secure database URL using environment variables\n",
    "if POSTGRES_HOST and POSTGRES_USER and POSTGRES_PASSWORD:\n",
    "    DATABASE_URL = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "else:\n",
    "    print(\"‚ùå Database credentials not found in environment variables\")\n",
    "    print(\"Please check your .env file contains the required database credentials\")\n",
    "\n",
    "# Create database engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        from sqlalchemy import text\n",
    "        result = conn.execute(text(\"SELECT count(*) FROM olist_sales_data_set.olist_geolocation_dataset\"))\n",
    "        count = result.scalar()\n",
    "        print(f\"‚úÖ Secure database connection established! ({count:,} records in geolocation table)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "\n",
    "print(\"üîí Security Note: Database credentials loaded from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Statistical Hypothesis Testing Framework\n",
    "\n",
    "### From Business Questions to Statistical Tests\n",
    "\n",
    "Statistical hypothesis testing provides a **systematic framework** for making data-driven business decisions. Here's how we transform business questions into testable hypotheses:\n",
    "\n",
    "#### The Scientific Method in Business Analytics\n",
    "\n",
    "1. **Observe** ‚Üí Notice patterns in data (from EDA)\n",
    "2. **Hypothesize** ‚Üí Form testable business assumptions\n",
    "3. **Test** ‚Üí Apply statistical methods to data\n",
    "4. **Decide** ‚Üí Accept or reject the hypothesis\n",
    "5. **Act** ‚Üí Implement business changes based on evidence\n",
    "\n",
    "#### Real Business Example: Payment Method Analysis\n",
    "\n",
    "**Business Question**: \"Do customers who pay with credit cards spend more than those who pay with debit cards?\"\n",
    "\n",
    "**Statistical Translation**:\n",
    "- **Null Hypothesis (H‚ÇÄ)**: Credit card and debit card customers spend the same amount on average\n",
    "- **Alternative Hypothesis (H‚ÇÅ)**: Credit card customers spend more on average\n",
    "- **Test**: Two-sample t-test comparing payment values\n",
    "- **Decision**: If p-value < 0.05, we have evidence that credit card users spend more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Business Question to Statistical Framework\n",
    "def demonstrate_hypothesis_framework():\n",
    "    \"\"\"\n",
    "    Show how business questions translate to statistical hypotheses.\n",
    "    \"\"\"\n",
    "    business_scenarios = {\n",
    "        \"Payment Method Impact\": {\n",
    "            \"business_question\": \"Do credit card users spend more than debit card users?\",\n",
    "            \"null_hypothesis\": \"H‚ÇÄ: Œº_credit = Œº_debit (no difference in spending)\",\n",
    "            \"alternative_hypothesis\": \"H‚ÇÅ: Œº_credit > Œº_debit (credit users spend more)\",\n",
    "            \"statistical_test\": \"Two-sample t-test (one-tailed)\",\n",
    "            \"business_impact\": \"Optimize payment processing and marketing strategies\"\n",
    "        },\n",
    "        \"Regional Satisfaction\": {\n",
    "            \"business_question\": \"Are customers equally satisfied across all Brazilian states?\",\n",
    "            \"null_hypothesis\": \"H‚ÇÄ: All states have equal customer satisfaction\",\n",
    "            \"alternative_hypothesis\": \"H‚ÇÅ: At least one state differs in satisfaction\",\n",
    "            \"statistical_test\": \"ANOVA (Analysis of Variance)\",\n",
    "            \"business_impact\": \"Focus operational improvements on underperforming regions\"\n",
    "        },\n",
    "        \"Product Category Performance\": {\n",
    "            \"business_question\": \"Is customer satisfaction independent of product category?\",\n",
    "            \"null_hypothesis\": \"H‚ÇÄ: Satisfaction and category are independent\",\n",
    "            \"alternative_hypothesis\": \"H‚ÇÅ: Satisfaction depends on product category\",\n",
    "            \"statistical_test\": \"Chi-square test of independence\",\n",
    "            \"business_impact\": \"Improve product quality in categories with lower satisfaction\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"üî¨ Business Questions ‚Üí Statistical Framework\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for scenario, details in business_scenarios.items():\n",
    "        print(f\"\\nüìä {scenario}\")\n",
    "        print(f\"‚ùì Question: {details['business_question']}\")\n",
    "        print(f\"üéØ {details['null_hypothesis']}\")\n",
    "        print(f\"üéØ {details['alternative_hypothesis']}\")\n",
    "        print(f\"‚ö° Test: {details['statistical_test']}\")\n",
    "        print(f\"üíº Impact: {details['business_impact']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_hypothesis_framework()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding P-Values and Statistical Significance\n",
    "\n",
    "### What is a P-Value?\n",
    "\n",
    "**P-value**: The probability of observing data as extreme as what we observed, **assuming the null hypothesis is true**.\n",
    "\n",
    "#### P-Value Interpretation Guide:\n",
    "- **p < 0.001**: Very strong evidence against H‚ÇÄ (\"This is almost certainly not due to chance\")\n",
    "- **p < 0.01**: Strong evidence against H‚ÇÄ (\"This is very unlikely to be chance\")\n",
    "- **p < 0.05**: Moderate evidence against H‚ÇÄ (\"This is probably not chance\") ‚Üê **Common threshold**\n",
    "- **p ‚â• 0.05**: Insufficient evidence against H‚ÇÄ (\"Could be due to chance\")\n",
    "\n",
    "### Critical Business Understanding\n",
    "\n",
    "**‚ö†Ô∏è Important**: P-values tell us about **statistical significance**, not **business significance**!\n",
    "\n",
    "- **Statistical Significance**: The difference is probably not due to random chance\n",
    "- **Business Significance**: The difference is large enough to matter for business decisions\n",
    "\n",
    "#### Real Example:\n",
    "- **Finding**: Credit card users spend R$ 2.50 more on average (p = 0.001)\n",
    "- **Statistical Interpretation**: Very strong evidence of a real difference\n",
    "- **Business Interpretation**: R$ 2.50 difference might not justify changing payment strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive P-Value Demonstration\n",
    "def visualize_p_value_concept():\n",
    "    \"\"\"\n",
    "    Create visual explanation of p-values using sampling distributions.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate two scenarios: null true vs alternative true\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scenario 1: Null hypothesis is true (no difference)\n",
    "    null_distribution = np.random.normal(0, 1, 10000)\n",
    "    observed_difference = 2.5  # Our observed test statistic\n",
    "    \n",
    "    ax1.hist(null_distribution, bins=50, density=True, alpha=0.7, color='lightblue', \n",
    "             label='Null Distribution\\n(no real difference)')\n",
    "    ax1.axvline(observed_difference, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Observed Difference: {observed_difference}')\n",
    "    \n",
    "    # Calculate and shade p-value area\n",
    "    p_value = (null_distribution >= observed_difference).mean()\n",
    "    x_shade = null_distribution[null_distribution >= observed_difference]\n",
    "    ax1.hist(x_shade, bins=50, density=True, alpha=0.8, color='red', \n",
    "             label=f'P-value Area: {p_value:.4f}')\n",
    "    \n",
    "    ax1.set_title('P-Value Visualization\\nProbability of observing this difference if H‚ÇÄ is true', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Test Statistic (Difference)')\n",
    "    ax1.set_ylabel('Probability Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scenario 2: Business vs Statistical Significance\n",
    "    effect_sizes = [0.1, 0.5, 1.0, 2.0]\n",
    "    p_values = [0.8, 0.2, 0.05, 0.001]\n",
    "    \n",
    "    colors = ['red' if p >= 0.05 else 'green' for p in p_values]\n",
    "    bars = ax2.bar(range(len(effect_sizes)), effect_sizes, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add p-value labels\n",
    "    for i, (effect, p_val) in enumerate(zip(effect_sizes, p_values)):\n",
    "        significance = 'Not Significant' if p_val >= 0.05 else 'Significant'\n",
    "        ax2.text(i, effect + 0.05, f'p = {p_val}\\n{significance}', \n",
    "                ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax2.axhline(y=0.5, color='orange', linestyle=':', linewidth=2, \n",
    "                label='Business Significance Threshold\\n(hypothetical R$ 0.50)')\n",
    "    \n",
    "    ax2.set_title('Statistical vs Business Significance\\nLow p-value ‚â† Business importance', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('Scenario')\n",
    "    ax2.set_ylabel('Effect Size (R$ difference)')\n",
    "    ax2.set_xticks(range(len(effect_sizes)))\n",
    "    ax2.set_xticklabels([f'Test {i+1}' for i in range(len(effect_sizes))])\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Key Insights:\")\n",
    "    print(f\"  ‚Ä¢ P-value measures evidence against null hypothesis\")\n",
    "    print(f\"  ‚Ä¢ Small p-value means 'unlikely to be due to chance'\")\n",
    "    print(f\"  ‚Ä¢ Always consider business significance alongside statistical significance\")\n",
    "    print(f\"  ‚Ä¢ A tiny difference can be statistically significant with large samples\")\n",
    "\n",
    "# Create the visualization\n",
    "visualize_p_value_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confidence Intervals: Quantifying Uncertainty\n",
    "\n",
    "### What are Confidence Intervals?\n",
    "\n",
    "A **confidence interval** provides a range of plausible values for a population parameter, along with our confidence level.\n",
    "\n",
    "**95% Confidence Interval Interpretation**: \n",
    "\"If we repeated this analysis 100 times with different samples, about 95 of our intervals would contain the true population value.\"\n",
    "\n",
    "#### Business Value of Confidence Intervals:\n",
    "- **Range of Effects**: Instead of just \"significant/not significant\", we get a range\n",
    "- **Precision Assessment**: Narrow intervals = precise estimates; wide intervals = uncertain estimates\n",
    "- **Business Planning**: Plan for best-case and worst-case scenarios within the interval\n",
    "- **Risk Assessment**: Understand the uncertainty in our business metrics\n",
    "\n",
    "#### Practical Example:\n",
    "**Point Estimate**: \"Credit card users spend R$ 15.50 more on average\"\n",
    "**With 95% CI**: \"Credit card users spend R$ 15.50 more on average (95% CI: R$ 12.30 - R$ 18.70)\"\n",
    "\n",
    "**Business Interpretation**: We're 95% confident the true difference is between R$ 12.30 and R$ 18.70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Data Example: Confidence Intervals with Olist Data\n",
    "def demonstrate_confidence_intervals():\n",
    "    \"\"\"\n",
    "    Calculate and visualize confidence intervals using real Olist data.\n",
    "    \"\"\"\n",
    "    if engine is None:\n",
    "        print(\"‚ùå Database connection required for this demonstration\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç Loading real payment method data from Olist database...\")\n",
    "    \n",
    "    # Query payment data for confidence interval analysis\n",
    "    payment_query = \"\"\"\n",
    "    SELECT \n",
    "        p.payment_type,\n",
    "        p.payment_value,\n",
    "        o.order_status\n",
    "    FROM \"olist_sales_data_set\".\"olist_order_payments_dataset\" p\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_orders_dataset\" o \n",
    "        ON p.order_id = o.order_id\n",
    "    WHERE p.payment_type IN ('credit_card', 'debit_card')\n",
    "        AND p.payment_value > 0\n",
    "        AND p.payment_value < 1000  -- Remove extreme outliers\n",
    "        AND o.order_status = 'delivered'\n",
    "    LIMIT 5000  -- Sample for demonstration\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        payment_data = pd.read_sql(text(payment_query), engine)\n",
    "        print(f\"‚úÖ Loaded {len(payment_data):,} payment records\")\n",
    "        \n",
    "        # Calculate confidence intervals for each payment type\n",
    "        results = {}\n",
    "        \n",
    "        for payment_type in ['credit_card', 'debit_card']:\n",
    "            data = payment_data[payment_data['payment_type'] == payment_type]['payment_value']\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mean = data.mean()\n",
    "            std_error = stats.sem(data)  # Standard error of mean\n",
    "            \n",
    "            # 95% confidence interval\n",
    "            ci_95 = stats.t.interval(0.95, len(data)-1, loc=mean, scale=std_error)\n",
    "            \n",
    "            # 99% confidence interval\n",
    "            ci_99 = stats.t.interval(0.99, len(data)-1, loc=mean, scale=std_error)\n",
    "            \n",
    "            results[payment_type] = {\n",
    "                'mean': mean,\n",
    "                'count': len(data),\n",
    "                'ci_95': ci_95,\n",
    "                'ci_99': ci_99\n",
    "            }\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nüìä Payment Method Confidence Intervals:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for payment_type, stats_dict in results.items():\n",
    "            print(f\"\\nüí≥ {payment_type.title()} Cards:\")\n",
    "            print(f\"   Sample size: {stats_dict['count']:,} transactions\")\n",
    "            print(f\"   Mean payment: R$ {stats_dict['mean']:.2f}\")\n",
    "            print(f\"   95% CI: R$ {stats_dict['ci_95'][0]:.2f} - R$ {stats_dict['ci_95'][1]:.2f}\")\n",
    "            print(f\"   99% CI: R$ {stats_dict['ci_99'][0]:.2f} - R$ {stats_dict['ci_99'][1]:.2f}\")\n",
    "        \n",
    "        # Calculate difference confidence interval\n",
    "        credit_data = payment_data[payment_data['payment_type'] == 'credit_card']['payment_value']\n",
    "        debit_data = payment_data[payment_data['payment_type'] == 'debit_card']['payment_value']\n",
    "        \n",
    "        # Two-sample t-test with confidence interval for difference\n",
    "        t_stat, p_value = stats.ttest_ind(credit_data, debit_data, equal_var=False)\n",
    "        \n",
    "        # Calculate difference and its confidence interval\n",
    "        mean_diff = credit_data.mean() - debit_data.mean()\n",
    "        \n",
    "        print(f\"\\nüîç Difference Analysis:\")\n",
    "        print(f\"   Mean difference: R$ {mean_diff:.2f}\")\n",
    "        print(f\"   Statistical test: t = {t_stat:.3f}, p = {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(f\"   ‚úÖ Statistically significant difference (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå No statistically significant difference (p ‚â• 0.05)\")\n",
    "        \n",
    "        # Business interpretation\n",
    "        print(f\"\\nüíº Business Interpretation:\")\n",
    "        if abs(mean_diff) > 10:  # Arbitrary business threshold\n",
    "            print(f\"   üìà The R$ {abs(mean_diff):.2f} difference may justify different payment strategies\")\n",
    "        else:\n",
    "            print(f\"   üìâ The R$ {abs(mean_diff):.2f} difference may not justify major strategy changes\")\n",
    "        \n",
    "        return payment_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading payment data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the confidence interval demonstration\n",
    "payment_data = demonstrate_confidence_intervals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Assumptions and When Tests Apply\n",
    "\n",
    "### Why Assumptions Matter\n",
    "\n",
    "Statistical tests make **assumptions** about the data. Violating these assumptions can lead to **incorrect conclusions** and **bad business decisions**.\n",
    "\n",
    "#### Common Test Assumptions:\n",
    "\n",
    "**1. Independence**: Observations are independent of each other\n",
    "- **Business Context**: Each customer's behavior doesn't influence others\n",
    "- **Violation Example**: Family members making correlated purchases\n",
    "\n",
    "**2. Normality**: Data follows a normal (bell curve) distribution\n",
    "- **Business Context**: Many financial metrics are approximately normal\n",
    "- **Violation Example**: Highly skewed data (income, order values)\n",
    "\n",
    "**3. Equal Variances**: Groups have similar variability\n",
    "- **Business Context**: Different customer segments have similar spread\n",
    "- **Violation Example**: Premium vs budget customer segments\n",
    "\n",
    "#### Practical Solutions:\n",
    "- **Check assumptions** before running tests\n",
    "- **Transform data** when assumptions are violated\n",
    "- **Use non-parametric tests** when assumptions can't be met\n",
    "- **Increase sample sizes** to rely on Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption Checking with Real Olist Data\n",
    "def check_statistical_assumptions(data):\n",
    "    \"\"\"\n",
    "    Check key statistical assumptions using real business data.\n",
    "    \"\"\"\n",
    "    if data is None or data.empty:\n",
    "        print(\"‚ùå No data available for assumption checking\")\n",
    "        return\n",
    "    \n",
    "    print(\"üî¨ Checking Statistical Assumptions\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Separate data by payment type\n",
    "    credit_values = data[data['payment_type'] == 'credit_card']['payment_value']\n",
    "    debit_values = data[data['payment_type'] == 'debit_card']['payment_value']\n",
    "    \n",
    "    # 1. Normality Testing\n",
    "    print(\"\\nüìä 1. Normality Assessment\")\n",
    "    \n",
    "    for payment_type, values in [('Credit Card', credit_values), ('Debit Card', debit_values)]:\n",
    "        # Shapiro-Wilk test (for smaller samples)\n",
    "        if len(values) <= 5000:\n",
    "            stat, p_value = stats.shapiro(values.sample(min(5000, len(values))))\n",
    "            test_name = \"Shapiro-Wilk\"\n",
    "        else:\n",
    "            # Use Anderson-Darling for larger samples\n",
    "            stat, p_value = stats.normaltest(values)\n",
    "            test_name = \"D'Agostino-Pearson\"\n",
    "        \n",
    "        normality = \"‚úÖ Normal\" if p_value > 0.05 else \"‚ùå Not Normal\"\n",
    "        print(f\"   {payment_type}: {test_name} p = {p_value:.4f} ‚Üí {normality}\")\n",
    "    \n",
    "    # 2. Equal Variances Testing\n",
    "    print(\"\\n‚öñÔ∏è 2. Equal Variances Assessment\")\n",
    "    \n",
    "    # Levene's test (robust to non-normality)\n",
    "    levene_stat, levene_p = stats.levene(credit_values, debit_values)\n",
    "    equal_var = \"‚úÖ Equal variances\" if levene_p > 0.05 else \"‚ùå Unequal variances\"\n",
    "    print(f\"   Levene's test: p = {levene_p:.4f} ‚Üí {equal_var}\")\n",
    "    \n",
    "    # 3. Sample Size Assessment\n",
    "    print(\"\\nüìè 3. Sample Size Assessment\")\n",
    "    print(f\"   Credit Card: {len(credit_values):,} samples\")\n",
    "    print(f\"   Debit Card: {len(debit_values):,} samples\")\n",
    "    \n",
    "    min_sample = min(len(credit_values), len(debit_values))\n",
    "    if min_sample >= 30:\n",
    "        print(f\"   ‚úÖ Large samples (n ‚â• 30) ‚Üí Central Limit Theorem applies\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Small samples (n < 30) ‚Üí Need stronger assumptions\")\n",
    "    \n",
    "    # 4. Outlier Detection\n",
    "    print(\"\\nüéØ 4. Outlier Assessment\")\n",
    "    \n",
    "    for payment_type, values in [('Credit Card', credit_values), ('Debit Card', debit_values)]:\n",
    "        Q1 = values.quantile(0.25)\n",
    "        Q3 = values.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        outlier_threshold_low = Q1 - 1.5 * IQR\n",
    "        outlier_threshold_high = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = ((values < outlier_threshold_low) | (values > outlier_threshold_high)).sum()\n",
    "        outlier_pct = (outliers / len(values)) * 100\n",
    "        \n",
    "        print(f\"   {payment_type}: {outliers:,} outliers ({outlier_pct:.1f}%)\")\n",
    "    \n",
    "    # 5. Recommendation\n",
    "    print(\"\\nüéØ Recommendations:\")\n",
    "    \n",
    "    if levene_p <= 0.05:\n",
    "        print(\"   ‚Ä¢ Use Welch's t-test (unequal variances)\")\n",
    "    else:\n",
    "        print(\"   ‚Ä¢ Standard t-test is appropriate\")\n",
    "    \n",
    "    if min_sample >= 30:\n",
    "        print(\"   ‚Ä¢ T-test is robust due to large sample sizes\")\n",
    "    else:\n",
    "        print(\"   ‚Ä¢ Consider non-parametric tests (Mann-Whitney U)\")\n",
    "    \n",
    "    total_outliers = ((credit_values.quantile(0.75) + 1.5 * (credit_values.quantile(0.75) - credit_values.quantile(0.25))) < credit_values).sum()\n",
    "    if total_outliers > len(credit_values) * 0.05:  # More than 5% outliers\n",
    "        print(\"   ‚Ä¢ Consider data transformation or outlier treatment\")\n",
    "\n",
    "# Check assumptions with our payment data\n",
    "if 'payment_data' in locals() and payment_data is not None:\n",
    "    check_statistical_assumptions(payment_data)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Run the previous cell to load payment data first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Right Statistical Test\n",
    "\n",
    "### Decision Framework for Business Scenarios\n",
    "\n",
    "Choosing the correct statistical test is crucial for valid business conclusions. Here's a practical framework:\n",
    "\n",
    "#### Test Selection Flowchart:\n",
    "\n",
    "**1. What type of data do you have?**\n",
    "- **Continuous** (order values, delivery times) ‚Üí Use t-tests, ANOVA\n",
    "- **Categorical** (payment methods, satisfaction ratings) ‚Üí Use chi-square tests\n",
    "- **Ordinal** (satisfaction scales 1-5) ‚Üí Consider non-parametric tests\n",
    "\n",
    "**2. How many groups are you comparing?**\n",
    "- **Two groups** ‚Üí t-test or Mann-Whitney U\n",
    "- **Multiple groups** ‚Üí ANOVA or Kruskal-Wallis\n",
    "- **Paired data** ‚Üí Paired t-test or Wilcoxon signed-rank\n",
    "\n",
    "**3. Are assumptions met?**\n",
    "- **Yes** ‚Üí Use parametric tests (more powerful)\n",
    "- **No** ‚Üí Use non-parametric tests (more robust)\n",
    "\n",
    "#### Common Business Test Scenarios:\n",
    "\n",
    "| Business Question | Data Type | Groups | Recommended Test |\n",
    "|------------------|-----------|--------|------------------|\n",
    "| \"Do credit card users spend more?\" | Continuous | 2 | Two-sample t-test |\n",
    "| \"Are all states equally satisfied?\" | Continuous | 3+ | ANOVA |\n",
    "| \"Is satisfaction independent of category?\" | Categorical | 2+ | Chi-square test |\n",
    "| \"Did the campaign improve sales?\" | Continuous | 2 (paired) | Paired t-test |\n",
    "| \"Which payment method is most popular?\" | Categorical | 1 | Goodness-of-fit test |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Test Selection Tool\n",
    "def statistical_test_selector():\n",
    "    \"\"\"\n",
    "    Interactive tool to help choose the right statistical test.\n",
    "    \"\"\"\n",
    "    print(\"üß≠ Statistical Test Selection Guide\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    test_matrix = {\n",
    "        \"Comparing Two Groups\": {\n",
    "            \"Continuous Data\": {\n",
    "                \"Independent Samples\": {\n",
    "                    \"Normal + Equal Variance\": \"Independent t-test\",\n",
    "                    \"Normal + Unequal Variance\": \"Welch's t-test\",\n",
    "                    \"Non-normal\": \"Mann-Whitney U test\"\n",
    "                },\n",
    "                \"Paired Samples\": {\n",
    "                    \"Normal Differences\": \"Paired t-test\",\n",
    "                    \"Non-normal Differences\": \"Wilcoxon signed-rank test\"\n",
    "                }\n",
    "            },\n",
    "            \"Categorical Data\": {\n",
    "                \"2x2 Table\": \"Chi-square test of independence\",\n",
    "                \"Fisher's Exact\": \"Small sample sizes (n < 5 in any cell)\"\n",
    "            }\n",
    "        },\n",
    "        \"Comparing Multiple Groups\": {\n",
    "            \"Continuous Data\": {\n",
    "                \"Independent Groups\": {\n",
    "                    \"Normal + Equal Variance\": \"One-way ANOVA\",\n",
    "                    \"Non-normal or Unequal Variance\": \"Kruskal-Wallis test\"\n",
    "                },\n",
    "                \"Repeated Measures\": \"Repeated measures ANOVA\"\n",
    "            },\n",
    "            \"Categorical Data\": {\n",
    "                \"Multiple Categories\": \"Chi-square test of independence\",\n",
    "                \"Goodness of Fit\": \"Chi-square goodness-of-fit\"\n",
    "            }\n",
    "        },\n",
    "        \"Relationship Analysis\": {\n",
    "            \"Two Continuous Variables\": {\n",
    "                \"Linear Relationship\": \"Pearson correlation\",\n",
    "                \"Non-linear/Non-normal\": \"Spearman correlation\"\n",
    "            },\n",
    "            \"Prediction\": {\n",
    "                \"Continuous Outcome\": \"Linear regression\",\n",
    "                \"Binary Outcome\": \"Logistic regression\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for scenario, tests in test_matrix.items():\n",
    "        print(f\"\\nüìä {scenario}\")\n",
    "        print(\"-\" * 30)\n",
    "        _print_test_tree(tests, indent=1)\n",
    "\n",
    "def _print_test_tree(tests, indent=1):\n",
    "    \"\"\"Helper function to print nested test structure.\"\"\"\n",
    "    indent_str = \"  \" * indent\n",
    "    \n",
    "    for key, value in tests.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"{indent_str}üî∏ {key}:\")\n",
    "            _print_test_tree(value, indent + 1)\n",
    "        else:\n",
    "            print(f\"{indent_str}‚úÖ {key}: {value}\")\n",
    "\n",
    "# Display the test selection guide\n",
    "statistical_test_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real Business Application: A/B Testing Framework\n",
    "\n",
    "### Practical Implementation with Olist Data\n",
    "\n",
    "Let's apply our statistical framework to a real business scenario: **A/B testing payment method recommendations**.\n",
    "\n",
    "#### Business Scenario:\n",
    "Olist wants to test whether recommending credit cards vs. allowing free choice affects:\n",
    "1. **Average order value** (AOV)\n",
    "2. **Customer satisfaction** scores\n",
    "3. **Order completion** rates\n",
    "\n",
    "#### Statistical Design:\n",
    "- **Treatment Group**: Customers recommended to use credit cards\n",
    "- **Control Group**: Customers with standard payment options\n",
    "- **Primary Metric**: Average order value (continuous)\n",
    "- **Secondary Metrics**: Satisfaction scores, completion rates\n",
    "\n",
    "#### Success Criteria:\n",
    "- **Statistical**: p < 0.05 with sufficient power\n",
    "- **Business**: Minimum R$ 10 increase in AOV to justify implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B Testing Framework Implementation\n",
    "def ab_testing_framework():\n",
    "    \"\"\"\n",
    "    Demonstrate complete A/B testing framework using Olist data.\n",
    "    \"\"\"\n",
    "    if engine is None:\n",
    "        print(\"‚ùå Database connection required for A/B test simulation\")\n",
    "        return\n",
    "    \n",
    "    print(\"üß™ A/B Testing Framework: Payment Method Recommendation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load broader sample for A/B test simulation\n",
    "    ab_test_query = \"\"\"\n",
    "    SELECT \n",
    "        p.payment_type,\n",
    "        p.payment_value,\n",
    "        r.review_score,\n",
    "        o.order_status,\n",
    "        c.customer_state\n",
    "    FROM \"olist_sales_data_set\".\"olist_order_payments_dataset\" p\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_orders_dataset\" o \n",
    "        ON p.order_id = o.order_id\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_customers_dataset\" c \n",
    "        ON o.customer_id = c.customer_id\n",
    "    LEFT JOIN \"olist_sales_data_set\".\"olist_order_reviews_dataset\" r \n",
    "        ON o.order_id = r.order_id\n",
    "    WHERE p.payment_value > 0\n",
    "        AND p.payment_value < 500\n",
    "        AND o.order_status = 'delivered'\n",
    "    LIMIT 10000\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        ab_data = pd.read_sql(text(ab_test_query), engine)\n",
    "        print(f\"‚úÖ Loaded {len(ab_data):,} records for A/B test simulation\")\n",
    "        \n",
    "        # Simulate A/B test groups\n",
    "        # Control: Current mix of payment methods\n",
    "        # Treatment: Simulate effect of credit card recommendation\n",
    "        \n",
    "        # Assign to groups (simulate randomization)\n",
    "        np.random.seed(42)\n",
    "        ab_data['test_group'] = np.random.choice(['Control', 'Treatment'], len(ab_data))\n",
    "        \n",
    "        # Simulate treatment effect: credit card recommendation increases credit card usage\n",
    "        treatment_mask = ab_data['test_group'] == 'Treatment'\n",
    "        credit_boost = np.random.choice([True, False], \n",
    "                                      size=treatment_mask.sum(), \n",
    "                                      p=[0.3, 0.7])  # 30% more likely to use credit\n",
    "        \n",
    "        # Simulate increased AOV for treatment group using credit cards\n",
    "        ab_data.loc[treatment_mask & (ab_data['payment_type'] == 'credit_card'), 'payment_value'] *= np.random.normal(1.15, 0.05, \n",
    "                                                                                                                       size=((treatment_mask) & (ab_data['payment_type'] == 'credit_card')).sum())\n",
    "        \n",
    "        # Analyze results\n",
    "        print(\"\\nüìä A/B Test Results Analysis\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Primary Metric: Average Order Value\n",
    "        control_aov = ab_data[ab_data['test_group'] == 'Control']['payment_value']\n",
    "        treatment_aov = ab_data[ab_data['test_group'] == 'Treatment']['payment_value']\n",
    "        \n",
    "        # Statistical test\n",
    "        t_stat, p_value = stats.ttest_ind(treatment_aov, control_aov, equal_var=False)\n",
    "        \n",
    "        # Effect size calculation\n",
    "        control_mean = control_aov.mean()\n",
    "        treatment_mean = treatment_aov.mean()\n",
    "        effect_size = treatment_mean - control_mean\n",
    "        effect_pct = (effect_size / control_mean) * 100\n",
    "        \n",
    "        # Confidence interval for difference\n",
    "        pooled_std = np.sqrt(((len(control_aov)-1)*control_aov.var() + (len(treatment_aov)-1)*treatment_aov.var()) / \n",
    "                            (len(control_aov)+len(treatment_aov)-2))\n",
    "        se_diff = pooled_std * np.sqrt(1/len(control_aov) + 1/len(treatment_aov))\n",
    "        ci_95 = stats.t.interval(0.95, len(control_aov)+len(treatment_aov)-2, \n",
    "                                loc=effect_size, scale=se_diff)\n",
    "        \n",
    "        print(f\"\\nüí∞ Primary Metric: Average Order Value\")\n",
    "        print(f\"   Control Group: R$ {control_mean:.2f} (n = {len(control_aov):,})\")\n",
    "        print(f\"   Treatment Group: R$ {treatment_mean:.2f} (n = {len(treatment_aov):,})\")\n",
    "        print(f\"   Difference: R$ {effect_size:.2f} ({effect_pct:+.1f}%)\")\n",
    "        print(f\"   95% CI: R$ {ci_95[0]:.2f} to R$ {ci_95[1]:.2f}\")\n",
    "        print(f\"   Statistical test: t = {t_stat:.3f}, p = {p_value:.4f}\")\n",
    "        \n",
    "        # Decision framework\n",
    "        print(f\"\\nüéØ Decision Framework:\")\n",
    "        \n",
    "        statistical_significant = p_value < 0.05\n",
    "        business_significant = abs(effect_size) >= 10  # R$ 10 minimum threshold\n",
    "        \n",
    "        print(f\"   Statistical Significance: {'‚úÖ Yes' if statistical_significant else '‚ùå No'} (p = {p_value:.4f})\")\n",
    "        print(f\"   Business Significance: {'‚úÖ Yes' if business_significant else '‚ùå No'} (|effect| ‚â• R$ 10)\")\n",
    "        \n",
    "        if statistical_significant and business_significant:\n",
    "            decision = \"üöÄ IMPLEMENT: Strong evidence for business impact\"\n",
    "        elif statistical_significant and not business_significant:\n",
    "            decision = \"‚ö†Ô∏è CAUTION: Statistically significant but small business impact\"\n",
    "        elif not statistical_significant and business_significant:\n",
    "            decision = \"üîÑ EXTEND TEST: Large effect size but need more data\"\n",
    "        else:\n",
    "            decision = \"‚ùå DO NOT IMPLEMENT: No significant effect detected\"\n",
    "        \n",
    "        print(f\"\\nüéØ Recommendation: {decision}\")\n",
    "        \n",
    "        # Power analysis\n",
    "        effect_size_cohen = effect_size / pooled_std\n",
    "        print(f\"\\n‚ö° Statistical Power Analysis:\")\n",
    "        print(f\"   Cohen's d (effect size): {effect_size_cohen:.3f}\")\n",
    "        \n",
    "        if abs(effect_size_cohen) >= 0.8:\n",
    "            print(f\"   Effect size: Large (good for detection)\")\n",
    "        elif abs(effect_size_cohen) >= 0.5:\n",
    "            print(f\"   Effect size: Medium (moderate detection)\")\n",
    "        else:\n",
    "            print(f\"   Effect size: Small (difficult to detect)\")\n",
    "        \n",
    "        return ab_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in A/B test simulation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run A/B testing framework\n",
    "ab_results = ab_testing_framework()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways and Next Steps\n",
    "\n",
    "### What We've Accomplished Today\n",
    "\n",
    "1. **Statistical Framework**: Learned systematic approach to hypothesis testing for business decisions\n",
    "2. **P-Value Interpretation**: Understood what p-values mean and their limitations\n",
    "3. **Confidence Intervals**: Quantified uncertainty in business metrics\n",
    "4. **Assumption Checking**: Validated test requirements with real data\n",
    "5. **Test Selection**: Chose appropriate statistical tests for business scenarios\n",
    "6. **A/B Testing**: Applied complete framework to real e-commerce decisions\n",
    "\n",
    "### Critical Business Insights\n",
    "\n",
    "**üéØ Statistical vs Business Significance**:\n",
    "- Small differences can be statistically significant with large samples\n",
    "- Always consider practical business impact alongside statistical evidence\n",
    "- Set business significance thresholds before testing\n",
    "\n",
    "**üîç Evidence-Based Decision Making**:\n",
    "- Use statistical tests to validate EDA discoveries\n",
    "- Quantify uncertainty with confidence intervals\n",
    "- Make decisions based on both statistical and business criteria\n",
    "\n",
    "**‚ö†Ô∏è Common Pitfalls to Avoid**:\n",
    "- Don't ignore test assumptions\n",
    "- Don't confuse correlation with causation\n",
    "- Don't make business decisions on p-values alone\n",
    "- Don't forget about multiple testing corrections\n",
    "\n",
    "### Preparing for Next Sessions\n",
    "\n",
    "**Wednesday Part 2**: We'll dive deep into **specific statistical tests**:\n",
    "- T-tests for comparing customer segments\n",
    "- Chi-square tests for categorical relationships\n",
    "- ANOVA for multiple group comparisons\n",
    "- Real business applications with Olist data\n",
    "\n",
    "**Wednesday Part 3**: **Practical business applications**:\n",
    "- Regional performance analysis\n",
    "- Customer satisfaction testing\n",
    "- Payment method optimization\n",
    "- Delivery performance validation\n",
    "\n",
    "### Practice Opportunity\n",
    "\n",
    "Before our next session, consider these questions about Olist data:\n",
    "1. Are customers in different states equally satisfied?\n",
    "2. Do different product categories have different satisfaction rates?\n",
    "3. Is delivery performance consistent across regions?\n",
    "4. Are payment preferences independent of order value?\n",
    "\n",
    "We'll answer these questions with statistical rigor in our next sessions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Summary and Preview\n",
    "def session_summary():\n",
    "    \"\"\"\n",
    "    Summarize key concepts and preview next session.\n",
    "    \"\"\"\n",
    "    print(\"üìã Week 8 Part 1 Summary: Statistical Foundations\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    concepts_learned = {\n",
    "        \"Hypothesis Testing Framework\": \"Systematic approach to business validation\",\n",
    "        \"P-Value Interpretation\": \"Evidence against null hypothesis, not effect size\",\n",
    "        \"Confidence Intervals\": \"Quantify uncertainty in business metrics\",\n",
    "        \"Statistical Assumptions\": \"Prerequisites for valid test results\",\n",
    "        \"Test Selection\": \"Choose appropriate tests for business scenarios\",\n",
    "        \"A/B Testing\": \"Complete framework for business experiments\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüìö Key Concepts Mastered:\")\n",
    "    for concept, description in concepts_learned.items():\n",
    "        print(f\"   ‚úÖ {concept}: {description}\")\n",
    "    \n",
    "    next_topics = [\n",
    "        \"T-tests for customer segment comparison\",\n",
    "        \"Chi-square tests for categorical relationships\",\n",
    "        \"ANOVA for multiple group analysis\",\n",
    "        \"Real Olist business scenario testing\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîú Next Session Preview (Part 2):\")\n",
    "    for i, topic in enumerate(next_topics, 1):\n",
    "        print(f\"   {i}. {topic}\")\n",
    "    \n",
    "    print(\"\\nüí° Remember:\")\n",
    "    print(\"   ‚Ä¢ Statistical significance ‚â† Business significance\")\n",
    "    print(\"   ‚Ä¢ Always check assumptions before testing\")\n",
    "    print(\"   ‚Ä¢ Use confidence intervals to quantify uncertainty\")\n",
    "    print(\"   ‚Ä¢ Make decisions based on both statistical and business criteria\")\n",
    "    \n",
    "    print(\"\\nüéØ Ready to apply these concepts to specific statistical tests!\")\n",
    "\n",
    "# Display session summary\n",
    "session_summary()\n",
    "\n",
    "# Clean up database connection\n",
    "if engine:\n",
    "    engine.dispose()\n",
    "    print(\"\\nüîí Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
