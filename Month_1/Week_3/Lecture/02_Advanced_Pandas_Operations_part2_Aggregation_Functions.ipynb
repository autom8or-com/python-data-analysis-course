{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Pandas Operations - Part 2: Aggregation Functions\n",
        "\n",
        "## Week 3, Day 2 (Thursday) - April 24th, 2025\n",
        "\n",
        "### Overview\n",
        "This session builds on the GroupBy operations covered in Part 1 and dives deeper into the various aggregation functions available in Pandas. Aggregation functions allow you to summarize data in meaningful ways, similar to SQL's aggregate functions but with more flexibility and power.\n",
        "\n",
        "### Learning Objectives\n",
        "- Master a wide range of built-in aggregation functions in Pandas\n",
        "- Create and apply custom aggregation functions\n",
        "- Use multiple aggregation functions simultaneously\n",
        "- Apply aggregations with and without grouping\n",
        "- Understand the relationship between Pandas aggregations and SQL aggregations\n",
        "\n",
        "### Prerequisites\n",
        "- Python fundamentals (Week 1)\n",
        "- Pandas Fundamentals I & II (Week 2, Day 2 & Week 3, Day 1)\n",
        "- GroupBy operations (Week 3, Day 2, Part 1)\n",
        "- SQL knowledge (prior to course)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction to Aggregation Functions\n",
        "\n",
        "Aggregation functions compute summary statistics over a set of values. While we briefly covered some aggregation methods in the GroupBy lesson, here we'll explore them more extensively. Let's start with a dataset to work with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a sample sales dataset (more detailed than the one in Part 1)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "n = 100  # Number of records\n",
        "\n",
        "# Generate dates for Q1 2025\n",
        "dates = pd.date_range('2025-01-01', '2025-03-31', periods=n)\n",
        "\n",
        "# Create dictionary of data\n",
        "data = {\n",
        "    'transaction_id': [f'T{i:04d}' for i in range(1, n+1)],\n",
        "    'date': dates,\n",
        "    'customer_id': np.random.choice([f'C{i:03d}' for i in range(1, 21)], size=n),  # 20 customers\n",
        "    'product_id': np.random.choice([f'P{i:03d}' for i in range(1, 51)], size=n),   # 50 products\n",
        "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Sports'], \n",
        "                                         size=n, p=[0.3, 0.25, 0.2, 0.15, 0.1]),  # Weighted categories\n",
        "    'store_id': np.random.choice(['S01', 'S02', 'S03', 'S04'], size=n),\n",
        "    'region': np.random.choice(['North', 'South', 'East', 'West'], size=n),\n",
        "    'quantity': np.random.randint(1, 10, size=n),\n",
        "    'unit_price': np.random.uniform(10, 500, size=n).round(2),\n",
        "    'discount_pct': np.random.choice([0, 5, 10, 15, 20, 25], size=n),\n",
        "    'payment_method': np.random.choice(['Credit Card', 'Debit Card', 'Cash', 'Mobile Payment'], size=n),\n",
        "    'is_online': np.random.choice([True, False], size=n, p=[0.6, 0.4]),  # 60% online\n",
        "    'order_status': np.random.choice(['Completed', 'Returned', 'Canceled'], size=n, p=[0.85, 0.1, 0.05]),\n",
        "    'customer_rating': np.random.choice([1, 2, 3, 4, 5, None], size=n, p=[0.05, 0.1, 0.15, 0.3, 0.3, 0.1])\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "sales_df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate derived columns\n",
        "sales_df['discount_amount'] = (sales_df['unit_price'] * sales_df['discount_pct'] / 100).round(2)\n",
        "sales_df['net_price'] = (sales_df['unit_price'] - sales_df['discount_amount']).round(2)\n",
        "sales_df['total_amount'] = (sales_df['quantity'] * sales_df['net_price']).round(2)\n",
        "\n",
        "# Add some additional time-related columns\n",
        "sales_df['month'] = sales_df['date'].dt.month_name()\n",
        "sales_df['day_of_week'] = sales_df['date'].dt.day_name()\n",
        "sales_df['week'] = sales_df['date'].dt.isocalendar().week\n",
        "sales_df['is_weekend'] = sales_df['day_of_week'].isin(['Saturday', 'Sunday'])\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Sample Sales DataFrame:\")\n",
        "print(sales_df.head())\n",
        "\n",
        "# Display summary information\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(f\"Shape: {sales_df.shape}\")\n",
        "print(f\"Columns: {sales_df.columns.tolist()}\")\n",
        "print(\"\\nColumn Data Types:\")\n",
        "print(sales_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Aggregation Functions\n",
        "\n",
        "Let's start with the basic aggregation functions built into Pandas. These are similar to SQL's aggregate functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single column aggregations\n",
        "print(\"Basic aggregations on unit_price:\")\n",
        "print(f\"Count: {sales_df['unit_price'].count()}\")\n",
        "print(f\"Sum: ${sales_df['unit_price'].sum():.2f}\")\n",
        "print(f\"Mean: ${sales_df['unit_price'].mean():.2f}\")\n",
        "print(f\"Median: ${sales_df['unit_price'].median():.2f}\")\n",
        "print(f\"Standard Deviation: ${sales_df['unit_price'].std():.2f}\")\n",
        "print(f\"Minimum: ${sales_df['unit_price'].min():.2f}\")\n",
        "print(f\"Maximum: ${sales_df['unit_price'].max():.2f}\")\n",
        "\n",
        "# SQL equivalents:\n",
        "# SELECT \n",
        "#     COUNT(unit_price),\n",
        "#     SUM(unit_price),\n",
        "#     AVG(unit_price),\n",
        "#     -- No direct median in standard SQL\n",
        "#     STDDEV(unit_price),\n",
        "#     MIN(unit_price),\n",
        "#     MAX(unit_price)\n",
        "# FROM sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple column aggregations with .agg()\n",
        "basic_aggs = sales_df.agg({\n",
        "    'unit_price': ['count', 'sum', 'mean', 'median', 'std', 'min', 'max'],\n",
        "    'quantity': ['count', 'sum', 'mean', 'median', 'std', 'min', 'max'],\n",
        "    'total_amount': ['count', 'sum', 'mean', 'median', 'std', 'min', 'max']\n",
        "})\n",
        "\n",
        "print(\"Multiple column aggregations:\")\n",
        "print(basic_aggs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate summary statistics for all numeric columns\n",
        "summary_stats = sales_df.describe()\n",
        "print(\"Summary statistics for numeric columns:\")\n",
        "print(summary_stats)\n",
        "\n",
        "# Calculate summary statistics for categorical columns\n",
        "cat_summary = sales_df.describe(include=['object', 'bool'])\n",
        "print(\"\\nSummary statistics for categorical columns:\")\n",
        "print(cat_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Advanced Aggregation Functions\n",
        "\n",
        "Pandas provides many advanced aggregation functions beyond the basic ones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate percentiles\n",
        "percentiles = sales_df['total_amount'].quantile([0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n",
        "print(\"Percentiles of total_amount:\")\n",
        "print(percentiles)\n",
        "\n",
        "# Interquartile Range (IQR)\n",
        "q1 = sales_df['total_amount'].quantile(0.25)\n",
        "q3 = sales_df['total_amount'].quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "print(f\"\\nInterquartile Range (IQR) for total_amount: ${iqr:.2f}\")\n",
        "\n",
        "# Mode (most frequent value)\n",
        "mode_product = sales_df['product_category'].mode()[0]\n",
        "mode_rating = sales_df['customer_rating'].mode()[0]\n",
        "print(f\"\\nMost common product category: {mode_product}\")\n",
        "print(f\"Most common customer rating: {mode_rating}\")\n",
        "\n",
        "# Variance\n",
        "price_variance = sales_df['unit_price'].var()\n",
        "print(f\"\\nVariance of unit_price: {price_variance:.2f}\")\n",
        "\n",
        "# Skewness and Kurtosis\n",
        "skew = sales_df['total_amount'].skew()\n",
        "kurt = sales_df['total_amount'].kurt()\n",
        "print(f\"\\nSkewness of total_amount: {skew:.4f}\")\n",
        "print(f\"Kurtosis of total_amount: {kurt:.4f}\")\n",
        "\n",
        "# Plot a histogram to visualize distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sales_df['total_amount'], bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(sales_df['total_amount'].mean(), color='red', linestyle='dashed', linewidth=1, label=f'Mean: ${sales_df[\"total_amount\"].mean():.2f}')\n",
        "plt.axvline(sales_df['total_amount'].median(), color='green', linestyle='dashed', linewidth=1, label=f'Median: ${sales_df[\"total_amount\"].median():.2f}')\n",
        "plt.title('Distribution of Total Sales Amount')\n",
        "plt.xlabel('Total Amount ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculating cumulative statistics\n",
        "sales_df_sorted = sales_df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# Cumulative sum of sales over time\n",
        "sales_df_sorted['cumulative_sales'] = sales_df_sorted['total_amount'].cumsum()\n",
        "\n",
        "# Cumulative average price\n",
        "sales_df_sorted['cumulative_avg_price'] = sales_df_sorted['unit_price'].expanding().mean().round(2)\n",
        "\n",
        "# Display the data\n",
        "print(\"Cumulative statistics:\")\n",
        "cumulative_cols = ['date', 'total_amount', 'cumulative_sales', 'unit_price', 'cumulative_avg_price']\n",
        "print(sales_df_sorted[cumulative_cols].head(10))\n",
        "\n",
        "# Visualize cumulative sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(sales_df_sorted['date'], sales_df_sorted['cumulative_sales'], marker='', linewidth=2)\n",
        "plt.title('Cumulative Sales Over Time (Q1 2025)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Cumulative Sales ($)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Aggregating with GroupBy\n",
        "\n",
        "Now, let's combine what we learned in Part 1 (GroupBy) with more advanced aggregation techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by product category and calculate multiple statistics\n",
        "category_stats = sales_df.groupby('product_category').agg({\n",
        "    'transaction_id': 'count',            # Number of transactions\n",
        "    'quantity': 'sum',                    # Total quantity sold\n",
        "    'total_amount': ['sum', 'mean', 'median', 'std', 'min', 'max'],  # Various price stats\n",
        "    'discount_pct': ['mean', 'median'],   # Average discount\n",
        "    'customer_rating': ['mean', 'count', 'median']  # Rating stats\n",
        "})\n",
        "\n",
        "# Clean up column names\n",
        "category_stats.columns = ['_'.join(col).strip() for col in category_stats.columns.values]\n",
        "category_stats = category_stats.rename(columns={\n",
        "    'transaction_id_count': 'num_transactions',\n",
        "    'quantity_sum': 'total_quantity',\n",
        "    'total_amount_sum': 'total_sales',\n",
        "    'total_amount_mean': 'avg_transaction_value',\n",
        "    'total_amount_median': 'median_transaction_value',\n",
        "    'discount_pct_mean': 'avg_discount_pct',\n",
        "    'customer_rating_mean': 'avg_rating',\n",
        "    'customer_rating_count': 'num_ratings'\n",
        "})\n",
        "\n",
        "print(\"Detailed statistics by product category:\")\n",
        "print(category_stats)\n",
        "\n",
        "# Visualize sales by category\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(category_stats.index, category_stats['total_sales'])\n",
        "plt.title('Total Sales by Product Category')\n",
        "plt.xlabel('Product Category')\n",
        "plt.ylabel('Total Sales ($)')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monthly sales trends\n",
        "monthly_sales = sales_df.groupby('month').agg({\n",
        "    'transaction_id': 'count',\n",
        "    'total_amount': 'sum',\n",
        "    'customer_rating': ['mean', 'count']\n",
        "})\n",
        "\n",
        "# Clean up column names\n",
        "monthly_sales.columns = ['_'.join(col).strip() for col in monthly_sales.columns.values]\n",
        "monthly_sales = monthly_sales.rename(columns={\n",
        "    'transaction_id_count': 'num_transactions',\n",
        "    'total_amount_sum': 'total_sales',\n",
        "    'customer_rating_mean': 'avg_rating',\n",
        "    'customer_rating_count': 'num_ratings'\n",
        "})\n",
        "\n",
        "# Reorder by month\n",
        "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
        "               'July', 'August', 'September', 'October', 'November', 'December']\n",
        "monthly_sales = monthly_sales.reindex(month_order)\n",
        "\n",
        "print(\"Monthly sales statistics:\")\n",
        "print(monthly_sales)\n",
        "\n",
        "# Visualize monthly trends\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot total sales on the first y-axis\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Month')\n",
        "ax1.set_ylabel('Total Sales ($)', color=color)\n",
        "ax1.bar(monthly_sales.index, monthly_sales['total_sales'], color=color, alpha=0.7)\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# Create a second y-axis for average rating\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Average Rating', color=color)\n",
        "ax2.plot(monthly_sales.index, monthly_sales['avg_rating'], color=color, marker='o', linewidth=2)\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.set_ylim(1, 5)  # Set y-axis limits for ratings\n",
        "\n",
        "plt.title('Monthly Sales and Average Customer Rating')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Custom Aggregation Functions\n",
        "\n",
        "While Pandas provides many built-in aggregation functions, you can also define your own custom functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define custom aggregation functions\n",
        "def range_func(x):\n",
        "    \"\"\"Calculate the range (max - min)\"\"\"\n",
        "    return x.max() - x.min()\n",
        "\n",
        "def pct_change_func(x):\n",
        "    \"\"\"Calculate the percentage change from first to last value\"\"\"\n",
        "    if len(x) > 1 and x.iloc[0] != 0:\n",
        "        return ((x.iloc[-1] - x.iloc[0]) / x.iloc[0] * 100).round(2)\n",
        "    return 0\n",
        "\n",
        "def discount_savings(x):\n",
        "    \"\"\"Calculate total savings from discounts\"\"\"\n",
        "    return (x * sales_df.loc[x.index, 'quantity']).sum().round(2)\n",
        "\n",
        "def rating_distribution(x):\n",
        "    \"\"\"Calculate the distribution of ratings as a dictionary\"\"\"\n",
        "    # Remove NaN values\n",
        "    x = x.dropna()\n",
        "    if len(x) == 0:\n",
        "        return {}\n",
        "    # Count occurrences of each rating\n",
        "    counts = x.value_counts().to_dict()\n",
        "    # Convert to percentages\n",
        "    total = sum(counts.values())\n",
        "    return {f\"{k}\": round(v/total*100, 1) for k, v in counts.items()}\n",
        "\n",
        "# Apply custom functions to each product category\n",
        "custom_stats = sales_df.groupby('product_category').agg({\n",
        "    'unit_price': [range_func, 'mean'],\n",
        "    'discount_amount': discount_savings,\n",
        "    'customer_rating': rating_distribution\n",
        "})\n",
        "\n",
        "# Clean up column names\n",
        "custom_stats.columns = ['_'.join(col).strip() for col in custom_stats.columns.values]\n",
        "custom_stats = custom_stats.rename(columns={\n",
        "    'unit_price_range_func': 'price_range',\n",
        "    'unit_price_mean': 'avg_price',\n",
        "    'discount_amount_discount_savings': 'total_discount_savings',\n",
        "    'customer_rating_rating_distribution': 'rating_distribution'\n",
        "})\n",
        "\n",
        "print(\"Custom aggregation results:\")\n",
        "print(custom_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time-based custom aggregations\n",
        "weekly_data = sales_df.sort_values('date').set_index('date')\n",
        "weekly_agg = weekly_data.resample('W').agg({\n",
        "    'transaction_id': 'count',\n",
        "    'total_amount': ['sum', 'mean', pct_change_func],\n",
        "    'customer_rating': ['mean', 'count']\n",
        "})\n",
        "\n",
        "# Clean up column names\n",
        "weekly_agg.columns = ['_'.join(col).strip() for col in weekly_agg.columns.values]\n",
        "weekly_agg = weekly_agg.rename(columns={\n",
        "    'transaction_id_count': 'num_transactions',\n",
        "    'total_amount_sum': 'total_sales',\n",
        "    'total_amount_mean': 'avg_transaction',\n",
        "    'total_amount_pct_change_func': 'weekly_pct_change',\n",
        "    'customer_rating_mean': 'avg_rating',\n",
        "    'customer_rating_count': 'num_ratings'\n",
        "})\n",
        "\n",
        "print(\"Weekly aggregations with custom functions:\")\n",
        "print(weekly_agg)\n",
        "\n",
        "# Plot weekly sales trend\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(weekly_agg.index, weekly_agg['total_sales'], marker='o', linewidth=2)\n",
        "plt.title('Weekly Sales Trend (Q1 2025)')\n",
        "plt.xlabel('Week Ending')\n",
        "plt.ylabel('Total Sales ($)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced GroupBy Aggregations\n",
        "\n",
        "Let's explore more complex aggregation patterns with GroupBy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nested grouping: region → store → product_category\n",
        "nested_agg = sales_df.groupby(['region', 'store_id', 'product_category']).agg({\n",
        "    'transaction_id': 'count',\n",
        "    'total_amount': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Rename columns\n",
        "nested_agg = nested_agg.rename(columns={\n",
        "    'transaction_id': 'num_transactions',\n",
        "    'total_amount': 'total_sales'\n",
        "})\n",
        "\n",
        "print(\"Nested grouping aggregation:\")\n",
        "print(nested_agg.head(15))\n",
        "\n",
        "# Create a pivot table for easier analysis\n",
        "pivot_region_store = pd.pivot_table(\n",
        "    nested_agg, \n",
        "    values='total_sales',\n",
        "    index=['region', 'store_id'],\n",
        "    columns='product_category',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "print(\"\\nPivot table of sales by region, store, and category:\")\n",
        "print(pivot_region_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyzing sales by online vs. in-store and payment method\n",
        "channel_payment_agg = sales_df.groupby(['is_online', 'payment_method']).agg({\n",
        "    'transaction_id': 'count',\n",
        "    'total_amount': ['sum', 'mean'],\n",
        "    'customer_rating': ['mean', 'count']\n",
        "}).reset_index()\n",
        "\n",
        "# Clean up column names\n",
        "channel_payment_agg.columns = ['_'.join(col).strip() for col in channel_payment_agg.columns.values]\n",
        "channel_payment_agg = channel_payment_agg.rename(columns={\n",
        "    'is_online_': 'is_online',\n",
        "    'payment_method_': 'payment_method',\n",
        "    'transaction_id_count': 'num_transactions',\n",
        "    'total_amount_sum': 'total_sales',\n",
        "    'total_amount_mean': 'avg_transaction',\n",
        "    'customer_rating_mean': 'avg_rating',\n",
        "    'customer_rating_count': 'num_ratings'\n",
        "})\n",
        "\n",
        "print(\"Sales by channel and payment method:\")\n",
        "print(channel_payment_agg)\n",
        "\n",
        "# Create a grouped bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='payment_method', y='total_sales', hue='is_online', data=channel_payment_agg)\n",
        "plt.title('Sales by Payment Method and Channel')\n",
        "plt.xlabel('Payment Method')\n",
        "plt.ylabel('Total Sales ($)')\n",
        "plt.legend(title='Is Online')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Named Aggregations\n",
        "\n",
        "Pandas 0.25+ introduced a more readable way to perform named aggregations, which we touched on in Part 1. Let's explore this further:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Named aggregations\n",
        "named_aggs = sales_df.groupby('product_category').agg(\n",
        "    num_transactions=('transaction_id', 'count'),\n",
        "    total_sales=('total_amount', 'sum'),\n",
        "    avg_transaction=('total_amount', 'mean'),\n",
        "    max_transaction=('total_amount', 'max'),\n",
        "    total_quantity=('quantity', 'sum'),\n",
        "    avg_rating=('customer_rating', 'mean'),\n",
        "    avg_discount=('discount_pct', 'mean')\n",
        ")\n",
        "\n",
        "print(\"Named aggregations:\")\n",
        "print(named_aggs)\n",
        "\n",
        "# Calculate a derived metric: average revenue per unit\n",
        "named_aggs['revenue_per_unit'] = (named_aggs['total_sales'] / named_aggs['total_quantity']).round(2)\n",
        "\n",
        "# Calculate another derived metric: discount impact ratio\n",
        "named_aggs['discount_impact'] = (named_aggs['avg_discount'] / named_aggs['avg_transaction'] * 100).round(2)\n",
        "\n",
        "print(\"\\nWith derived metrics:\")\n",
        "print(named_aggs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mixed named and callable aggregations\n",
        "def top_products(x):\n",
        "    \"\"\"Returns the top 3 most common product IDs in a group\"\"\"\n",
        "    return x.value_counts().nlargest(3).index.tolist()\n",
        "\n",
        "mixed_aggs = sales_df.groupby('product_category').agg(\n",
        "    num_transactions=('transaction_id', 'count'),\n",
        "    total_sales=('total_amount', 'sum'),\n",
        "    price_range=('unit_price', lambda x: x.max() - x.min()),\n",
        "    popular_products=('product_id', top_products),\n",
        "    rating_summary=('customer_rating', rating_distribution)\n",
        ")\n",
        "\n",
        "print(\"Mixed named and callable aggregations:\")\n",
        "print(mixed_aggs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Advanced Statistical Aggregations\n",
        "\n",
        "Let's perform some more advanced statistical aggregations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis between numeric variables\n",
        "numeric_cols = ['quantity', 'unit_price', 'discount_pct', 'discount_amount', \n",
        "                'net_price', 'total_amount', 'customer_rating']\n",
        "correlation_matrix = sales_df[numeric_cols].corr()\n",
        "\n",
        "print(\"Correlation matrix:\")\n",
        "print(correlation_matrix.round(2))\n",
        "\n",
        "# Visualize the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
        "plt.title('Correlation Matrix of Numeric Variables')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests and aggregations\n",
        "# Compare online vs. in-store sales\n",
        "channel_comparison = sales_df.groupby('is_online').agg(\n",
        "    num_transactions=('transaction_id', 'count'),\n",
        "    total_sales=('total_amount', 'sum'),\n",
        "    avg_transaction=('total_amount', 'mean'),\n",
        "    std_transaction=('total_amount', 'std'),\n",
        "    min_transaction=('total_amount', 'min'),\n",
        "    max_transaction=('total_amount', 'max'),\n",
        "    avg_rating=('customer_rating', 'mean')\n",
        ")\n",
        "\n",
        "print(\"Comparison of online vs. in-store sales:\")\n",
        "print(channel_comparison)\n",
        "\n",
        "# Perform a t-test to see if online transaction values are different from in-store\n",
        "from scipy import stats\n",
        "\n",
        "online_sales = sales_df[sales_df['is_online']]['total_amount']\n",
        "instore_sales = sales_df[~sales_df['is_online']]['total_amount']\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(online_sales, instore_sales, equal_var=False)\n",
        "print(f\"\\nT-test for difference in transaction amounts between online and in-store:\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "print(f\"Statistically significant difference: {p_value < 0.05}\")\n",
        "\n",
        "# Visualize the distributions\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=sales_df, x='total_amount', hue='is_online', bins=20, element='step', common_norm=False, stat='density')\n",
        "plt.axvline(online_sales.mean(), color='blue', linestyle='dashed', linewidth=1, label=f'Online Mean: ${online_sales.mean():.2f}')\n",
        "plt.axvline(instore_sales.mean(), color='orange', linestyle='dashed', linewidth=1, label=f'In-store Mean: ${instore_sales.mean():.2f}')\n",
        "plt.title('Distribution of Transaction Amounts by Channel')\n",
        "plt.xlabel('Transaction Amount ($)')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. SQL to Pandas Aggregation Translation Guide\n",
        "\n",
        "Let's expand our SQL-to-Pandas translation guide with aggregation-specific operations:\n",
        "\n",
        "| SQL Aggregation | Pandas Equivalent |\n",
        "|-----------------|-------------------|\n",
        "| `COUNT(*)` | `df.shape[0]` or `len(df)` |\n",
        "| `COUNT(column)` | `df['column'].count()` |\n",
        "| `SUM(column)` | `df['column'].sum()` |\n",
        "| `AVG(column)` | `df['column'].mean()` |\n",
        "| `MIN(column)` | `df['column'].min()` |\n",
        "| `MAX(column)` | `df['column'].max()` |\n",
        "| `STDDEV(column)` | `df['column'].std()` |\n",
        "| `VAR(column)` | `df['column'].var()` |\n",
        "| No direct equivalent | `df['column'].median()` |\n",
        "| No direct equivalent | `df['column'].quantile(0.25)` |\n",
        "| No direct equivalent | `df['column'].mode()[0]` |\n",
        "| `GROUP BY col1, col2` | `df.groupby(['col1', 'col2'])` |\n",
        "| `SELECT col1, SUM(col2) FROM table GROUP BY col1` | `df.groupby('col1')['col2'].sum()` |\n",
        "| `SELECT col1, AVG(col2), MAX(col3) FROM table GROUP BY col1` | `df.groupby('col1').agg({'col2': 'mean', 'col3': 'max'})` |\n",
        "| `HAVING COUNT(*) > 10` | `df.groupby('col1').filter(lambda x: len(x) > 10)` |\n",
        "| `ORDER BY SUM(col2) DESC` | `df.groupby('col1')['col2'].sum().sort_values(ascending=False)` |\n",
        "| window function: `SUM(col2) OVER (PARTITION BY col1)` | `df.groupby('col1')['col2'].transform('sum')` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Practice Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1: Basic Aggregation\n",
        "For each payment method in the `sales_df` DataFrame, calculate the total sales, average transaction value, number of transactions, and average customer rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Custom Aggregation Function\n",
        "Create a custom aggregation function that calculates the percentage of high-value transactions (over $500) for each product category. Then apply this function in a groupby operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Multiple Aggregations\n",
        "Group the sales data by both day of the week and is_online status. Calculate the total sales, number of transactions, and average transaction value for each group. Then create a visualization that compares online vs. in-store sales for each day of the week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4: Statistical Aggregation\n",
        "For each region, calculate the following statistics for transaction amounts: mean, median, standard deviation, interquartile range (IQR), and coefficient of variation (CV = standard deviation / mean). Which region has the most consistent transaction values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5: SQL to Pandas Translation\n",
        "Translate the following SQL query to Pandas code using aggregation functions:\n",
        "```sql\n",
        "SELECT \n",
        "    CASE \n",
        "        WHEN unit_price < 100 THEN 'Low'\n",
        "        WHEN unit_price BETWEEN 100 AND 250 THEN 'Medium'\n",
        "        ELSE 'High'\n",
        "    END as price_category,\n",
        "    COUNT(*) as num_transactions,\n",
        "    SUM(total_amount) as total_sales,\n",
        "    AVG(customer_rating) as avg_rating,\n",
        "    SUM(CASE WHEN is_online = true THEN 1 ELSE 0 END) as online_count,\n",
        "    SUM(CASE WHEN is_online = false THEN 1 ELSE 0 END) as instore_count\n",
        "FROM sales\n",
        "GROUP BY price_category\n",
        "ORDER BY total_sales DESC\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "In the next part of today's session, we'll explore:\n",
        "- Part 3: Pivot tables and cross-tabulations\n",
        "\n",
        "Continue to Part 3: Pivot Tables and Cross-Tabulations when you're ready to proceed."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
