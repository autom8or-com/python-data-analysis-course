{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Fundamentals I - Part 2: Basic DataFrame Operations\n",
    "\n",
    "## Week 2, Day 2 (Thursday) - April 17th, 2025\n",
    "\n",
    "### Overview\n",
    "This is the second part of our introduction to Pandas, focusing on basic operations for exploring and manipulating DataFrames. We'll learn the equivalent Pandas operations for common SQL tasks.\n",
    "\n",
    "### Learning Objectives\n",
    "- Inspect and understand DataFrame structure\n",
    "- Access and manipulate DataFrame elements\n",
    "- Handle missing data\n",
    "- Perform basic column operations\n",
    "\n",
    "### Prerequisites\n",
    "- Pandas Fundamentals I - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame to work with\n",
    "data = {\n",
    "    'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "    'product_name': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'category': ['Electronics', 'Electronics', 'Electronics', 'Accessories', 'Electronics'],\n",
    "    'price': [1200, 800, 450, 150, 300],\n",
    "    'stock_quantity': [15, 25, 0, 30, 10],\n",
    "    'rating': [4.5, 4.8, 4.2, 4.6, np.nan]  # Note the missing value (np.nan)\n",
    "}\n",
    "\n",
    "products_df = pd.DataFrame(data)\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DataFrame Inspection\n",
    "\n",
    "Before diving into data analysis, it's important to inspect and understand your data. Pandas provides several methods for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first n rows (default is 5)\n",
    "print(\"First 3 rows:\")\n",
    "print(products_df.head(3))\n",
    "\n",
    "# View the last n rows (default is 5)\n",
    "print(\"\\nLast 2 rows:\")\n",
    "print(products_df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the DataFrame\n",
    "print(\"DataFrame info:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info()` method provides key information about the DataFrame:\n",
    "- The number of rows and columns\n",
    "- The column names and data types\n",
    "- Non-null values for each column\n",
    "- Memory usage\n",
    "\n",
    "This is similar to getting table schema information in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for numeric columns\n",
    "print(\"Summary statistics:\")\n",
    "print(products_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` method provides descriptive statistics for numeric columns:\n",
    "- count: number of non-missing values\n",
    "- mean, std (standard deviation): measures of central tendency and dispersion\n",
    "- min, 25%, 50% (median), 75%, max: percentiles\n",
    "\n",
    "This is similar to aggregate functions in SQL like COUNT(), AVG(), MIN(), MAX(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics for categorical columns\n",
    "print(\"Category counts:\")\n",
    "print(products_df['category'].value_counts())\n",
    "\n",
    "# You can also use describe() with include/exclude parameters\n",
    "print(\"\\nDescribe categorical columns:\")\n",
    "print(products_df.describe(include=['object']))  # 'object' is pandas' string type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional inspection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "print(\"Column names:\", products_df.columns.tolist())\n",
    "\n",
    "# Row index\n",
    "print(\"\\nRow index:\", products_df.index.tolist())\n",
    "\n",
    "# DataFrame dimensions (rows, columns)\n",
    "print(\"\\nDataFrame shape:\", products_df.shape)\n",
    "\n",
    "# Unique values in a column\n",
    "print(\"\\nUnique categories:\", products_df['category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accessing Columns and Rows\n",
    "\n",
    "Now let's look at different ways to access data within a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a single column (returns a Series)\n",
    "prices = products_df['price']\n",
    "print(\"Prices:\\n\", prices)\n",
    "print(\"Type:\", type(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative column access using dot notation\n",
    "# Note: This only works for column names that could be valid Python variable names\n",
    "# and don't conflict with DataFrame method names\n",
    "prices_alt = products_df.price\n",
    "print(\"Prices (dot notation):\\n\", prices_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing multiple columns (returns a DataFrame)\n",
    "product_info = products_df[['product_name', 'price', 'rating']]\n",
    "print(\"Product info:\\n\", product_info)\n",
    "print(\"Type:\", type(product_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a row by position using iloc\n",
    "# iloc uses integer-based indexing [row, column]\n",
    "first_row = products_df.iloc[0]\n",
    "print(\"First row:\\n\", first_row)\n",
    "print(\"Type:\", type(first_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing multiple rows with iloc\n",
    "first_three_rows = products_df.iloc[0:3]\n",
    "print(\"First three rows:\\n\", first_three_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing specific rows and columns with iloc\n",
    "# iloc[row_selector, column_selector]\n",
    "subset = products_df.iloc[1:4, [0, 1, 3]]  # Rows 1-3, columns 0, 1, and 3\n",
    "print(\"Subset of rows and columns:\\n\", subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing rows and columns by label using loc\n",
    "# loc uses label-based indexing [row_label, column_label]\n",
    "# Since our index is numeric (0-4), it looks similar to iloc in this case\n",
    "second_row = products_df.loc[1, ['product_id', 'product_name', 'price']]\n",
    "print(\"Second row selected fields:\\n\", second_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label-based indexing with custom index\n",
    "\n",
    "Let's set the `product_id` as the index to see how label-based indexing works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set product_id as index\n",
    "products_indexed = products_df.set_index('product_id')\n",
    "print(products_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can access rows by product_id\n",
    "laptop_row = products_indexed.loc['P001']\n",
    "print(\"Laptop details:\\n\", laptop_row)\n",
    "\n",
    "# Get specific fields for specific products\n",
    "headphones_info = products_indexed.loc['P004', ['price', 'stock_quantity']]\n",
    "print(\"\\nHeadphones price and stock:\\n\", headphones_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL equivalent for row and column selection\n",
    "\n",
    "In SQL, selecting specific columns and rows would look like:\n",
    "\n",
    "```sql\n",
    "SELECT product_name, price, rating\n",
    "FROM products\n",
    "WHERE product_id = 'P001';\n",
    "```\n",
    "\n",
    "In Pandas, this is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL to Pandas translation\n",
    "result = products_df.loc[products_df['product_id'] == 'P001', ['product_name', 'price', 'rating']]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Types and Conversions\n",
    "\n",
    "Let's look at data types in Pandas and how to convert between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(products_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common pandas data types include:\n",
    "- `object`: String or mixed types (similar to VARCHAR in SQL)\n",
    "- `int64`: Integer (similar to INT in SQL)\n",
    "- `float64`: Floating-point (similar to FLOAT or DOUBLE in SQL)\n",
    "- `bool`: Boolean (similar to BOOLEAN in SQL)\n",
    "- `datetime64`: Date and time (similar to DATE, DATETIME in SQL)\n",
    "- `category`: Categorical data (similar to ENUM in SQL, but more powerful)\n",
    "\n",
    "Let's convert some columns to different types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert category to categorical type (more memory efficient for repeated values)\n",
    "products_df['category'] = products_df['category'].astype('category')\n",
    "\n",
    "# Create a date column and convert to datetime\n",
    "products_df['last_updated'] = ['2025-01-15', '2025-01-20', '2025-01-10', '2025-01-25', '2025-01-18']\n",
    "products_df['last_updated'] = pd.to_datetime(products_df['last_updated'])\n",
    "\n",
    "# Check data types again\n",
    "print(products_df.dtypes)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Missing Data\n",
    "\n",
    "Missing data is a common issue in real-world datasets. In Pandas, missing values are typically represented by `NaN` (Not a Number). Let's see how to detect and handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(products_df.isna().sum())\n",
    "\n",
    "# Check if any value in a row is missing\n",
    "print(\"\\nRows with any missing value:\")\n",
    "print(products_df[products_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "There are several ways to handle missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove rows with missing values\n",
    "print(\"DataFrame after dropping rows with NaN:\")\n",
    "print(products_df.dropna())\n",
    "\n",
    "# Note: The above operation doesn't modify the original DataFrame unless inplace=True\n",
    "# Check that our original DataFrame still has the missing value\n",
    "print(\"\\nOriginal DataFrame (unchanged):\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fill missing values\n",
    "# With a constant value\n",
    "print(\"DataFrame after filling NaN with 0:\")\n",
    "print(products_df.fillna(0))\n",
    "\n",
    "# With column-specific values\n",
    "print(\"\\nDataFrame after filling NaN with column-specific values:\")\n",
    "print(products_df.fillna({'rating': 3.0}))\n",
    "\n",
    "# With the mean of the column\n",
    "mean_rating = products_df['rating'].mean()\n",
    "print(f\"\\nMean rating: {mean_rating:.2f}\")\n",
    "print(\"DataFrame after filling NaN with column mean:\")\n",
    "print(products_df.fillna({'rating': mean_rating}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Update the original DataFrame\n",
    "# Let's fill the missing rating with the mean and update our DataFrame\n",
    "products_df['rating'] = products_df['rating'].fillna(mean_rating)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(products_df)\n",
    "\n",
    "# Verify there are no more missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(products_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic Column Operations\n",
    "\n",
    "Now let's look at some basic operations on DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "# Calculate inventory value (price * stock_quantity)\n",
    "products_df['inventory_value'] = products_df['price'] * products_df['stock_quantity']\n",
    "print(\"DataFrame with inventory value:\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply() to create a column with a function\n",
    "def stock_status(quantity):\n",
    "    if quantity == 0:\n",
    "        return 'Out of Stock'\n",
    "    elif quantity < 15:\n",
    "        return 'Low Stock'\n",
    "    else:\n",
    "        return 'In Stock'\n",
    "\n",
    "products_df['stock_status'] = products_df['stock_quantity'].apply(stock_status)\n",
    "print(\"DataFrame with stock status:\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lambda functions for simple operations\n",
    "# Calculate a 10% discount price\n",
    "products_df['discount_price'] = products_df['price'].apply(lambda x: x * 0.9)\n",
    "print(\"DataFrame with discount price:\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "products_df = products_df.rename(columns={\n",
    "    'stock_quantity': 'quantity_in_stock',\n",
    "    'discount_price': 'sale_price'\n",
    "})\n",
    "print(\"DataFrame with renamed columns:\")\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "products_df_simplified = products_df.drop(columns=['inventory_value', 'stock_status'])\n",
    "print(\"Simplified DataFrame:\")\n",
    "print(products_df_simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practice Exercises\n",
    "\n",
    "Now let's practice with some exercises using what we've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: DataFrame Inspection\n",
    "\n",
    "Create a new DataFrame with sales data and answer the following questions:\n",
    "1. How many rows and columns are in the DataFrame?\n",
    "2. What is the data type of each column?\n",
    "3. Are there any missing values?\n",
    "4. What is the average sales amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sales DataFrame\n",
    "sales_data = {\n",
    "    'sale_id': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006'],\n",
    "    'date': ['2025-01-05', '2025-01-10', '2025-01-15', '2025-01-20', '2025-01-25', '2025-01-30'],\n",
    "    'product_id': ['P001', 'P002', 'P001', 'P003', 'P002', 'P004'],\n",
    "    'quantity': [1, 2, 1, 1, 3, 2],\n",
    "    'amount': [1200, 1600, 1200, 450, 2400, 300],\n",
    "    'customer_id': ['C001', 'C002', 'C003', 'C001', None, 'C002']\n",
    "}\n",
    "\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "print(sales_df)\n",
    "\n",
    "# Your code here to answer the questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Column Operations\n",
    "\n",
    "Using the sales DataFrame from Exercise 1:\n",
    "1. Add a column 'unit_price' that calculates the price per unit (amount / quantity)\n",
    "2. Add a column 'month' that extracts the month from the date\n",
    "3. Add a column 'high_value' that is True if the amount is greater than 1000, False otherwise\n",
    "4. Calculate the total sales amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Handling Missing Values\n",
    "\n",
    "Using the sales DataFrame from Exercise 1:\n",
    "1. Identify which rows have missing values\n",
    "2. Fill missing customer_id values with 'Unknown'\n",
    "3. Create a new DataFrame that drops rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next part, we'll focus on data selection and filtering operations, including how to translate SQL WHERE clauses to Pandas.\n",
    "\n",
    "Continue to [Part 3: Selection and Filtering](02_Pandas_Fundamentals_I_part3.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}