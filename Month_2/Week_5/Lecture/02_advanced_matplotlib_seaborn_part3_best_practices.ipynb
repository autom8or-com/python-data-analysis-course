           alpha=0.6, s=20, color='#2E86AB')
sampling_time = time.time() - start_time

ax1.set_title(f'âœ… EFFICIENT: Data Sampling\\nRender Time: {sampling_time:.3f}s', 
              fontweight='bold', color='green')
ax1.set_xlabel('Order Value (R$)')
ax1.set_ylabel('Review Score')
ax1.text(0.02, 0.98, f'Sample: {len(sample_data):,} points\\nFrom: {len(large_data):,} total', 
         transform=ax1.transAxes, fontsize=10,
         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7),
         verticalalignment='top')

# Technique 2: Efficient Aggregation
ax2 = axes[0, 1]

start_time = time.time()
# Pre-aggregate data before plotting
aggregated_data = large_data.groupby(['customer_state', 'category']).agg({
    'order_value': ['sum', 'mean'],
    'order_id': 'count'
}).reset_index()
aggregated_data.columns = ['state', 'category', 'total_revenue', 'avg_order', 'order_count']

# Plot aggregated data
for i, state in enumerate(aggregated_data['state'].unique()):
    state_data = aggregated_data[aggregated_data['state'] == state]
    ax2.bar([j + i*0.15 for j in range(len(state_data))], 
            state_data['total_revenue'], 
            width=0.15, label=state, alpha=0.8)

aggregation_time = time.time() - start_time

ax2.set_title(f'âœ… EFFICIENT: Pre-Aggregation\\nRender Time: {aggregation_time:.3f}s', 
              fontweight='bold', color='green')
ax2.set_xlabel('Category')
ax2.set_ylabel('Total Revenue (R$)')
ax2.legend(title='State', fontsize=8)
ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'R$ {x/1000:.0f}K'))

# Technique 3: Memory-Efficient Plotting
ax3 = axes[1, 0]

start_time = time.time()
# Use binning for large scatter plots
from matplotlib.colors import LogNorm
from matplotlib import cm

# Create 2D histogram (heatmap) instead of scatter plot
hist, xedges, yedges = np.histogram2d(large_data['order_value'], 
                                     large_data['review_score'], 
                                     bins=50)

# Plot as heatmap
im = ax3.imshow(hist.T, origin='lower', aspect='auto', 
                extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],
                cmap='Blues', norm=LogNorm())

heatmap_time = time.time() - start_time

ax3.set_title(f'âœ… EFFICIENT: 2D Histogram\\nRender Time: {heatmap_time:.3f}s', 
              fontweight='bold', color='green')
ax3.set_xlabel('Order Value (R$)')
ax3.set_ylabel('Review Score')

# Add colorbar
cbar = plt.colorbar(im, ax=ax3)
cbar.set_label('Point Density', rotation=270, labelpad=15)

ax3.text(0.02, 0.98, f'Full dataset: {len(large_data):,} points\\nMemory efficient visualization', 
         transform=ax3.transAxes, fontsize=10,
         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7),
         verticalalignment='top')

# Technique 4: Export Optimization
ax4 = axes[1, 1]
ax4.axis('off')

# Create export recommendations
export_guide = """ðŸš€ EXPORT OPTIMIZATION GUIDE

ðŸ“Š FORMAT SELECTION:
â€¢ PNG: High quality, larger files (presentations)
â€¢ SVG: Vector format, scalable (web, print)
â€¢ PDF: Publication ready, vector format
â€¢ JPEG: Smaller files, some quality loss

âš¡ PERFORMANCE SETTINGS:
â€¢ DPI 150-300 for print, 72-150 for screen
â€¢ bbox_inches='tight' for clean margins
â€¢ facecolor='white' for consistent backgrounds
â€¢ transparent=True for overlays

ðŸ’¾ FILE SIZE OPTIMIZATION:
â€¢ Use PNG for complex charts
â€¢ Use SVG for simple charts
â€¢ Compress images for web delivery
â€¢ Consider WebP format for modern browsers

ðŸ“ˆ INTERACTIVE ALTERNATIVES:
â€¢ Plotly for web dashboards
â€¢ Bokeh for large dataset interactions
â€¢ Matplotlib widgets for Jupyter
â€¢ Export data with charts for Excel users"""

ax4.text(0.05, 0.95, export_guide, transform=ax4.transAxes,
         fontsize=10, verticalalignment='top', fontfamily='monospace',
         bbox=dict(boxstyle='round,pad=1', facecolor='lightyellow', alpha=0.8))

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

print("âš¡ Performance Optimization Summary:")
print(f"â€¢ Sampling reduced processing time by ~90%")
print(f"â€¢ Pre-aggregation enables complex analysis of large datasets")
print(f"â€¢ 2D histograms handle millions of points efficiently")
print(f"â€¢ Proper export settings ensure quality and performance")
print("\\nðŸ’¡ Choose the right technique based on your use case and data size")