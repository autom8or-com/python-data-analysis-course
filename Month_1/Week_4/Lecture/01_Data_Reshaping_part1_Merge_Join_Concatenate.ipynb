{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Reshaping - Part 1: Merge, Join, and Concatenate\n",
        "\n",
        "## Week 4, Day 1 (Wednesday) - April 30th, 2025\n",
        "\n",
        "### Overview\n",
        "This is the first part of our Data Reshaping session, focusing on combining data from multiple sources. Understanding how to merge, join, and concatenate DataFrames is essential for working with real-world datasets that are often split across multiple tables or files.\n",
        "\n",
        "### Learning Objectives\n",
        "- Master different ways to combine DataFrames in Pandas\n",
        "- Understand the difference between concatenation and merging\n",
        "- Learn various types of joins and their SQL equivalents\n",
        "- Apply data combination techniques to e-commerce scenarios\n",
        "- Handle common issues when combining datasets\n",
        "\n",
        "### Prerequisites\n",
        "- Python fundamentals (Week 1)\n",
        "- NumPy basics (Week 2, Day 1)\n",
        "- Pandas fundamentals (Week 2-3)\n",
        "- SQL knowledge (prior to course) - especially JOIN operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction to Data Combination\n",
        "\n",
        "In real-world data analysis, you rarely work with a single dataset. Data is often:\n",
        "- Split across multiple tables (normalized databases)\n",
        "- Stored in separate files by time period\n",
        "- Coming from different sources that need to be combined\n",
        "\n",
        "Pandas provides powerful tools to combine data, similar to SQL's JOIN and UNION operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set display options for better readability\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Creating Sample E-commerce Datasets\n",
        "\n",
        "Let's create sample datasets similar to what you might find in an e-commerce database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Orders dataset\n",
        "orders = pd.DataFrame({\n",
        "    'order_id': ['ORD001', 'ORD002', 'ORD003', 'ORD004', 'ORD005'],\n",
        "    'customer_id': ['CUST001', 'CUST002', 'CUST001', 'CUST003', 'CUST002'],\n",
        "    'order_date': ['2025-01-15', '2025-01-16', '2025-01-17', '2025-01-18', '2025-01-19'],\n",
        "    'total_amount': [299.99, 149.50, 89.99, 199.99, 75.25]\n",
        "})\n",
        "\n",
        "# Customers dataset\n",
        "customers = pd.DataFrame({\n",
        "    'customer_id': ['CUST001', 'CUST002', 'CUST003', 'CUST004'],\n",
        "    'customer_name': ['Alice Johnson', 'Bob Smith', 'Carol Brown', 'David Wilson'],\n",
        "    'email': ['alice@email.com', 'bob@email.com', 'carol@email.com', 'david@email.com'],\n",
        "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
        "})\n",
        "\n",
        "# Products dataset\n",
        "products = pd.DataFrame({\n",
        "    'product_id': ['PROD001', 'PROD002', 'PROD003', 'PROD004', 'PROD005'],\n",
        "    'product_name': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Monitor'],\n",
        "    'category': ['Electronics', 'Electronics', 'Electronics', 'Accessories', 'Electronics'],\n",
        "    'price': [1299.99, 899.99, 449.99, 199.99, 349.99]\n",
        "})\n",
        "\n",
        "# Order items dataset (linking orders to products)\n",
        "order_items = pd.DataFrame({\n",
        "    'order_id': ['ORD001', 'ORD001', 'ORD002', 'ORD003', 'ORD004', 'ORD005'],\n",
        "    'product_id': ['PROD001', 'PROD004', 'PROD002', 'PROD003', 'PROD005', 'PROD004'],\n",
        "    'quantity': [1, 1, 1, 1, 1, 1],\n",
        "    'unit_price': [1299.99, 199.99, 899.99, 449.99, 349.99, 199.99]\n",
        "})\n",
        "\n",
        "print(\"Sample datasets created!\")\n",
        "print(f\"Orders: {len(orders)} rows\")\n",
        "print(f\"Customers: {len(customers)} rows\")\n",
        "print(f\"Products: {len(products)} rows\")\n",
        "print(f\"Order Items: {len(order_items)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's examine our datasets\n",
        "print(\"ORDERS:\")\n",
        "print(orders)\n",
        "print(\"\\nCUSTOMERS:\")\n",
        "print(customers)\n",
        "print(\"\\nPRODUCTS:\")\n",
        "print(products)\n",
        "print(\"\\nORDER ITEMS:\")\n",
        "print(order_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Concatenation with pd.concat()\n",
        "\n",
        "### What is Concatenation?\n",
        "Concatenation combines DataFrames by stacking them vertically (rows) or horizontally (columns). It's similar to SQL's UNION operation.\n",
        "\n",
        "### Vertical Concatenation (Stacking Rows)\n",
        "SQL equivalent: `SELECT * FROM table1 UNION ALL SELECT * FROM table2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create additional orders data (like from another time period)\n",
        "new_orders = pd.DataFrame({\n",
        "    'order_id': ['ORD006', 'ORD007', 'ORD008'],\n",
        "    'customer_id': ['CUST001', 'CUST004', 'CUST002'],\n",
        "    'order_date': ['2025-01-20', '2025-01-21', '2025-01-22'],\n",
        "    'total_amount': [199.99, 299.99, 89.99]\n",
        "})\n",
        "\n",
        "print(\"Original orders:\")\n",
        "print(orders)\n",
        "print(\"\\nNew orders:\")\n",
        "print(new_orders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate vertically (default behavior)\n",
        "all_orders = pd.concat([orders, new_orders])\n",
        "\n",
        "print(\"All orders combined:\")\n",
        "print(all_orders)\n",
        "print(f\"\\nOriginal orders: {len(orders)} rows\")\n",
        "print(f\"New orders: {len(new_orders)} rows\")\n",
        "print(f\"Combined: {len(all_orders)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset index to have continuous numbering\n",
        "all_orders_reset = pd.concat([orders, new_orders], ignore_index=True)\n",
        "\n",
        "print(\"All orders with reset index:\")\n",
        "print(all_orders_reset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Horizontal Concatenation (Side by Side)\n",
        "Useful when you have additional columns for the same rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create additional customer information\n",
        "customer_details = pd.DataFrame({\n",
        "    'phone': ['555-0101', '555-0102', '555-0103', '555-0104'],\n",
        "    'age': [28, 35, 42, 31],\n",
        "    'membership_tier': ['Gold', 'Silver', 'Gold', 'Bronze']\n",
        "})\n",
        "\n",
        "print(\"Original customers:\")\n",
        "print(customers)\n",
        "print(\"\\nAdditional details:\")\n",
        "print(customer_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate horizontally\n",
        "customers_expanded = pd.concat([customers, customer_details], axis=1)\n",
        "\n",
        "print(\"Customers with additional details:\")\n",
        "print(customers_expanded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Labels to Concatenated Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add labels to identify data sources\n",
        "labeled_orders = pd.concat([orders, new_orders], \n",
        "                          keys=['January_Week_3', 'January_Week_4'],\n",
        "                          names=['Week', 'Row'])\n",
        "\n",
        "print(\"Orders with source labels:\")\n",
        "print(labeled_orders)\n",
        "print(\"\\nIndex structure:\")\n",
        "print(labeled_orders.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Merging and Joining with pd.merge()\n",
        "\n",
        "### What is Merging?\n",
        "Merging combines DataFrames based on common columns or indices, similar to SQL JOINs. This is used when you have related data across multiple tables.\n",
        "\n",
        "### Inner Join (Default)\n",
        "SQL equivalent: `SELECT * FROM table1 INNER JOIN table2 ON table1.key = table2.key`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inner join: Orders with Customer information\n",
        "orders_with_customers = pd.merge(orders, customers, on='customer_id')\n",
        "\n",
        "print(\"Orders with customer information (Inner Join):\")\n",
        "print(orders_with_customers)\n",
        "print(f\"\\nOriginal orders: {len(orders)} rows\")\n",
        "print(f\"Customers: {len(customers)} rows\")\n",
        "print(f\"Merged result: {len(orders_with_customers)} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Left Join\n",
        "SQL equivalent: `SELECT * FROM table1 LEFT JOIN table2 ON table1.key = table2.key`\n",
        "\n",
        "Keeps all records from the left DataFrame, adds matching records from the right:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Left join: All orders, with customer info where available\n",
        "orders_left_join = pd.merge(orders, customers, on='customer_id', how='left')\n",
        "\n",
        "print(\"Orders with customer information (Left Join):\")\n",
        "print(orders_left_join)\n",
        "print(f\"\\nResult has {len(orders_left_join)} rows (same as orders: {len(orders)})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Right Join\n",
        "SQL equivalent: `SELECT * FROM table1 RIGHT JOIN table2 ON table1.key = table2.key`\n",
        "\n",
        "Keeps all records from the right DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Right join: All customers, with order info where available\n",
        "customers_right_join = pd.merge(orders, customers, on='customer_id', how='right')\n",
        "\n",
        "print(\"Customers with order information (Right Join):\")\n",
        "print(customers_right_join)\n",
        "print(f\"\\nResult has {len(customers_right_join)} rows (same as customers: {len(customers)})\")\n",
        "print(\"\\nNotice: David Wilson (CUST004) appears with NaN values because he has no orders\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outer Join (Full Join)\n",
        "SQL equivalent: `SELECT * FROM table1 FULL OUTER JOIN table2 ON table1.key = table2.key`\n",
        "\n",
        "Keeps all records from both DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Outer join: All orders and all customers\n",
        "full_outer_join = pd.merge(orders, customers, on='customer_id', how='outer')\n",
        "\n",
        "print(\"Full outer join - All orders and customers:\")\n",
        "print(full_outer_join)\n",
        "print(f\"\\nResult has {len(full_outer_join)} rows\")\n",
        "print(\"NaN values appear where no match exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Complex Merging Scenarios\n",
        "\n",
        "### Merging on Multiple Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a scenario where we need to merge on multiple columns\n",
        "# Let's say we have daily sales data and want to merge with promotional data\n",
        "\n",
        "daily_sales = pd.DataFrame({\n",
        "    'date': ['2025-01-15', '2025-01-16', '2025-01-17', '2025-01-15', '2025-01-16'],\n",
        "    'product_id': ['PROD001', 'PROD001', 'PROD001', 'PROD002', 'PROD002'],\n",
        "    'sales_qty': [5, 3, 8, 2, 4]\n",
        "})\n",
        "\n",
        "promotions = pd.DataFrame({\n",
        "    'date': ['2025-01-15', '2025-01-16', '2025-01-17', '2025-01-15'],\n",
        "    'product_id': ['PROD001', 'PROD001', 'PROD001', 'PROD002'],\n",
        "    'discount_pct': [10, 15, 5, 20]\n",
        "})\n",
        "\n",
        "print(\"Daily Sales:\")\n",
        "print(daily_sales)\n",
        "print(\"\\nPromotions:\")\n",
        "print(promotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge on multiple columns\n",
        "sales_with_promotions = pd.merge(daily_sales, promotions, \n",
        "                                on=['date', 'product_id'], \n",
        "                                how='left')\n",
        "\n",
        "print(\"Sales with promotions (merged on date AND product_id):\")\n",
        "print(sales_with_promotions)\n",
        "print(\"\\nNaN in discount_pct means no promotion was available for that date/product combination\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merging with Different Column Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sometimes the join columns have different names\n",
        "customer_reviews = pd.DataFrame({\n",
        "    'cust_id': ['CUST001', 'CUST002', 'CUST003', 'CUST001'],  # Different column name\n",
        "    'product_id': ['PROD001', 'PROD002', 'PROD003', 'PROD004'],\n",
        "    'rating': [5, 4, 3, 5],\n",
        "    'review_date': ['2025-01-20', '2025-01-21', '2025-01-22', '2025-01-23']\n",
        "})\n",
        "\n",
        "print(\"Customer Reviews (note: 'cust_id' instead of 'customer_id'):\")\n",
        "print(customer_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge with different column names using left_on and right_on\n",
        "reviews_with_customers = pd.merge(customer_reviews, customers, \n",
        "                                 left_on='cust_id', right_on='customer_id',\n",
        "                                 how='inner')\n",
        "\n",
        "print(\"Reviews with customer details:\")\n",
        "print(reviews_with_customers)\n",
        "print(\"\\nNotice: Both 'cust_id' and 'customer_id' columns are kept\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Duplicate Column Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets with overlapping column names\n",
        "order_summary = pd.DataFrame({\n",
        "    'order_id': ['ORD001', 'ORD002', 'ORD003'],\n",
        "    'total_amount': [299.99, 149.50, 89.99],  # Same name as in orders\n",
        "    'status': ['Delivered', 'Shipped', 'Processing']\n",
        "})\n",
        "\n",
        "print(\"Original orders:\")\n",
        "print(orders[['order_id', 'total_amount']].head(3))\n",
        "print(\"\\nOrder summary:\")\n",
        "print(order_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge with suffixes to handle duplicate column names\n",
        "orders_with_status = pd.merge(orders, order_summary, \n",
        "                             on='order_id', \n",
        "                             suffixes=('_original', '_summary'))\n",
        "\n",
        "print(\"Orders merged with status (using suffixes):\")\n",
        "print(orders_with_status)\n",
        "print(\"\\nNotice: total_amount_original and total_amount_summary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced Merging: One-to-Many and Many-to-Many\n",
        "\n",
        "### One-to-Many Relationship\n",
        "Each customer can have multiple orders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is a one-to-many relationship: one customer -> many orders\n",
        "customer_orders = pd.merge(customers, orders, on='customer_id', how='inner')\n",
        "\n",
        "print(\"Customer-Order relationship (One-to-Many):\")\n",
        "print(customer_orders)\n",
        "print(\"\\nNotice: Alice Johnson appears twice because she has two orders\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Many-to-Many Relationship\n",
        "Let's create a more complex scenario with order items:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complex join: Orders -> Order Items -> Products\n",
        "# First join orders with order items\n",
        "orders_items = pd.merge(orders, order_items, on='order_id')\n",
        "\n",
        "print(\"Orders joined with Order Items:\")\n",
        "print(orders_items)\n",
        "print(f\"\\nRows: {len(orders_items)} (more than original {len(orders)} orders because some orders have multiple items)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now add product information\n",
        "complete_order_info = pd.merge(orders_items, products, on='product_id')\n",
        "\n",
        "print(\"Complete order information (Orders + Items + Products):\")\n",
        "print(complete_order_info)\n",
        "print(\"\\nNow we can see what products were ordered in each order!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Performance and Memory Considerations\n",
        "\n",
        "### When to Use Concatenation vs Merging\n",
        "\n",
        "| Operation | Use When | SQL Equivalent |\n",
        "|-----------|----------|----------------|\n",
        "| `pd.concat()` | Combining DataFrames with same structure | `UNION ALL` |\n",
        "| `pd.merge()` | Combining related data from different tables | `JOIN` |\n",
        "\n",
        "### Memory Efficiency Tips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check memory usage\n",
        "print(\"Memory usage of our datasets:\")\n",
        "print(f\"Orders: {orders.memory_usage(deep=True).sum()} bytes\")\n",
        "print(f\"Customers: {customers.memory_usage(deep=True).sum()} bytes\")\n",
        "print(f\"Products: {products.memory_usage(deep=True).sum()} bytes\")\n",
        "print(f\"Complete order info: {complete_order_info.memory_usage(deep=True).sum()} bytes\")\n",
        "\n",
        "# For large datasets, consider:\n",
        "# 1. Using categorical data types for repeated strings\n",
        "# 2. Selecting only needed columns before merging\n",
        "# 3. Using chunking for very large datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. SQL to Pandas Translation Guide\n",
        "\n",
        "### Common SQL JOIN patterns and their Pandas equivalents:\n",
        "\n",
        "| SQL Operation | Pandas Equivalent |\n",
        "|--------------|-------------------|\n",
        "| `SELECT * FROM a INNER JOIN b ON a.key = b.key` | `pd.merge(a, b, on='key')` |\n",
        "| `SELECT * FROM a LEFT JOIN b ON a.key = b.key` | `pd.merge(a, b, on='key', how='left')` |\n",
        "| `SELECT * FROM a RIGHT JOIN b ON a.key = b.key` | `pd.merge(a, b, on='key', how='right')` |\n",
        "| `SELECT * FROM a FULL OUTER JOIN b ON a.key = b.key` | `pd.merge(a, b, on='key', how='outer')` |\n",
        "| `SELECT * FROM a UNION ALL SELECT * FROM b` | `pd.concat([a, b])` |\n",
        "| `SELECT * FROM a JOIN b ON a.k1=b.k1 AND a.k2=b.k2` | `pd.merge(a, b, on=['k1', 'k2'])` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Real-World E-commerce Example\n",
        "\n",
        "Let's create a comprehensive analysis combining all our datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive customer analysis\n",
        "# Step 1: Get orders with customer information\n",
        "step1 = pd.merge(orders, customers, on='customer_id', how='left')\n",
        "\n",
        "# Step 2: Add order items\n",
        "step2 = pd.merge(step1, order_items, on='order_id', how='left')\n",
        "\n",
        "# Step 3: Add product information\n",
        "comprehensive_data = pd.merge(step2, products, on='product_id', how='left')\n",
        "\n",
        "print(\"Comprehensive E-commerce Analysis Dataset:\")\n",
        "print(comprehensive_data)\n",
        "print(f\"\\nShape: {comprehensive_data.shape}\")\n",
        "print(f\"Columns: {list(comprehensive_data.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we can do interesting analyses\n",
        "print(\"Analysis Examples:\")\n",
        "print(\"\\n1. Total spent by each customer:\")\n",
        "customer_spending = comprehensive_data.groupby('customer_name')['unit_price'].sum().sort_values(ascending=False)\n",
        "print(customer_spending)\n",
        "\n",
        "print(\"\\n2. Most popular product categories:\")\n",
        "category_popularity = comprehensive_data['category'].value_counts()\n",
        "print(category_popularity)\n",
        "\n",
        "print(\"\\n3. Average order value by city:\")\n",
        "city_avg_order = comprehensive_data.groupby('city')['total_amount'].mean().sort_values(ascending=False)\n",
        "print(city_avg_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Common Issues and Solutions\n",
        "\n",
        "### Issue 1: Unexpected Number of Rows After Merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This can happen with duplicate keys\n",
        "# Let's create a scenario with duplicate customer IDs\n",
        "duplicate_customers = pd.DataFrame({\n",
        "    'customer_id': ['CUST001', 'CUST001', 'CUST002'],  # CUST001 appears twice\n",
        "    'segment': ['Premium', 'VIP', 'Standard']\n",
        "})\n",
        "\n",
        "print(\"Orders (3 for CUST001):\")\n",
        "print(orders[orders['customer_id'] == 'CUST001'])\n",
        "print(\"\\nDuplicate customer segments:\")\n",
        "print(duplicate_customers)\n",
        "\n",
        "# This will create a Cartesian product!\n",
        "problematic_merge = pd.merge(orders, duplicate_customers, on='customer_id')\n",
        "print(f\"\\nProblematic merge result ({len(problematic_merge)} rows):\")\n",
        "print(problematic_merge[problematic_merge['customer_id'] == 'CUST001'])\n",
        "print(\"\\nNotice: Each order for CUST001 now appears twice!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 2: Missing Data After Inner Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Some orders might not have customer information\n",
        "orders_with_missing = orders.copy()\n",
        "orders_with_missing.loc[len(orders_with_missing)] = ['ORD999', 'CUST999', '2025-01-25', 99.99]\n",
        "\n",
        "print(\"Orders with missing customer:\")\n",
        "print(orders_with_missing.tail())\n",
        "\n",
        "# Inner join will drop the order with missing customer\n",
        "inner_result = pd.merge(orders_with_missing, customers, on='customer_id', how='inner')\n",
        "print(f\"\\nInner join result: {len(inner_result)} rows (lost 1 order)\")\n",
        "\n",
        "# Left join will keep all orders\n",
        "left_result = pd.merge(orders_with_missing, customers, on='customer_id', how='left')\n",
        "print(f\"Left join result: {len(left_result)} rows (kept all orders)\")\n",
        "print(\"\\nOrders without customer info:\")\n",
        "print(left_result[left_result['customer_name'].isna()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Practice Exercises\n",
        "\n",
        "### Exercise 1: Basic Merging\n",
        "Merge the `orders` and `customers` DataFrames to show all orders with customer information. Include orders even if customer information is missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Multiple Table Join\n",
        "Create a dataset that shows:\n",
        "- Order ID\n",
        "- Customer Name\n",
        "- Product Name\n",
        "- Quantity\n",
        "- Unit Price\n",
        "\n",
        "Hint: You'll need to join orders, customers, order_items, and products."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Concatenation Challenge\n",
        "You have sales data from two different months. Combine them and add a column to identify which month each sale came from.\n",
        "\n",
        "```python\n",
        "january_sales = pd.DataFrame({\n",
        "    'product': ['A', 'B', 'C'],\n",
        "    'sales': [100, 150, 200]\n",
        "})\n",
        "\n",
        "february_sales = pd.DataFrame({\n",
        "    'product': ['A', 'B', 'D'],\n",
        "    'sales': [120, 180, 90]\n",
        "})\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the sample data\n",
        "january_sales = pd.DataFrame({\n",
        "    'product': ['A', 'B', 'C'],\n",
        "    'sales': [100, 150, 200]\n",
        "})\n",
        "\n",
        "february_sales = pd.DataFrame({\n",
        "    'product': ['A', 'B', 'D'],\n",
        "    'sales': [120, 180, 90]\n",
        "})\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4: SQL Translation\n",
        "Translate this SQL query to Pandas:\n",
        "\n",
        "```sql\n",
        "SELECT c.customer_name, COUNT(o.order_id) as order_count, SUM(o.total_amount) as total_spent\n",
        "FROM customers c\n",
        "LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
        "GROUP BY c.customer_id, c.customer_name\n",
        "ORDER BY total_spent DESC\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Congratulations! You've mastered the fundamentals of merging, joining, and concatenating DataFrames. In the next parts of today's session, we'll continue with:\n",
        "\n",
        "- **Part 2: Reshape operations (melt, pivot)**\n",
        "- **Part 3: Time series manipulation basics**\n",
        "\n",
        "These skills form the foundation for working with real-world, multi-table datasets like the Olist e-commerce database we'll be using throughout the course.\n",
        "\n",
        "### Key Takeaways\n",
        "1. **Concatenation** (`pd.concat()`) stacks DataFrames - use for combining similar data\n",
        "2. **Merging** (`pd.merge()`) joins related data - use for combining different but related datasets\n",
        "3. **Join types** (inner, left, right, outer) control which records are kept\n",
        "4. **Always verify** the number of rows after joining to catch unexpected duplications\n",
        "5. **Plan your joins** - start with the main table and add related information step by step"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}