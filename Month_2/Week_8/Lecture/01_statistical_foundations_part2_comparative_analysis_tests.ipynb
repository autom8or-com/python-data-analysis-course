{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 - Statistical Foundations Part 2: Comparative Analysis Tests\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will be able to:\n",
    "1. **Conduct** t-tests to compare customer segments and business metrics\n",
    "2. **Apply** chi-square tests to analyze categorical relationships in e-commerce\n",
    "3. **Perform** ANOVA to compare multiple groups simultaneously\n",
    "4. **Interpret** test results in business context with actionable insights\n",
    "5. **Choose** the appropriate test for different business scenarios\n",
    "\n",
    "## Business Context: Comparative Analysis in E-commerce\n",
    "\n",
    "In **Part 1**, we established the statistical foundation for hypothesis testing. Now we'll apply specific statistical tests to answer critical business questions:\n",
    "\n",
    "### Real Olist Business Questions:\n",
    "- **Customer Segmentation**: Do different customer groups have significantly different behaviors?\n",
    "- **Regional Performance**: Are sales performance differences between states statistically meaningful?\n",
    "- **Payment Analysis**: Is payment method choice related to customer satisfaction?\n",
    "- **Product Categories**: Do different product categories perform significantly differently?\n",
    "\n",
    "### Test Arsenal for Business Analysis:\n",
    "- **T-tests**: Compare two groups (SP vs RJ customers, credit vs debit payments)\n",
    "- **Chi-square**: Analyze categorical relationships (payment type vs satisfaction level)\n",
    "- **ANOVA**: Compare multiple groups (all Brazilian states, product categories)\n",
    "\n",
    "## Strategic Impact\n",
    "\n",
    "Today's analysis will provide **statistical evidence** for business decisions:\n",
    "- **Marketing**: Which customer segments to target with different strategies\n",
    "- **Operations**: Which regions need operational improvements\n",
    "- **Product**: Which categories require quality improvements\n",
    "- **Finance**: Which payment methods drive higher transaction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Statistical Testing Environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Comprehensive statistical testing toolkit\n",
    "from scipy import stats\n",
    "from scipy.stats import (\n",
    "    ttest_ind, ttest_rel, mannwhitneyu, wilcoxon,  # Two-sample tests\n",
    "    chi2_contingency, fisher_exact,                # Categorical tests\n",
    "    f_oneway, kruskal,                             # Multiple group tests\n",
    "    pearsonr, spearmanr,                           # Correlation tests\n",
    "    normaltest, levene, shapiro                    # Assumption tests\n",
    ")\n",
    "\n",
    "# Database connection\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced plotting configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"🔬 Comparative Analysis Testing Environment Ready!\")\n",
    "print(f\"📊 Statistical Tests Available: t-tests, chi-square, ANOVA, and more\")\n",
    "print(f\"🎯 Ready to conduct rigorous comparative analysis on Olist marketplace data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secure Database Connection Using Environment Variables\n",
    "# Best practice: Never expose credentials in code\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Read database credentials from environment variables\n",
    "SUPABASE_URL = os.getenv('SUPABASE_URL')\n",
    "SUPABASE_KEY = os.getenv('SUPABASE_KEY')\n",
    "\n",
    "# Alternative: Use legacy postgres connection if needed\n",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '6543')\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DATABASE', 'postgres')\n",
    "POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "# Construct secure database URL using environment variables\n",
    "if POSTGRES_HOST and POSTGRES_USER and POSTGRES_PASSWORD:\n",
    "    DATABASE_URL = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "else:\n",
    "    print(\"❌ Database credentials not found in environment variables\")\n",
    "    print(\"Please check your .env file contains the required database credentials\")\n",
    "\n",
    "# Create database engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        from sqlalchemy import text\n",
    "        result = conn.execute(text(\"SELECT count(*) FROM olist_sales_data_set.olist_geolocation_dataset\"))\n",
    "        count = result.scalar()\n",
    "        print(f\"✅ Secure database connection established! ({count:,} records in geolocation table)\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")\n",
    "\n",
    "print(\"🔒 Security Note: Database credentials loaded from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. T-Tests: Comparing Two Groups\n",
    "\n",
    "### Business Application: Regional Customer Analysis\n",
    "\n",
    "**Business Question**: \"Are customers in São Paulo (SP) significantly different from customers in Rio de Janeiro (RJ) in terms of spending behavior?\"\n",
    "\n",
    "This comparison is crucial for:\n",
    "- **Regional Marketing**: Different strategies for different states\n",
    "- **Inventory Management**: Stock allocation based on spending patterns\n",
    "- **Pricing Strategy**: Regional pricing optimization\n",
    "- **Expansion Planning**: Understanding regional market dynamics\n",
    "\n",
    "### Types of T-Tests:\n",
    "1. **Independent Samples T-test**: Compare two separate groups (SP vs RJ customers)\n",
    "2. **Paired Samples T-test**: Compare same subjects before/after (customer behavior changes)\n",
    "3. **One-Sample T-test**: Compare group to a known value (compare to national average)\n",
    "\n",
    "### When to Use T-Tests:\n",
    "- **Continuous data** (order values, delivery times, satisfaction scores)\n",
    "- **Approximately normal** distributions (or large samples)\n",
    "- **Independent observations** (customers don't influence each other)\n",
    "- **Comparing means** between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional Customer Analysis: SP vs RJ\n",
    "def regional_customer_analysis():\n",
    "    \"\"\"\n",
    "    Compare customer spending behavior between São Paulo and Rio de Janeiro.\n",
    "    \"\"\"\n",
    "    if engine is None:\n",
    "        print(\"❌ Database connection required for regional analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🗺️ Regional Customer Analysis: São Paulo vs Rio de Janeiro\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load customer spending data by state\n",
    "    regional_query = \"\"\"\n",
    "    SELECT \n",
    "        c.customer_state,\n",
    "        c.customer_city,\n",
    "        SUM(oi.price + oi.freight_value) as total_spending,\n",
    "        COUNT(DISTINCT o.order_id) as order_count,\n",
    "        AVG(oi.price + oi.freight_value) as avg_order_value,\n",
    "        AVG(r.review_score) as avg_satisfaction\n",
    "    FROM \"olist_sales_data_set\".\"olist_customers_dataset\" c\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_orders_dataset\" o ON c.customer_id = o.customer_id\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_order_items_dataset\" oi ON o.order_id = oi.order_id\n",
    "    LEFT JOIN \"olist_sales_data_set\".\"olist_order_reviews_dataset\" r ON o.order_id = r.order_id\n",
    "    WHERE c.customer_state IN ('SP', 'RJ')\n",
    "        AND o.order_status = 'delivered'\n",
    "        AND oi.price > 0\n",
    "    GROUP BY c.customer_id, c.customer_state, c.customer_city\n",
    "    HAVING COUNT(DISTINCT o.order_id) >= 1  -- At least one order\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        regional_data = pd.read_sql(text(regional_query), engine)\n",
    "        print(f\"✅ Loaded data for {len(regional_data):,} customers\")\n",
    "        \n",
    "        # Separate data by state\n",
    "        sp_customers = regional_data[regional_data['customer_state'] == 'SP']\n",
    "        rj_customers = regional_data[regional_data['customer_state'] == 'RJ']\n",
    "        \n",
    "        print(f\"📊 Sample sizes: SP = {len(sp_customers):,}, RJ = {len(rj_customers):,}\")\n",
    "        \n",
    "        # Analysis 1: Average Order Value Comparison\n",
    "        print(\"\\n💰 Analysis 1: Average Order Value Comparison\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        sp_aov = sp_customers['avg_order_value']\n",
    "        rj_aov = rj_customers['avg_order_value']\n",
    "        \n",
    "        # Descriptive statistics\n",
    "        sp_mean, sp_std = sp_aov.mean(), sp_aov.std()\n",
    "        rj_mean, rj_std = rj_aov.mean(), rj_aov.std()\n",
    "        \n",
    "        print(f\"São Paulo (SP): Mean = R$ {sp_mean:.2f}, SD = R$ {sp_std:.2f}\")\n",
    "        print(f\"Rio de Janeiro (RJ): Mean = R$ {rj_mean:.2f}, SD = R$ {rj_std:.2f}\")\n",
    "        print(f\"Raw Difference: R$ {sp_mean - rj_mean:.2f}\")\n",
    "        \n",
    "        # Check assumptions\n",
    "        print(\"\\n🔍 Assumption Checking:\")\n",
    "        \n",
    "        # Normality test (sample for large datasets)\n",
    "        sp_sample = sp_aov.sample(min(5000, len(sp_aov))) if len(sp_aov) > 5000 else sp_aov\n",
    "        rj_sample = rj_aov.sample(min(5000, len(rj_aov))) if len(rj_aov) > 5000 else rj_aov\n",
    "        \n",
    "        _, sp_normal_p = normaltest(sp_sample)\n",
    "        _, rj_normal_p = normaltest(rj_sample)\n",
    "        \n",
    "        print(f\"SP Normality test p-value: {sp_normal_p:.4f}\")\n",
    "        print(f\"RJ Normality test p-value: {rj_normal_p:.4f}\")\n",
    "        \n",
    "        # Equal variances test\n",
    "        _, levene_p = levene(sp_aov, rj_aov)\n",
    "        print(f\"Equal variances test p-value: {levene_p:.4f}\")\n",
    "        \n",
    "        equal_var = levene_p > 0.05\n",
    "        print(f\"Assumption: {'✅ Equal variances' if equal_var else '❌ Unequal variances'}\")\n",
    "        \n",
    "        # Perform appropriate t-test\n",
    "        t_stat, p_value = ttest_ind(sp_aov, rj_aov, equal_var=equal_var)\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt(((len(sp_aov)-1)*sp_aov.var() + (len(rj_aov)-1)*rj_aov.var()) / \n",
    "                            (len(sp_aov)+len(rj_aov)-2))\n",
    "        cohens_d = (sp_mean - rj_mean) / pooled_std\n",
    "        \n",
    "        print(\"\\n📊 T-Test Results:\")\n",
    "        print(f\"Test statistic: t = {t_stat:.4f}\")\n",
    "        print(f\"P-value: {p_value:.6f}\")\n",
    "        print(f\"Cohen's d (effect size): {cohens_d:.4f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        alpha = 0.05\n",
    "        if p_value < alpha:\n",
    "            print(f\"✅ Statistically significant difference (p < {alpha})\")\n",
    "        else:\n",
    "            print(f\"❌ No statistically significant difference (p ≥ {alpha})\")\n",
    "        \n",
    "        # Effect size interpretation\n",
    "        if abs(cohens_d) >= 0.8:\n",
    "            effect_interpretation = \"Large effect\"\n",
    "        elif abs(cohens_d) >= 0.5:\n",
    "            effect_interpretation = \"Medium effect\"\n",
    "        elif abs(cohens_d) >= 0.2:\n",
    "            effect_interpretation = \"Small effect\"\n",
    "        else:\n",
    "            effect_interpretation = \"Negligible effect\"\n",
    "        \n",
    "        print(f\"Effect size: {effect_interpretation}\")\n",
    "        \n",
    "        # Confidence interval for difference\n",
    "        se_diff = pooled_std * np.sqrt(1/len(sp_aov) + 1/len(rj_aov))\n",
    "        degrees_freedom = len(sp_aov) + len(rj_aov) - 2\n",
    "        t_critical = stats.t.ppf(0.975, degrees_freedom)\n",
    "        ci_lower = (sp_mean - rj_mean) - t_critical * se_diff\n",
    "        ci_upper = (sp_mean - rj_mean) + t_critical * se_diff\n",
    "        \n",
    "        print(f\"95% CI for difference: R$ {ci_lower:.2f} to R$ {ci_upper:.2f}\")\n",
    "        \n",
    "        # Business interpretation\n",
    "        print(\"\\n💼 Business Interpretation:\")\n",
    "        if p_value < alpha and abs(sp_mean - rj_mean) > 5:  # R$ 5 threshold\n",
    "            higher_state = \"SP\" if sp_mean > rj_mean else \"RJ\"\n",
    "            print(f\"📈 {higher_state} customers have significantly higher average order values\")\n",
    "            print(f\"💡 Consider targeted marketing strategies for each state\")\n",
    "            print(f\"🎯 Regional pricing and inventory strategies may be justified\")\n",
    "        else:\n",
    "            print(f\"📊 No meaningful difference in spending between SP and RJ customers\")\n",
    "            print(f\"💡 Unified marketing and pricing strategies are appropriate\")\n",
    "        \n",
    "        return regional_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in regional analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Perform regional customer analysis\n",
    "regional_data = regional_customer_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: T-Test Results\n",
    "def visualize_ttest_results(data):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of t-test results.\n",
    "    \"\"\"\n",
    "    if data is None or data.empty:\n",
    "        print(\"❌ No data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Regional Customer Analysis: SP vs RJ', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Distribution Comparison\n",
    "    sp_data = data[data['customer_state'] == 'SP']['avg_order_value']\n",
    "    rj_data = data[data['customer_state'] == 'RJ']['avg_order_value']\n",
    "    \n",
    "    ax1.hist(sp_data, bins=50, alpha=0.7, label='São Paulo', color='blue', density=True)\n",
    "    ax1.hist(rj_data, bins=50, alpha=0.7, label='Rio de Janeiro', color='red', density=True)\n",
    "    ax1.axvline(sp_data.mean(), color='blue', linestyle='--', linewidth=2, label=f'SP Mean: R$ {sp_data.mean():.2f}')\n",
    "    ax1.axvline(rj_data.mean(), color='red', linestyle='--', linewidth=2, label=f'RJ Mean: R$ {rj_data.mean():.2f}')\n",
    "    ax1.set_title('Distribution of Average Order Values')\n",
    "    ax1.set_xlabel('Average Order Value (R$)')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Box Plot Comparison\n",
    "    box_data = [sp_data, rj_data]\n",
    "    box_labels = ['São Paulo', 'Rio de Janeiro']\n",
    "    box_plot = ax2.boxplot(box_data, labels=box_labels, patch_artist=True)\n",
    "    colors = ['lightblue', 'lightcoral']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    ax2.set_title('Box Plot: Average Order Value by State')\n",
    "    ax2.set_ylabel('Average Order Value (R$)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Statistical Summary\n",
    "    summary_stats = data.groupby('customer_state')['avg_order_value'].agg([\n",
    "        'count', 'mean', 'std', 'median', \n",
    "        lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)\n",
    "    ]).round(2)\n",
    "    summary_stats.columns = ['Count', 'Mean', 'Std Dev', 'Median', 'Q1', 'Q3']\n",
    "    \n",
    "    ax3.axis('tight')\n",
    "    ax3.axis('off')\n",
    "    table = ax3.table(cellText=summary_stats.values,\n",
    "                     rowLabels=summary_stats.index,\n",
    "                     colLabels=summary_stats.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "    ax3.set_title('Statistical Summary', pad=20)\n",
    "    \n",
    "    # 4. Effect Size Visualization\n",
    "    mean_diff = sp_data.mean() - rj_data.mean()\n",
    "    pooled_std = np.sqrt(((len(sp_data)-1)*sp_data.var() + (len(rj_data)-1)*rj_data.var()) / \n",
    "                        (len(sp_data)+len(rj_data)-2))\n",
    "    cohens_d = mean_diff / pooled_std\n",
    "    \n",
    "    effect_sizes = ['Negligible\\n(0-0.2)', 'Small\\n(0.2-0.5)', 'Medium\\n(0.5-0.8)', 'Large\\n(0.8+)']\n",
    "    effect_thresholds = [0.2, 0.5, 0.8, 1.2]\n",
    "    colors = ['lightgray', 'yellow', 'orange', 'red']\n",
    "    \n",
    "    bars = ax4.bar(effect_sizes, effect_thresholds, color=colors, alpha=0.6)\n",
    "    ax4.axhline(y=abs(cohens_d), color='blue', linestyle='-', linewidth=3, \n",
    "               label=f'Observed Effect Size: {abs(cohens_d):.3f}')\n",
    "    ax4.set_title('Effect Size Context')\n",
    "    ax4.set_ylabel('Cohen\\'s d')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualization\n",
    "if 'regional_data' in locals() and regional_data is not None:\n",
    "    visualize_ttest_results(regional_data)\n",
    "else:\n",
    "    print(\"⚠️ Run the regional analysis first to generate visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chi-Square Tests: Analyzing Categorical Relationships\n",
    "\n",
    "### Business Application: Payment Method and Customer Satisfaction\n",
    "\n",
    "**Business Question**: \"Is there a relationship between payment method and customer satisfaction levels?\"\n",
    "\n",
    "This analysis helps with:\n",
    "- **Payment Strategy**: Which payment methods lead to higher satisfaction\n",
    "- **Customer Experience**: Understanding friction points in payment process\n",
    "- **Business Optimization**: Promoting payment methods that improve satisfaction\n",
    "- **Risk Management**: Identifying payment-related satisfaction issues\n",
    "\n",
    "### Types of Chi-Square Tests:\n",
    "1. **Test of Independence**: Are two categorical variables related?\n",
    "2. **Goodness of Fit**: Does observed distribution match expected distribution?\n",
    "3. **Homogeneity**: Are distributions the same across groups?\n",
    "\n",
    "### When to Use Chi-Square Tests:\n",
    "- **Categorical data** (payment methods, satisfaction levels, product categories)\n",
    "- **Independence assumption** (observations don't influence each other)\n",
    "- **Expected frequencies ≥ 5** in each cell (or use Fisher's exact test)\n",
    "- **Testing relationships** between categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment Method vs Customer Satisfaction Analysis\n",
    "def payment_satisfaction_analysis():\n",
    "    \"\"\"\n",
    "    Analyze relationship between payment methods and customer satisfaction.\n",
    "    \"\"\"\n",
    "    if engine is None:\n",
    "        print(\"❌ Database connection required for payment analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"💳 Payment Method vs Customer Satisfaction Analysis\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Load payment and satisfaction data\n",
    "    payment_satisfaction_query = \"\"\"\n",
    "    SELECT \n",
    "        p.payment_type,\n",
    "        r.review_score,\n",
    "        CASE \n",
    "            WHEN r.review_score >= 4 THEN 'High Satisfaction'\n",
    "            WHEN r.review_score = 3 THEN 'Medium Satisfaction'\n",
    "            WHEN r.review_score <= 2 THEN 'Low Satisfaction'\n",
    "            ELSE 'Unknown'\n",
    "        END as satisfaction_level,\n",
    "        p.payment_value\n",
    "    FROM \"olist_sales_data_set\".\"olist_order_payments_dataset\" p\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_orders_dataset\" o ON p.order_id = o.order_id\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_order_reviews_dataset\" r ON o.order_id = r.order_id\n",
    "    WHERE p.payment_type IN ('credit_card', 'debit_card', 'boleto', 'voucher')\n",
    "        AND r.review_score IS NOT NULL\n",
    "        AND o.order_status = 'delivered'\n",
    "        AND p.payment_value > 0\n",
    "    LIMIT 15000  -- Sample for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        payment_sat_data = pd.read_sql(text(payment_satisfaction_query), engine)\n",
    "        print(f\"✅ Loaded {len(payment_sat_data):,} payment-satisfaction records\")\n",
    "        \n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(payment_sat_data['payment_type'], \n",
    "                                       payment_sat_data['satisfaction_level'])\n",
    "        \n",
    "        print(\"\\n📊 Contingency Table: Payment Method vs Satisfaction Level\")\n",
    "        print(contingency_table)\n",
    "        \n",
    "        # Calculate percentages\n",
    "        percentage_table = pd.crosstab(payment_sat_data['payment_type'], \n",
    "                                     payment_sat_data['satisfaction_level'], \n",
    "                                     normalize='index') * 100\n",
    "        \n",
    "        print(\"\\n📈 Percentage Distribution (by Payment Method):\")\n",
    "        print(percentage_table.round(1))\n",
    "        \n",
    "        # Check assumptions\n",
    "        print(\"\\n🔍 Chi-Square Test Assumptions:\")\n",
    "        min_expected = 5\n",
    "        chi2_stat, p_value, dof, expected_freq = chi2_contingency(contingency_table)\n",
    "        \n",
    "        cells_below_5 = (expected_freq < min_expected).sum()\n",
    "        total_cells = expected_freq.size\n",
    "        print(f\"Expected frequencies below 5: {cells_below_5}/{total_cells}\")\n",
    "        \n",
    "        if cells_below_5 == 0:\n",
    "            print(\"✅ All expected frequencies ≥ 5 - Chi-square test is appropriate\")\n",
    "        elif cells_below_5 <= total_cells * 0.2:\n",
    "            print(\"⚠️ Some expected frequencies < 5, but test is still valid\")\n",
    "        else:\n",
    "            print(\"❌ Too many expected frequencies < 5 - consider Fisher's exact test\")\n",
    "        \n",
    "        # Perform Chi-Square test\n",
    "        print(\"\\n📊 Chi-Square Test Results:\")\n",
    "        print(f\"Chi-square statistic: χ² = {chi2_stat:.4f}\")\n",
    "        print(f\"Degrees of freedom: {dof}\")\n",
    "        print(f\"P-value: {p_value:.6f}\")\n",
    "        \n",
    "        # Critical value\n",
    "        alpha = 0.05\n",
    "        critical_value = stats.chi2.ppf(1 - alpha, dof)\n",
    "        print(f\"Critical value (α = {alpha}): {critical_value:.4f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if p_value < alpha:\n",
    "            print(f\"✅ Statistically significant relationship (p < {alpha})\")\n",
    "            print(\"📈 Payment method and satisfaction level are NOT independent\")\n",
    "        else:\n",
    "            print(f\"❌ No statistically significant relationship (p ≥ {alpha})\")\n",
    "            print(\"📊 Payment method and satisfaction level appear independent\")\n",
    "        \n",
    "        # Effect size (Cramér's V)\n",
    "        n = contingency_table.sum().sum()\n",
    "        cramers_v = np.sqrt(chi2_stat / (n * (min(contingency_table.shape) - 1)))\n",
    "        print(f\"\\nEffect size (Cramér's V): {cramers_v:.4f}\")\n",
    "        \n",
    "        if cramers_v < 0.1:\n",
    "            effect_interpretation = \"Negligible association\"\n",
    "        elif cramers_v < 0.3:\n",
    "            effect_interpretation = \"Small association\"\n",
    "        elif cramers_v < 0.5:\n",
    "            effect_interpretation = \"Medium association\"\n",
    "        else:\n",
    "            effect_interpretation = \"Large association\"\n",
    "        \n",
    "        print(f\"Effect size interpretation: {effect_interpretation}\")\n",
    "        \n",
    "        # Standardized residuals for detailed analysis\n",
    "        print(\"\\n🔍 Standardized Residuals (deviations from independence):\")\n",
    "        residuals = (contingency_table - expected_freq) / np.sqrt(expected_freq)\n",
    "        residuals_df = pd.DataFrame(residuals, \n",
    "                                   index=contingency_table.index, \n",
    "                                   columns=contingency_table.columns)\n",
    "        print(residuals_df.round(2))\n",
    "        \n",
    "        print(\"\\nInterpretation of residuals:\")\n",
    "        print(\"  |residual| > 2: Significant deviation from independence\")\n",
    "        print(\"  |residual| > 3: Highly significant deviation\")\n",
    "        \n",
    "        # Business insights\n",
    "        print(\"\\n💼 Business Insights:\")\n",
    "        \n",
    "        # Find payment method with highest satisfaction\n",
    "        high_satisfaction_rates = percentage_table['High Satisfaction']\n",
    "        best_payment = high_satisfaction_rates.idxmax()\n",
    "        best_rate = high_satisfaction_rates.max()\n",
    "        \n",
    "        worst_payment = high_satisfaction_rates.idxmin()\n",
    "        worst_rate = high_satisfaction_rates.min()\n",
    "        \n",
    "        print(f\"📈 Highest satisfaction rate: {best_payment} ({best_rate:.1f}% high satisfaction)\")\n",
    "        print(f\"📉 Lowest satisfaction rate: {worst_payment} ({worst_rate:.1f}% high satisfaction)\")\n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(f\"💡 Recommendations:\")\n",
    "            print(f\"   • Promote {best_payment} payment method to improve satisfaction\")\n",
    "            print(f\"   • Investigate issues with {worst_payment} payment process\")\n",
    "            print(f\"   • Consider payment-specific customer experience improvements\")\n",
    "        else:\n",
    "            print(f\"💡 Recommendations:\")\n",
    "            print(f\"   • Payment method doesn't significantly affect satisfaction\")\n",
    "            print(f\"   • Focus on other factors that influence customer experience\")\n",
    "        \n",
    "        return payment_sat_data, contingency_table\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in payment satisfaction analysis: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Perform payment satisfaction analysis\n",
    "payment_data, contingency_table = payment_satisfaction_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ANOVA: Comparing Multiple Groups\n",
    "\n",
    "### Business Application: Multi-State Performance Analysis\n",
    "\n",
    "**Business Question**: \"Are there significant differences in customer satisfaction across the top 5 Brazilian states?\"\n",
    "\n",
    "This analysis supports:\n",
    "- **Regional Strategy**: Identify states needing operational improvements\n",
    "- **Resource Allocation**: Direct improvement efforts to underperforming regions\n",
    "- **Market Expansion**: Understand regional performance variations\n",
    "- **Operational Excellence**: Benchmark best-performing regions\n",
    "\n",
    "### ANOVA Fundamentals:\n",
    "- **One-Way ANOVA**: Compare means across multiple groups (states)\n",
    "- **F-statistic**: Ratio of between-group to within-group variance\n",
    "- **Post-hoc tests**: Identify which specific groups differ\n",
    "\n",
    "### When to Use ANOVA:\n",
    "- **Continuous dependent variable** (satisfaction scores, order values)\n",
    "- **Categorical independent variable** with 3+ groups (states, categories)\n",
    "- **Normal distributions** within groups (or large samples)\n",
    "- **Equal variances** across groups (homoscedasticity)\n",
    "- **Independent observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-State Customer Satisfaction ANOVA\n",
    "def multistate_satisfaction_anova():\n",
    "    \"\"\"\n",
    "    Compare customer satisfaction across top Brazilian states using ANOVA.\n",
    "    \"\"\"\n",
    "    if engine is None:\n",
    "        print(\"❌ Database connection required for multi-state analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🗺️ Multi-State Customer Satisfaction Analysis (ANOVA)\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Load satisfaction data by state (top 5 states by order volume)\n",
    "    multistate_query = \"\"\"\n",
    "    WITH top_states AS (\n",
    "        SELECT customer_state, COUNT(*) as order_count\n",
    "        FROM \"olist_sales_data_set\".\"olist_customers_dataset\" c\n",
    "        INNER JOIN \"olist_sales_data_set\".\"olist_orders_dataset\" o ON c.customer_id = o.customer_id\n",
    "        WHERE o.order_status = 'delivered'\n",
    "        GROUP BY customer_state\n",
    "        ORDER BY order_count DESC\n",
    "        LIMIT 5\n",
    "    )\n",
    "    SELECT \n",
    "        c.customer_state,\n",
    "        r.review_score,\n",
    "        o.order_id,\n",
    "        oi.price + oi.freight_value as order_value\n",
    "    FROM \"olist_sales_data_set\".\"olist_customers_dataset\" c\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_orders_dataset\" o ON c.customer_id = o.customer_id\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_order_reviews_dataset\" r ON o.order_id = r.order_id\n",
    "    INNER JOIN \"olist_sales_data_set\".\"olist_order_items_dataset\" oi ON o.order_id = oi.order_id\n",
    "    INNER JOIN top_states ts ON c.customer_state = ts.customer_state\n",
    "    WHERE r.review_score IS NOT NULL\n",
    "        AND o.order_status = 'delivered'\n",
    "        AND oi.price > 0\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        multistate_data = pd.read_sql(text(multistate_query), engine)\n",
    "        print(f\"✅ Loaded {len(multistate_data):,} records from top 5 states\")\n",
    "        \n",
    "        # Group data by state\n",
    "        states = multistate_data['customer_state'].unique()\n",
    "        print(f\"📊 Analyzing states: {', '.join(states)}\")\n",
    "        \n",
    "        # Calculate descriptive statistics by state\n",
    "        state_stats = multistate_data.groupby('customer_state')['review_score'].agg([\n",
    "            'count', 'mean', 'std', 'median', 'min', 'max'\n",
    "        ]).round(3)\n",
    "        \n",
    "        print(\"\\n📈 Descriptive Statistics by State:\")\n",
    "        print(state_stats)\n",
    "        \n",
    "        # Check ANOVA assumptions\n",
    "        print(\"\\n🔍 ANOVA Assumption Checking:\")\n",
    "        \n",
    "        # 1. Normality within groups (sample from each state)\n",
    "        print(\"1. Normality within groups:\")\n",
    "        normality_results = {}\n",
    "        for state in states:\n",
    "            state_scores = multistate_data[multistate_data['customer_state'] == state]['review_score']\n",
    "            if len(state_scores) > 5000:\n",
    "                state_scores = state_scores.sample(5000)  # Sample for large datasets\n",
    "            \n",
    "            _, p_normal = normaltest(state_scores)\n",
    "            normality_results[state] = p_normal\n",
    "            normality_status = \"✅ Normal\" if p_normal > 0.05 else \"❌ Not normal\"\n",
    "            print(f\"   {state}: p = {p_normal:.4f} → {normality_status}\")\n",
    "        \n",
    "        # 2. Equal variances (Levene's test)\n",
    "        print(\"\\n2. Equal variances across groups:\")\n",
    "        state_groups = [multistate_data[multistate_data['customer_state'] == state]['review_score'] \n",
    "                       for state in states]\n",
    "        \n",
    "        _, levene_p = levene(*state_groups)\n",
    "        equal_var_status = \"✅ Equal variances\" if levene_p > 0.05 else \"❌ Unequal variances\"\n",
    "        print(f\"   Levene's test: p = {levene_p:.4f} → {equal_var_status}\")\n",
    "        \n",
    "        # 3. Independence (assumed based on business context)\n",
    "        print(\"\\n3. Independence: ✅ Assumed (customers in different states are independent)\")\n",
    "        \n",
    "        # Perform One-Way ANOVA\n",
    "        print(\"\\n📊 One-Way ANOVA Results:\")\n",
    "        f_stat, p_value = f_oneway(*state_groups)\n",
    "        \n",
    "        print(f\"F-statistic: F = {f_stat:.4f}\")\n",
    "        print(f\"P-value: {p_value:.6f}\")\n",
    "        \n",
    "        # Degrees of freedom\n",
    "        df_between = len(states) - 1\n",
    "        df_within = len(multistate_data) - len(states)\n",
    "        print(f\"Degrees of freedom: between = {df_between}, within = {df_within}\")\n",
    "        \n",
    "        alpha = 0.05\n",
    "        if p_value < alpha:\n",
    "            print(f\"✅ Statistically significant difference between states (p < {alpha})\")\n",
    "            print(\"📈 At least one state differs significantly from others\")\n",
    "        else:\n",
    "            print(f\"❌ No statistically significant difference between states (p ≥ {alpha})\")\n",
    "            print(\"📊 All states have similar customer satisfaction levels\")\n",
    "        \n",
    "        # Effect size (Eta squared)\n",
    "        ss_between = f_stat * df_between\n",
    "        ss_total = ss_between + df_within\n",
    "        eta_squared = ss_between / ss_total\n",
    "        \n",
    "        print(f\"\\nEffect size (η²): {eta_squared:.4f}\")\n",
    "        \n",
    "        if eta_squared < 0.01:\n",
    "            effect_interpretation = \"Small effect\"\n",
    "        elif eta_squared < 0.06:\n",
    "            effect_interpretation = \"Medium effect\"\n",
    "        else:\n",
    "            effect_interpretation = \"Large effect\"\n",
    "        \n",
    "        print(f\"Effect size interpretation: {effect_interpretation}\")\n",
    "        \n",
    "        # Post-hoc analysis if significant\n",
    "        if p_value < alpha:\n",
    "            print(\"\\n🔍 Post-Hoc Analysis (Pairwise Comparisons):\")\n",
    "            \n",
    "            # Pairwise t-tests with Bonferroni correction\n",
    "            from itertools import combinations\n",
    "            \n",
    "            comparisons = list(combinations(states, 2))\n",
    "            n_comparisons = len(comparisons)\n",
    "            bonferroni_alpha = alpha / n_comparisons\n",
    "            \n",
    "            print(f\"Number of comparisons: {n_comparisons}\")\n",
    "            print(f\"Bonferroni-corrected α: {bonferroni_alpha:.4f}\")\n",
    "            \n",
    "            significant_pairs = []\n",
    "            \n",
    "            for state1, state2 in comparisons:\n",
    "                group1 = multistate_data[multistate_data['customer_state'] == state1]['review_score']\n",
    "                group2 = multistate_data[multistate_data['customer_state'] == state2]['review_score']\n",
    "                \n",
    "                t_stat, p_val = ttest_ind(group1, group2, equal_var=(levene_p > 0.05))\n",
    "                \n",
    "                mean_diff = group1.mean() - group2.mean()\n",
    "                significance = \"✅ Significant\" if p_val < bonferroni_alpha else \"❌ Not significant\"\n",
    "                \n",
    "                print(f\"   {state1} vs {state2}: Δ = {mean_diff:+.3f}, p = {p_val:.4f} → {significance}\")\n",
    "                \n",
    "                if p_val < bonferroni_alpha:\n",
    "                    significant_pairs.append((state1, state2, mean_diff))\n",
    "        \n",
    "        # Business recommendations\n",
    "        print(\"\\n💼 Business Insights and Recommendations:\")\n",
    "        \n",
    "        # Find best and worst performing states\n",
    "        best_state = state_stats['mean'].idxmax()\n",
    "        worst_state = state_stats['mean'].idxmin()\n",
    "        best_score = state_stats.loc[best_state, 'mean']\n",
    "        worst_score = state_stats.loc[worst_state, 'mean']\n",
    "        \n",
    "        print(f\"📈 Highest satisfaction: {best_state} (avg: {best_score:.2f})\")\n",
    "        print(f\"📉 Lowest satisfaction: {worst_state} (avg: {worst_score:.2f})\")\n",
    "        print(f\"🔄 Performance gap: {best_score - worst_score:.2f} points\")\n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(f\"\\n💡 Strategic Recommendations:\")\n",
    "            print(f\"   • Benchmark {best_state}'s operations and customer service practices\")\n",
    "            print(f\"   • Investigate satisfaction drivers in {worst_state}\")\n",
    "            print(f\"   • Implement targeted improvement programs in underperforming states\")\n",
    "            print(f\"   • Consider state-specific customer experience initiatives\")\n",
    "        else:\n",
    "            print(f\"\\n💡 Strategic Recommendations:\")\n",
    "            print(f\"   • Satisfaction levels are consistent across states\")\n",
    "            print(f\"   • Focus on system-wide improvements rather than state-specific initiatives\")\n",
    "            print(f\"   • Leverage uniform customer experience strategies\")\n",
    "        \n",
    "        return multistate_data, state_stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in multi-state ANOVA: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Perform multi-state satisfaction ANOVA\n",
    "multistate_data, state_stats = multistate_satisfaction_anova()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Takeaways and Business Applications\n",
    "\n",
    "### What We've Accomplished in Part 2\n",
    "\n",
    "1. **T-Tests**: Compared two groups (SP vs RJ customers) with statistical rigor\n",
    "2. **Chi-Square Tests**: Analyzed categorical relationships (payment methods vs satisfaction)\n",
    "3. **ANOVA**: Compared multiple groups simultaneously (satisfaction across states)\n",
    "4. **Assumption Checking**: Validated test requirements for reliable results\n",
    "5. **Effect Sizes**: Quantified practical significance beyond statistical significance\n",
    "6. **Business Translation**: Converted statistical findings into actionable business insights\n",
    "\n",
    "### Critical Business Insights\n",
    "\n",
    "**🎯 Test Selection Framework**:\n",
    "- **Continuous + 2 Groups** → T-test\n",
    "- **Categorical Relationships** → Chi-square test  \n",
    "- **Continuous + 3+ Groups** → ANOVA\n",
    "- **Always check assumptions** before interpreting results\n",
    "\n",
    "**📊 Beyond P-Values**:\n",
    "- Calculate **effect sizes** to assess practical significance\n",
    "- Use **confidence intervals** to quantify uncertainty\n",
    "- Consider **business context** when interpreting statistical results\n",
    "- **Statistical significance ≠ Business importance**\n",
    "\n",
    "**💼 Business Decision Framework**:\n",
    "1. **Statistical Significance**: Is the difference real (not due to chance)?\n",
    "2. **Practical Significance**: Is the difference large enough to matter?\n",
    "3. **Business Context**: Does the finding justify action/investment?\n",
    "4. **Implementation Feasibility**: Can we act on these insights?\n",
    "\n",
    "### Preparing for Part 3\n",
    "\n",
    "**Next Session Preview**: We'll apply these statistical tests to **real business scenarios**:\n",
    "- Regional performance optimization\n",
    "- Customer satisfaction improvement strategies  \n",
    "- Payment method optimization\n",
    "- Delivery performance validation\n",
    "- Strategic business recommendations based on statistical evidence\n",
    "\n",
    "**Skills Integration**: Combine statistical testing with business strategy to make **data-driven decisions** that impact Olist's marketplace performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Summary and Next Steps\n",
    "def part2_summary():\n",
    "    \"\"\"\n",
    "    Summarize comparative analysis tests and preview Part 3.\n",
    "    \"\"\"\n",
    "    print(\"📋 Week 8 Part 2 Summary: Comparative Analysis Tests\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    tests_mastered = {\n",
    "        \"T-Tests\": {\n",
    "            \"purpose\": \"Compare means between two groups\",\n",
    "            \"example\": \"SP vs RJ customer spending patterns\",\n",
    "            \"key_insight\": \"Independent samples t-test with assumption checking\"\n",
    "        },\n",
    "        \"Chi-Square Tests\": {\n",
    "            \"purpose\": \"Analyze relationships between categorical variables\",\n",
    "            \"example\": \"Payment method vs customer satisfaction\",\n",
    "            \"key_insight\": \"Contingency table analysis with effect size\"\n",
    "        },\n",
    "        \"ANOVA\": {\n",
    "            \"purpose\": \"Compare means across multiple groups\",\n",
    "            \"example\": \"Satisfaction across top 5 Brazilian states\",\n",
    "            \"key_insight\": \"F-test with post-hoc pairwise comparisons\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\n📚 Statistical Tests Mastered:\")\n",
    "    for test_name, details in tests_mastered.items():\n",
    "        print(f\"\\n🔬 {test_name}:\")\n",
    "        print(f\"   Purpose: {details['purpose']}\")\n",
    "        print(f\"   Example: {details['example']}\")\n",
    "        print(f\"   Key Learning: {details['key_insight']}\")\n",
    "    \n",
    "    business_applications = [\n",
    "        \"Regional customer segmentation and targeting\",\n",
    "        \"Payment method optimization strategies\", \n",
    "        \"Multi-state operational improvement priorities\",\n",
    "        \"Evidence-based business decision making\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n💼 Business Applications Unlocked:\")\n",
    "    for i, application in enumerate(business_applications, 1):\n",
    "        print(f\"   {i}. {application}\")\n",
    "    \n",
    "    part3_topics = [\n",
    "        \"Real business scenario analysis with statistical validation\",\n",
    "        \"Integrated approach: EDA → Hypothesis → Testing → Action\", \n",
    "        \"Strategic recommendations based on statistical evidence\",\n",
    "        \"End-to-end business problem solving framework\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n🔜 Part 3 Preview - Practical Business Applications:\")\n",
    "    for i, topic in enumerate(part3_topics, 1):\n",
    "        print(f\"   {i}. {topic}\")\n",
    "    \n",
    "    critical_concepts = [\n",
    "        \"Always check statistical assumptions before testing\",\n",
    "        \"Calculate effect sizes for practical significance\", \n",
    "        \"Use business context to interpret statistical results\",\n",
    "        \"Choose appropriate tests based on data types and research questions\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n💡 Critical Concepts to Remember:\")\n",
    "    for concept in critical_concepts:\n",
    "        print(f\"   • {concept}\")\n",
    "    \n",
    "    print(\"\\n🎯 Ready to apply statistical testing to real business scenarios!\")\n",
    "\n",
    "# Display summary\n",
    "part2_summary()\n",
    "\n",
    "# Clean up database connection\n",
    "if engine:\n",
    "    engine.dispose()\n",
    "    print(\"\\n🔒 Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
