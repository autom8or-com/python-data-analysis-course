{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Reshaping - Part 2: Melt and Pivot Operations\n",
        "\n",
        "## Week 4, Day 1 (Wednesday) - April 30th, 2025\n",
        "\n",
        "### Overview\n",
        "This is the second part of our Data Reshaping session, focusing on transforming data between wide and long formats. Understanding how to reshape data is crucial for data analysis, visualization, and reporting - especially when working with time series data and creating pivot tables.\n",
        "\n",
        "### Learning Objectives\n",
        "- Understand the difference between wide and long format data\n",
        "- Master `pd.melt()` for converting wide to long format\n",
        "- Learn `pd.pivot()` and `pd.pivot_table()` for converting long to wide format\n",
        "- Apply reshaping techniques to e-commerce scenarios\n",
        "- Create summary tables and reports using pivot operations\n",
        "- Handle common reshaping challenges\n",
        "\n",
        "### Prerequisites\n",
        "- Completed Part 1: Merge, Join, and Concatenate\n",
        "- Understanding of Pandas DataFrames\n",
        "- Basic knowledge of SQL GROUP BY operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction to Data Reshaping\n",
        "\n",
        "### Wide vs Long Format Data\n",
        "\n",
        "**Wide Format**: Each variable has its own column\n",
        "- Easy to read by humans\n",
        "- Common in spreadsheets\n",
        "- Good for summary tables\n",
        "\n",
        "**Long Format**: Each observation is a row\n",
        "- Better for analysis and visualization\n",
        "- Required by many statistical functions\n",
        "- More normalized database structure\n",
        "\n",
        "Think of it like the difference between a crosstab table and a detailed transaction log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set display options for better readability\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Creating Sample E-commerce Data\n",
        "\n",
        "Let's create realistic e-commerce datasets to demonstrate reshaping operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monthly sales data - WIDE FORMAT\n",
        "# Each month is a separate column\n",
        "monthly_sales_wide = pd.DataFrame({\n",
        "    'product_id': ['PROD001', 'PROD002', 'PROD003', 'PROD004', 'PROD005'],\n",
        "    'product_name': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Monitor'],\n",
        "    'Jan_2025': [15, 25, 12, 8, 18],\n",
        "    'Feb_2025': [18, 30, 15, 12, 22],\n",
        "    'Mar_2025': [22, 28, 18, 15, 25],\n",
        "    'Apr_2025': [20, 32, 20, 18, 28]\n",
        "})\n",
        "\n",
        "print(\"Monthly Sales Data (WIDE FORMAT):\")\n",
        "print(monthly_sales_wide)\n",
        "print(f\"\\nShape: {monthly_sales_wide.shape}\")\n",
        "print(\"Notice: Each month is a separate column\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daily sales data - LONG FORMAT\n",
        "# Each observation (product-date combination) is a separate row\n",
        "np.random.seed(42)  # For reproducible results\n",
        "dates = pd.date_range('2025-01-01', '2025-01-10', freq='D')\n",
        "products = ['PROD001', 'PROD002', 'PROD003']\n",
        "\n",
        "daily_sales_long = pd.DataFrame([\n",
        "    {'date': date, 'product_id': product, 'sales_qty': np.random.randint(1, 10)}\n",
        "    for date in dates\n",
        "    for product in products\n",
        "])\n",
        "\n",
        "print(\"Daily Sales Data (LONG FORMAT):\")\n",
        "print(daily_sales_long.head(15))\n",
        "print(f\"\\nShape: {daily_sales_long.shape}\")\n",
        "print(\"Notice: Each product-date combination is a separate row\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Melting Data (Wide to Long Format)\n",
        "\n",
        "### What is Melting?\n",
        "`pd.melt()` transforms wide format data to long format by:\n",
        "- Taking column names and making them values in a new column\n",
        "- Moving the corresponding values to another new column\n",
        "- Creating a row for each original column value\n",
        "\n",
        "### Basic Melting Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Melt the monthly sales data from wide to long format\n",
        "monthly_sales_melted = pd.melt(monthly_sales_wide, \n",
        "                              id_vars=['product_id', 'product_name'],  # Columns to keep as identifiers\n",
        "                              value_vars=['Jan_2025', 'Feb_2025', 'Mar_2025', 'Apr_2025'],  # Columns to melt\n",
        "                              var_name='month',  # Name for the new column containing old column names\n",
        "                              value_name='sales_qty')  # Name for the new column containing values\n",
        "\n",
        "print(\"Melted Monthly Sales Data (LONG FORMAT):\")\n",
        "print(monthly_sales_melted.head(12))\n",
        "print(f\"\\nOriginal shape: {monthly_sales_wide.shape}\")\n",
        "print(f\"Melted shape: {monthly_sales_melted.shape}\")\n",
        "print(\"\\nNotice: 5 products Ã— 4 months = 20 rows!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simplified Melting\n",
        "You can also melt without specifying all parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simplified melt - pandas will automatically determine what to melt\n",
        "simple_melt = pd.melt(monthly_sales_wide, \n",
        "                     id_vars=['product_id', 'product_name'])\n",
        "\n",
        "print(\"Simplified Melt (default column names):\")\n",
        "print(simple_melt.head(8))\n",
        "print(\"\\nDefault column names: 'variable' and 'value'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Melting with Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's clean up the melted data for better analysis\n",
        "monthly_sales_clean = monthly_sales_melted.copy()\n",
        "\n",
        "# Convert month column to datetime\n",
        "monthly_sales_clean['month'] = pd.to_datetime(monthly_sales_clean['month'], format='%b_%Y')\n",
        "\n",
        "# Sort by product and month\n",
        "monthly_sales_clean = monthly_sales_clean.sort_values(['product_id', 'month']).reset_index(drop=True)\n",
        "\n",
        "print(\"Cleaned Melted Data:\")\n",
        "print(monthly_sales_clean.head(12))\n",
        "print(f\"\\nMonth column data type: {monthly_sales_clean['month'].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Pivoting Data (Long to Wide Format)\n",
        "\n",
        "### What is Pivoting?\n",
        "`pd.pivot()` transforms long format data to wide format by:\n",
        "- Using unique values from one column as new column headers\n",
        "- Using values from another column to populate the new columns\n",
        "- Creating a summary view of the data\n",
        "\n",
        "### Basic Pivot Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot the daily sales data from long to wide format\n",
        "daily_sales_pivot = daily_sales_long.pivot(index='date', \n",
        "                                          columns='product_id', \n",
        "                                          values='sales_qty')\n",
        "\n",
        "print(\"Daily Sales Data Pivoted (WIDE FORMAT):\")\n",
        "print(daily_sales_pivot)\n",
        "print(f\"\\nOriginal shape: {daily_sales_long.shape}\")\n",
        "print(f\"Pivoted shape: {daily_sales_pivot.shape}\")\n",
        "print(\"\\nNotice: Dates are now rows, products are columns!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Missing Values in Pivots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data with missing combinations\n",
        "sparse_sales = pd.DataFrame({\n",
        "    'date': ['2025-01-01', '2025-01-01', '2025-01-02', '2025-01-03'],\n",
        "    'product_id': ['PROD001', 'PROD002', 'PROD001', 'PROD003'],\n",
        "    'sales_qty': [5, 3, 7, 2]\n",
        "})\n",
        "\n",
        "print(\"Sparse Sales Data (missing combinations):\")\n",
        "print(sparse_sales)\n",
        "\n",
        "# Pivot with missing values\n",
        "sparse_pivot = sparse_sales.pivot(index='date', columns='product_id', values='sales_qty')\n",
        "print(\"\\nPivoted with NaN for missing combinations:\")\n",
        "print(sparse_pivot)\n",
        "\n",
        "# Fill missing values\n",
        "sparse_pivot_filled = sparse_pivot.fillna(0)\n",
        "print(\"\\nPivoted with 0 for missing combinations:\")\n",
        "print(sparse_pivot_filled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Pivot Tables with Aggregation\n",
        "\n",
        "### When to Use pivot_table() vs pivot()\n",
        "- Use `pivot()` when each index-column combination has exactly one value\n",
        "- Use `pivot_table()` when you need aggregation (like SQL GROUP BY)\n",
        "\n",
        "### Creating Comprehensive Sales Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sales data with multiple entries per product-date combination\n",
        "# (Like multiple orders for the same product on the same day)\n",
        "detailed_sales = pd.DataFrame({\n",
        "    'date': ['2025-01-01', '2025-01-01', '2025-01-01', '2025-01-01', '2025-01-02', '2025-01-02'],\n",
        "    'product_id': ['PROD001', 'PROD001', 'PROD002', 'PROD003', 'PROD001', 'PROD002'],\n",
        "    'customer_id': ['CUST001', 'CUST002', 'CUST001', 'CUST003', 'CUST001', 'CUST002'],\n",
        "    'sales_qty': [2, 3, 1, 4, 2, 1],\n",
        "    'sales_amount': [100, 150, 50, 200, 100, 50]\n",
        "})\n",
        "\n",
        "print(\"Detailed Sales Data (multiple entries per product-date):\")\n",
        "print(detailed_sales)\n",
        "\n",
        "# This would fail with regular pivot() due to duplicate index-column combinations\n",
        "# detailed_pivot = detailed_sales.pivot(index='date', columns='product_id', values='sales_qty')\n",
        "# UnionError: Index contains duplicate entries, cannot reshape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using pivot_table() for Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use pivot_table with aggregation function\n",
        "sales_pivot_table = pd.pivot_table(detailed_sales,\n",
        "                                  index='date',\n",
        "                                  columns='product_id',\n",
        "                                  values='sales_qty',\n",
        "                                  aggfunc='sum',  # Aggregate function\n",
        "                                  fill_value=0)   # Fill missing values\n",
        "\n",
        "print(\"Sales Pivot Table (aggregated):\")\n",
        "print(sales_pivot_table)\n",
        "print(\"\\nThis is like: SELECT date, product_id, SUM(sales_qty) FROM sales GROUP BY date, product_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple Aggregation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple aggregation functions\n",
        "multi_agg_pivot = pd.pivot_table(detailed_sales,\n",
        "                                index='date',\n",
        "                                columns='product_id',\n",
        "                                values='sales_qty',\n",
        "                                aggfunc=['sum', 'mean', 'count'],\n",
        "                                fill_value=0)\n",
        "\n",
        "print(\"Multi-Aggregation Pivot Table:\")\n",
        "print(multi_agg_pivot)\n",
        "print(\"\\nNotice the hierarchical column structure!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple Values in Pivot Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pivot table with multiple value columns\n",
        "multi_value_pivot = pd.pivot_table(detailed_sales,\n",
        "                                  index='date',\n",
        "                                  columns='product_id',\n",
        "                                  values=['sales_qty', 'sales_amount'],\n",
        "                                  aggfunc='sum',\n",
        "                                  fill_value=0)\n",
        "\n",
        "print(\"Multi-Value Pivot Table:\")\n",
        "print(multi_value_pivot)\n",
        "print(\"\\nBoth sales_qty and sales_amount are pivoted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Real-World E-commerce Examples\n",
        "\n",
        "### Example 1: Customer Purchase Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create customer purchase data\n",
        "customer_purchases = pd.DataFrame({\n",
        "    'customer_id': ['CUST001', 'CUST001', 'CUST002', 'CUST002', 'CUST003', 'CUST003'],\n",
        "    'category': ['Electronics', 'Books', 'Electronics', 'Clothing', 'Books', 'Electronics'],\n",
        "    'purchase_amount': [299.99, 19.99, 499.99, 79.99, 29.99, 199.99],\n",
        "    'purchase_count': [1, 2, 1, 3, 1, 1]\n",
        "})\n",
        "\n",
        "print(\"Customer Purchase Data:\")\n",
        "print(customer_purchases)\n",
        "\n",
        "# Create customer-category spending matrix\n",
        "customer_category_spending = pd.pivot_table(customer_purchases,\n",
        "                                           index='customer_id',\n",
        "                                           columns='category',\n",
        "                                           values='purchase_amount',\n",
        "                                           aggfunc='sum',\n",
        "                                           fill_value=0)\n",
        "\n",
        "print(\"\\nCustomer-Category Spending Matrix:\")\n",
        "print(customer_category_spending)\n",
        "print(\"\\nThis shows how much each customer spent in each category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Product Performance Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create product performance data\n",
        "product_metrics = pd.DataFrame({\n",
        "    'product_id': ['PROD001', 'PROD002', 'PROD003'] * 4,\n",
        "    'metric': ['revenue', 'orders', 'returns', 'reviews'] * 3,\n",
        "    'value': [15000, 50, 2, 45, 12000, 40, 1, 38, 8000, 25, 3, 22]\n",
        "})\n",
        "\n",
        "print(\"Product Metrics Data (LONG FORMAT):\")\n",
        "print(product_metrics)\n",
        "\n",
        "# Pivot to create a product dashboard\n",
        "product_dashboard = pd.pivot_table(product_metrics,\n",
        "                                  index='product_id',\n",
        "                                  columns='metric',\n",
        "                                  values='value',\n",
        "                                  aggfunc='first')  # Use 'first' since each combination has one value\n",
        "\n",
        "print(\"\\nProduct Performance Dashboard:\")\n",
        "print(product_dashboard)\n",
        "\n",
        "# Add calculated metrics\n",
        "product_dashboard['avg_order_value'] = product_dashboard['revenue'] / product_dashboard['orders']\n",
        "product_dashboard['return_rate'] = product_dashboard['returns'] / product_dashboard['orders'] * 100\n",
        "\n",
        "print(\"\\nDashboard with Calculated Metrics:\")\n",
        "print(product_dashboard.round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Advanced Reshaping Techniques\n",
        "\n",
        "### Melting Multiple Value Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data with multiple value columns\n",
        "quarterly_data = pd.DataFrame({\n",
        "    'product_id': ['PROD001', 'PROD002', 'PROD003'],\n",
        "    'Q1_revenue': [10000, 8000, 6000],\n",
        "    'Q1_orders': [50, 40, 30],\n",
        "    'Q2_revenue': [12000, 9000, 7000],\n",
        "    'Q2_orders': [60, 45, 35]\n",
        "})\n",
        "\n",
        "print(\"Quarterly Data (WIDE FORMAT):\")\n",
        "print(quarterly_data)\n",
        "\n",
        "# Melt to long format\n",
        "quarterly_melted = pd.melt(quarterly_data,\n",
        "                          id_vars=['product_id'],\n",
        "                          var_name='quarter_metric',\n",
        "                          value_name='value')\n",
        "\n",
        "print(\"\\nQuarterly Data Melted:\")\n",
        "print(quarterly_melted)\n",
        "\n",
        "# Split the quarter_metric column to separate quarter and metric\n",
        "quarterly_melted[['quarter', 'metric']] = quarterly_melted['quarter_metric'].str.split('_', expand=True)\n",
        "quarterly_melted = quarterly_melted.drop('quarter_metric', axis=1)\n",
        "\n",
        "print(\"\\nCleaned Quarterly Data:\")\n",
        "print(quarterly_melted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stack and Unstack Operations\n",
        "Alternative methods for reshaping data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using stack() and unstack() as alternatives to melt() and pivot()\n",
        "# Start with our monthly sales data\n",
        "monthly_indexed = monthly_sales_wide.set_index(['product_id', 'product_name'])\n",
        "\n",
        "print(\"Monthly Sales with MultiIndex:\")\n",
        "print(monthly_indexed)\n",
        "\n",
        "# Stack to convert columns to rows (like melt)\n",
        "stacked = monthly_indexed.stack()\n",
        "print(\"\\nStacked (columns to rows):\")\n",
        "print(stacked.head(8))\n",
        "print(f\"Type: {type(stacked)}\")\n",
        "\n",
        "# Unstack to convert rows to columns (like pivot)\n",
        "unstacked = stacked.unstack()\n",
        "print(\"\\nUnstacked (back to original):\")\n",
        "print(unstacked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Handling Complex Reshaping Scenarios\n",
        "\n",
        "### Reshaping with Hierarchical Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data with hierarchical column structure\n",
        "hierarchical_data = pd.DataFrame({\n",
        "    ('Sales', 'Q1'): [100, 120, 90],\n",
        "    ('Sales', 'Q2'): [110, 130, 95],\n",
        "    ('Revenue', 'Q1'): [10000, 12000, 9000],\n",
        "    ('Revenue', 'Q2'): [11000, 13000, 9500]\n",
        "}, index=['PROD001', 'PROD002', 'PROD003'])\n",
        "\n",
        "# Set proper column names\n",
        "hierarchical_data.columns = pd.MultiIndex.from_tuples(hierarchical_data.columns, names=['Metric', 'Quarter'])\n",
        "hierarchical_data.index.name = 'Product'\n",
        "\n",
        "print(\"Hierarchical Column Data:\")\n",
        "print(hierarchical_data)\n",
        "\n",
        "# Stack to reshape\n",
        "hierarchical_stacked = hierarchical_data.stack()\n",
        "print(\"\\nStacked Hierarchical Data:\")\n",
        "print(hierarchical_stacked)\n",
        "\n",
        "# Reset index to get a flat structure\n",
        "flat_hierarchical = hierarchical_stacked.reset_index()\n",
        "print(\"\\nFlat Structure:\")\n",
        "print(flat_hierarchical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. SQL Equivalents and Comparisons\n",
        "\n",
        "### Pivot Table vs SQL GROUP BY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sales data for SQL comparison\n",
        "sales_data = pd.DataFrame({\n",
        "    'region': ['North', 'North', 'South', 'South', 'East', 'East'],\n",
        "    'product': ['Laptop', 'Phone', 'Laptop', 'Phone', 'Laptop', 'Phone'],\n",
        "    'sales': [100, 150, 120, 180, 90, 160]\n",
        "})\n",
        "\n",
        "print(\"Sales Data:\")\n",
        "print(sales_data)\n",
        "\n",
        "# SQL equivalent: SELECT region, product, SUM(sales) FROM sales GROUP BY region, product\n",
        "sql_equivalent = sales_data.groupby(['region', 'product'])['sales'].sum().reset_index()\n",
        "print(\"\\nSQL GROUP BY equivalent:\")\n",
        "print(sql_equivalent)\n",
        "\n",
        "# Pivot table for cross-tabulation\n",
        "# SQL equivalent: Complex CASE WHEN statements\n",
        "pivot_crosstab = pd.pivot_table(sales_data,\n",
        "                               index='region',\n",
        "                               columns='product',\n",
        "                               values='sales',\n",
        "                               aggfunc='sum',\n",
        "                               fill_value=0)\n",
        "\n",
        "print(\"\\nPivot Table (Cross-tabulation):\")\n",
        "print(pivot_crosstab)\n",
        "print(\"\\nThis would require complex CASE WHEN statements in SQL!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Performance Tips and Best Practices\n",
        "\n",
        "### When to Use Each Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance comparison for different reshaping methods\n",
        "import time\n",
        "\n",
        "# Create larger dataset for timing\n",
        "large_data = pd.DataFrame({\n",
        "    'id': list(range(1000)) * 4,\n",
        "    'category': ['A', 'B', 'C', 'D'] * 1000,\n",
        "    'value': np.random.randn(4000)\n",
        "})\n",
        "\n",
        "print(f\"Large dataset shape: {large_data.shape}\")\n",
        "\n",
        "# Time pivot_table\n",
        "start_time = time.time()\n",
        "pivot_result = pd.pivot_table(large_data, index='id', columns='category', values='value', aggfunc='mean')\n",
        "pivot_time = time.time() - start_time\n",
        "\n",
        "# Time groupby + unstack\n",
        "start_time = time.time()\n",
        "groupby_result = large_data.groupby(['id', 'category'])['value'].mean().unstack()\n",
        "groupby_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nPivot table time: {pivot_time:.4f} seconds\")\n",
        "print(f\"GroupBy + unstack time: {groupby_time:.4f} seconds\")\n",
        "\n",
        "# Verify results are the same\n",
        "print(f\"\\nResults are equal: {pivot_result.equals(groupby_result)}\")\n",
        "\n",
        "print(\"\\nPerformance Tips:\")\n",
        "print(\"1. Use groupby + unstack for large datasets\")\n",
        "print(\"2. Use pivot_table for readability and multiple aggregations\")\n",
        "print(\"3. Consider memory usage when reshaping large datasets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Common Issues and Solutions\n",
        "\n",
        "### Issue 1: Duplicate Values in Pivot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data with duplicates\n",
        "duplicate_data = pd.DataFrame({\n",
        "    'date': ['2025-01-01', '2025-01-01', '2025-01-02'],\n",
        "    'product': ['A', 'A', 'B'],  # Duplicate A on same date\n",
        "    'sales': [10, 15, 20]\n",
        "})\n",
        "\n",
        "print(\"Data with duplicates:\")\n",
        "print(duplicate_data)\n",
        "\n",
        "# This will fail with regular pivot()\n",
        "try:\n",
        "    bad_pivot = duplicate_data.pivot(index='date', columns='product', values='sales')\n",
        "except ValueError as e:\n",
        "    print(f\"\\nError with pivot(): {e}\")\n",
        "\n",
        "# Solution: Use pivot_table with aggregation\n",
        "good_pivot = pd.pivot_table(duplicate_data,\n",
        "                           index='date',\n",
        "                           columns='product',\n",
        "                           values='sales',\n",
        "                           aggfunc='sum')  # Aggregate duplicates\n",
        "\n",
        "print(\"\\nSolution with pivot_table:\")\n",
        "print(good_pivot)\n",
        "print(\"Note: The duplicate values for product A on 2025-01-01 were summed (10 + 15 = 25)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 2: Memory Usage with Large Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor memory usage during reshaping\n",
        "def check_memory_usage(df, name):\n",
        "    memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
        "    print(f\"{name}: {memory_mb:.2f} MB\")\n",
        "    return memory_mb\n",
        "\n",
        "# Original data\n",
        "original_memory = check_memory_usage(large_data, \"Original data\")\n",
        "\n",
        "# After pivot\n",
        "pivot_memory = check_memory_usage(pivot_result, \"After pivot\")\n",
        "\n",
        "print(f\"\\nMemory increase: {((pivot_memory - original_memory) / original_memory * 100):.1f}%\")\n",
        "\n",
        "print(\"\\nMemory optimization tips:\")\n",
        "print(\"1. Use categorical data types for repeated strings\")\n",
        "print(\"2. Consider sparse matrices for data with many zeros\")\n",
        "print(\"3. Process data in chunks for very large datasets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Practice Exercises\n",
        "\n",
        "### Exercise 1: Sales Report Reshaping\n",
        "You have quarterly sales data in wide format. Convert it to long format for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise data\n",
        "quarterly_sales = pd.DataFrame({\n",
        "    'salesperson': ['Alice', 'Bob', 'Carol'],\n",
        "    'region': ['North', 'South', 'East'],\n",
        "    'Q1_2025': [50000, 45000, 48000],\n",
        "    'Q2_2025': [55000, 48000, 52000],\n",
        "    'Q3_2025': [52000, 50000, 49000],\n",
        "    'Q4_2025': [58000, 53000, 55000]\n",
        "})\n",
        "\n",
        "print(\"Quarterly Sales Data:\")\n",
        "print(quarterly_sales)\n",
        "\n",
        "# Your task: Convert to long format with columns: salesperson, region, quarter, sales\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 2: Customer Behavior Analysis\n",
        "Create a pivot table showing customer purchase patterns by category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise data\n",
        "customer_transactions = pd.DataFrame({\n",
        "    'customer_id': ['CUST001', 'CUST001', 'CUST002', 'CUST002', 'CUST003', 'CUST003', 'CUST001'],\n",
        "    'category': ['Electronics', 'Books', 'Electronics', 'Clothing', 'Books', 'Electronics', 'Clothing'],\n",
        "    'transaction_amount': [299.99, 19.99, 499.99, 79.99, 29.99, 199.99, 59.99],\n",
        "    'transaction_count': [1, 1, 1, 1, 1, 1, 1]\n",
        "})\n",
        "\n",
        "print(\"Customer Transactions:\")\n",
        "print(customer_transactions)\n",
        "\n",
        "# Your task: Create a pivot table showing:\n",
        "# - Rows: customer_id\n",
        "# - Columns: category\n",
        "# - Values: total transaction_amount per customer per category\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 3: Product Performance Dashboard\n",
        "Transform the following metrics data into a dashboard format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise data\n",
        "product_metrics_long = pd.DataFrame({\n",
        "    'product_id': ['PROD001', 'PROD001', 'PROD001', 'PROD002', 'PROD002', 'PROD002'],\n",
        "    'metric_type': ['sales', 'returns', 'rating', 'sales', 'returns', 'rating'],\n",
        "    'metric_value': [1000, 50, 4.5, 800, 30, 4.2]\n",
        "})\n",
        "\n",
        "print(\"Product Metrics (Long Format):\")\n",
        "print(product_metrics_long)\n",
        "\n",
        "# Your task: Create a dashboard where:\n",
        "# - Rows: product_id\n",
        "# - Columns: metric_type\n",
        "# - Values: metric_value\n",
        "# Then calculate return_rate = returns / sales * 100\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4: Advanced Reshaping Challenge\n",
        "You have monthly data for multiple metrics. Reshape it for time series analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise data\n",
        "monthly_metrics = pd.DataFrame({\n",
        "    'product': ['Laptop', 'Phone', 'Tablet'],\n",
        "    'Jan_sales': [100, 150, 80],\n",
        "    'Jan_revenue': [50000, 45000, 24000],\n",
        "    'Feb_sales': [120, 180, 90],\n",
        "    'Feb_revenue': [60000, 54000, 27000],\n",
        "    'Mar_sales': [110, 160, 85],\n",
        "    'Mar_revenue': [55000, 48000, 25500]\n",
        "})\n",
        "\n",
        "print(\"Monthly Metrics (Wide Format):\")\n",
        "print(monthly_metrics)\n",
        "\n",
        "# Your task: \n",
        "# 1. Melt to long format\n",
        "# 2. Split the month_metric column into separate month and metric columns\n",
        "# 3. Pivot to have months as rows and metrics as columns (grouped by product)\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Excellent work! You've mastered the fundamentals of data reshaping with melt and pivot operations. These skills are essential for:\n",
        "\n",
        "- **Data Analysis**: Converting data to the right format for analysis\n",
        "- **Visualization**: Many plotting libraries require specific data formats\n",
        "- **Reporting**: Creating summary tables and dashboards\n",
        "- **Time Series Analysis**: Preparing data for temporal analysis\n",
        "\n",
        "In the next part of today's session, we'll continue with:\n",
        "- **Part 3: Time series manipulation basics**\n",
        "\n",
        "### Key Takeaways\n",
        "1. **Melt** (`pd.melt()`) converts wide to long format - use for analysis and visualization\n",
        "2. **Pivot** (`pd.pivot()`) converts long to wide format - use for summary tables\n",
        "3. **Pivot Table** (`pd.pivot_table()`) adds aggregation - use when you have duplicate combinations\n",
        "4. **Choose the right tool**:\n",
        "   - `melt()` for analysis-ready long format\n",
        "   - `pivot()` for unique combinations\n",
        "   - `pivot_table()` for aggregation\n",
        "   - `stack()`/`unstack()` for hierarchical data\n",
        "5. **Always handle missing values** and consider memory usage with large datasets"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}