{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Fundamentals I - Part 1: Introduction and DataFrame Creation\n",
    "\n",
    "## Week 2, Day 2 (Thursday) - April 17th, 2025\n",
    "\n",
    "### Overview\n",
    "This is the first part of our introduction to Pandas, focusing on core concepts and DataFrame creation. We'll explore how Pandas relates to SQL and learn how to create and load DataFrames from various sources.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand what Pandas is and why it's essential for data analysis\n",
    "- Compare Pandas DataFrames to SQL tables\n",
    "- Create DataFrames from different data structures\n",
    "- Load data from external files\n",
    "\n",
    "### Prerequisites\n",
    "- Python fundamentals (Week 1)\n",
    "- NumPy basics (Week 2, Day 1)\n",
    "- SQL knowledge (prior to course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pandas\n",
    "\n",
    "### What is Pandas?\n",
    "\n",
    "Pandas is a powerful, open-source Python library for data manipulation and analysis. The name comes from \"panel data,\" a term for multidimensional structured data sets in econometrics.\n",
    "\n",
    "Key features of Pandas include:\n",
    "- Fast, efficient manipulation of large data sets\n",
    "- Tools for reading and writing data between in-memory data structures and different file formats\n",
    "- Smart data alignment and handling of missing data\n",
    "- Reshaping and pivoting of data sets\n",
    "- Label-based slicing, fancy indexing, and subsetting of large data sets\n",
    "- Data aggregation and transformation\n",
    "- High-performance merging and joining of data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check pandas version\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Pandas for Data Analysis?\n",
    "\n",
    "If you're coming from a SQL background, you might wonder why we need Pandas when we already have powerful database systems. Here are some advantages of using Pandas for data analysis:\n",
    "\n",
    "1. **Flexibility**: Pandas works with various data formats, not just databases.\n",
    "2. **Interactivity**: Immediate feedback during exploratory data analysis.\n",
    "3. **Integration**: Works seamlessly with other Python libraries for visualization and modeling.\n",
    "4. **Functionality**: Combines the best of SQL, Excel, and programming in one place.\n",
    "5. **Performance**: Optimized C code under the hood for efficient data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas vs. SQL: Key Similarities and Differences\n",
    "\n",
    "Since you already know SQL, let's compare some SQL operations with their Pandas equivalents:\n",
    "\n",
    "| SQL Operation | Pandas Equivalent |\n",
    "|--------------|-------------------|\n",
    "| `SELECT * FROM table` | `df` |\n",
    "| `SELECT col1, col2 FROM table` | `df[['col1', 'col2']]` |\n",
    "| `SELECT * FROM table WHERE col > value` | `df[df['col'] > value]` |\n",
    "| `SELECT col, COUNT(*) FROM table GROUP BY col` | `df.groupby('col').size()` |\n",
    "| `SELECT * FROM table ORDER BY col` | `df.sort_values('col')` |\n",
    "| `SELECT * FROM table LIMIT 5` | `df.head(5)` |\n",
    "| `SELECT t1.col, t2.col FROM t1 JOIN t2 ON t1.id = t2.id` | `pd.merge(df1, df2, on='id')` |\n",
    "\n",
    "We'll explore these operations in more detail throughout the course, but this gives you a preview of how your SQL knowledge will transfer to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Series Objects\n",
    "\n",
    "Before diving into DataFrames, let's understand the Series object, which is a one-dimensional labeled array in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple Series\n",
    "s = pd.Series([1, 3, 5, 7, 9])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with custom index\n",
    "s = pd.Series([1, 3, 5, 7, 9], index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series from a dictionary\n",
    "population = {\n",
    "    'New York': 8.4,\n",
    "    'Los Angeles': 3.9,\n",
    "    'Chicago': 2.7,\n",
    "    'Houston': 2.3,\n",
    "    'Phoenix': 1.6\n",
    "}\n",
    "\n",
    "city_pop = pd.Series(population)\n",
    "print(city_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series operations\n",
    "print(\"Values above 3 million:\")\n",
    "print(city_pop[city_pop > 3])\n",
    "\n",
    "print(\"\\nMultiply all populations by 1 million:\")\n",
    "print(city_pop * 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key characteristics of Series:\n",
    "- Similar to a 1D NumPy array or a Python dictionary\n",
    "- Has an index (like row labels in a database table)\n",
    "- Supports vectorized operations\n",
    "- Can handle missing data\n",
    "- Can be thought of as a single column in a SQL table or a single column in a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DataFrame Objects\n",
    "\n",
    "A DataFrame is a 2D labeled data structure with columns of potentially different types. You can think of it as a spreadsheet or SQL table. It's the most commonly used Pandas object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple DataFrame from a dictionary of Series\n",
    "data = {\n",
    "    'population': pd.Series([8.4, 3.9, 2.7, 2.3, 1.6], index=['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']),\n",
    "    'area': pd.Series([468.9, 502.7, 227.3, 637.5, 517.9], index=['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']),\n",
    "    'state': pd.Series(['NY', 'CA', 'IL', 'TX', 'AZ'], index=['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'])\n",
    "}\n",
    "\n",
    "cities_df = pd.DataFrame(data)\n",
    "print(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate population density (population per square mile)\n",
    "cities_df['density'] = cities_df['population'] / cities_df['area'] * 1000  # Converting to thousands per square mile\n",
    "print(cities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key characteristics of DataFrames:\n",
    "- Similar to a SQL table or an Excel spreadsheet\n",
    "- Has row labels (index) and column labels\n",
    "- Can contain columns of different data types\n",
    "- Supports SQL-like operations such as filtering, grouping, and joining\n",
    "- Provides powerful data manipulation capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating DataFrames from Python Objects\n",
    "\n",
    "Let's explore different ways to create DataFrames from Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a dictionary of lists or arrays\n",
    "data = {\n",
    "    'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "    'product_name': ['Laptop', 'Smartphone', 'Tablet', 'Headphones', 'Monitor'],\n",
    "    'category': ['Electronics', 'Electronics', 'Electronics', 'Accessories', 'Electronics'],\n",
    "    'price': [1200, 800, 450, 150, 300],\n",
    "    'in_stock': [True, True, False, True, True]\n",
    "}\n",
    "\n",
    "products_df = pd.DataFrame(data)\n",
    "print(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list of dictionaries (each dict = one row)\n",
    "data = [\n",
    "    {'order_id': 'O001', 'customer_id': 'C001', 'amount': 1250, 'date': '2025-01-05'},\n",
    "    {'order_id': 'O002', 'customer_id': 'C002', 'amount': 800, 'date': '2025-01-06'},\n",
    "    {'order_id': 'O003', 'customer_id': 'C001', 'amount': 150, 'date': '2025-01-09'},\n",
    "    {'order_id': 'O004', 'customer_id': 'C003', 'amount': 450, 'date': '2025-01-10'},\n",
    "    {'order_id': 'O005', 'customer_id': 'C002', 'amount': 300, 'date': '2025-01-15'}\n",
    "]\n",
    "\n",
    "orders_df = pd.DataFrame(data)\n",
    "print(orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a NumPy array\n",
    "data = np.random.randint(0, 100, size=(5, 3))\n",
    "columns = ['A', 'B', 'C']\n",
    "index = ['Row1', 'Row2', 'Row3', 'Row4', 'Row5']\n",
    "\n",
    "df_from_array = pd.DataFrame(data, index=index, columns=columns)\n",
    "print(df_from_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reading Data from External Files\n",
    "\n",
    "In real-world data analysis, you'll often read data from files rather than creating DataFrames manually. Pandas provides functions to read data from various file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from CSV files\n",
    "# Note: Adjust the file path if needed\n",
    "df_csv = pd.read_csv('../Data/numeric_data.csv')\n",
    "print(df_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV with options\n",
    "df_csv_options = pd.read_csv('../Data/numeric_data.csv', \n",
    "                            index_col='id',  # Use 'id' column as index\n",
    "                            parse_dates=['date'],  # Parse date column as datetime\n",
    "                            nrows=3)  # Read only first 3 rows\n",
    "print(df_csv_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other File Formats\n",
    "\n",
    "Pandas can read data from many other file formats, including:\n",
    "\n",
    "- Excel files: `pd.read_excel('file.xlsx')`\n",
    "- JSON: `pd.read_json('file.json')`\n",
    "- SQL databases: \n",
    "  ```python\n",
    "  from sqlalchemy import create_engine\n",
    "  engine = create_engine('sqlite:///database.db')\n",
    "  df = pd.read_sql('SELECT * FROM table', engine)\n",
    "  ```\n",
    "- HTML tables: `pd.read_html('http://example.com/table.html')`\n",
    "- Stata, SAS, and SPSS files: `pd.read_stata()`, `pd.read_sas()`, etc.\n",
    "- Parquet and other columnar formats: `pd.read_parquet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from SQL databases\n",
    "\n",
    "Since you already know SQL, this might be particularly interesting. Here's an example of how you might read data from a SQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This code is for demonstration only; we're not connecting to a real database in this notebook\n",
    "'''\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create a connection to the database\n",
    "# Replace with your actual database connection string\n",
    "engine = create_engine('sqlite:///olist.db')  \n",
    "\n",
    "# Read data using a SQL query\n",
    "query = \"\"\"\n",
    "SELECT o.order_id, c.customer_id, o.order_status, o.order_purchase_timestamp\n",
    "FROM olist_orders_dataset o\n",
    "JOIN olist_customers_dataset c ON o.customer_id = c.customer_id\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df_sql = pd.read_sql(query, engine)\n",
    "print(df_sql)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practice Exercises\n",
    "\n",
    "Now let's practice creating and manipulating DataFrames with some exercises.\n",
    "\n",
    "### Exercise 1: Create a DataFrame from a dictionary\n",
    "\n",
    "Create a DataFrame that represents customer data for an e-commerce website with the following columns:\n",
    "- customer_id\n",
    "- name\n",
    "- email\n",
    "- signup_date\n",
    "- is_premium\n",
    "\n",
    "Include at least 5 customers in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Read and explore sample data\n",
    "\n",
    "Read the sample CSV file we used earlier and answer the following questions:\n",
    "1. How many rows and columns are in the dataset?\n",
    "2. What are the column names?\n",
    "3. What is the average value of 'value1'?\n",
    "4. How many records belong to each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: SQL to Pandas translation\n",
    "\n",
    "Translate the following SQL query into Pandas code using the products_df DataFrame we created earlier:\n",
    "\n",
    "```sql\n",
    "SELECT product_name, price\n",
    "FROM products\n",
    "WHERE category = 'Electronics' AND price > 500\n",
    "ORDER BY price DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next part, we'll dive deeper into basic DataFrame operations, including data inspection, column and row operations, and handling missing data.\n",
    "\n",
    "Continue to [Part 2: Basic DataFrame Operations](02_Pandas_Fundamentals_I_part2.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}