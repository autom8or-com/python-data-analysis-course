{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header-section"
      },
      "source": [
        "# NumPy Fundamentals - Part 4a\n",
        "\n",
        "## Week 2, Day 1 (Wednesday) - April 16th, 2025\n",
        "\n",
        "### Overview\n",
        "This is a continuation of Part 4, focusing on practical applications of NumPy for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import-numpy-again"
      },
      "outputs": [],
      "source": [
        "# Import NumPy\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "practical-applications"
      },
      "source": [
        "## 2. Practical Applications\n",
        "\n",
        "Let's explore some practical applications of NumPy for data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "image-processing"
      },
      "source": [
        "### 2.1 Image Processing\n",
        "\n",
        "In image processing, images are represented as multi-dimensional arrays. Let's create a simple example of image manipulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "image-processing-code"
      },
      "outputs": [],
      "source": [
        "# Create a simple 5x5 grayscale image (values 0-255)\n",
        "image = np.array([\n",
        "    [50, 50, 50, 50, 50],\n",
        "    [50, 100, 100, 100, 50],\n",
        "    [50, 100, 200, 100, 50],\n",
        "    [50, 100, 100, 100, 50],\n",
        "    [50, 50, 50, 50, 50]\n",
        "])\n",
        "\n",
        "print(\"Original image:\")\n",
        "print(image)\n",
        "\n",
        "# Increase brightness (add 50 to each pixel)\n",
        "brighter = image + 50\n",
        "# Ensure values stay in the valid range (0-255)\n",
        "brighter = np.clip(brighter, 0, 255)\n",
        "\n",
        "print(\"\nBrighter image:\")\n",
        "print(brighter)\n",
        "\n",
        "# Invert the image (255 - pixel value)\n",
        "inverted = 255 - image\n",
        "print(\"\nInverted image:\")\n",
        "print(inverted)\n",
        "\n",
        "# Apply a simple blur using a 3x3 mean filter\n",
        "def apply_mean_filter(image):\n",
        "    # Create output image with same shape\n",
        "    result = np.zeros_like(image)\n",
        "    rows, cols = image.shape\n",
        "    \n",
        "    # For each pixel (excluding borders)\n",
        "    for i in range(1, rows-1):\n",
        "        for j in range(1, cols-1):\n",
        "            # 3x3 neighborhood\n",
        "            neighborhood = image[i-1:i+2, j-1:j+2]\n",
        "            # Mean value\n",
        "            result[i, j] = np.mean(neighborhood)\n",
        "    \n",
        "    return result\n",
        "\n",
        "blurred = apply_mean_filter(image)\n",
        "print(\"\nBlurred image:\")\n",
        "print(blurred.astype(int))  # Convert to int for cleaner display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vectorized-image-processing"
      },
      "source": [
        "### Vectorized Image Processing\n",
        "\n",
        "We can make our image processing functions more efficient using vectorization. Let's implement a vectorized version of our blur filter using NumPy's built-in functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vectorized-image-code"
      },
      "outputs": [],
      "source": [
        "# Create a larger test image (20x20) with a simple pattern\n",
        "large_image = np.zeros((20, 20))\n",
        "large_image[5:15, 5:15] = 200  # Create a white square in the middle\n",
        "large_image[8:12, 8:12] = 50   # Create a gray square inside\n",
        "\n",
        "# Add some random noise\n",
        "np.random.seed(42)\n",
        "noise = np.random.normal(0, 20, large_image.shape)\n",
        "noisy_image = np.clip(large_image + noise, 0, 255)\n",
        "\n",
        "# Define a vectorized version of the mean filter using NumPy's 2D convolution\n",
        "def mean_filter_vectorized(image, kernel_size=3):\n",
        "    # Create output image\n",
        "    result = np.zeros_like(image)\n",
        "    \n",
        "    # Calculate padding size\n",
        "    pad = kernel_size // 2\n",
        "    \n",
        "    # Pad the image\n",
        "    padded_image = np.pad(image, pad, mode='constant')\n",
        "    \n",
        "    # Vectorized implementation using sliding window\n",
        "    rows, cols = image.shape\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            # Extract the neighborhood using slicing (vectorized operation)\n",
        "            neighborhood = padded_image[i:i+kernel_size, j:j+kernel_size]\n",
        "            # Calculate mean (vectorized operation)\n",
        "            result[i, j] = np.mean(neighborhood)\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Apply the filter to the noisy image\n",
        "filtered_image = mean_filter_vectorized(noisy_image)\n",
        "\n",
        "# Print a small section of the images to see the effect\n",
        "section = (slice(8, 13), slice(8, 13))  # 5x5 section in the middle\n",
        "print(\"Original image section:\")\n",
        "print(large_image[section].astype(int))\n",
        "print(\"\\nNoisy image section:\")\n",
        "print(noisy_image[section].astype(int))\n",
        "print(\"\\nFiltered image section:\")\n",
        "print(filtered_image[section].astype(int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced-image-processing"
      },
      "source": [
        "### More Advanced Image Operations\n",
        "\n",
        "NumPy can be used for more advanced image processing techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "advanced-image-code"
      },
      "outputs": [],
      "source": [
        "# Edge detection using a Sobel filter\n",
        "def sobel_edge_detection(image):\n",
        "    # Sobel operators for x and y directions\n",
        "    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "    \n",
        "    # Result images\n",
        "    edges_x = np.zeros_like(image)\n",
        "    edges_y = np.zeros_like(image)\n",
        "    \n",
        "    # Pad the image\n",
        "    padded_image = np.pad(image, 1, mode='constant')\n",
        "    \n",
        "    # Apply Sobel operators\n",
        "    rows, cols = image.shape\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            # Extract 3x3 neighborhood\n",
        "            neighborhood = padded_image[i:i+3, j:j+3]\n",
        "            # Apply convolution\n",
        "            edges_x[i, j] = np.sum(neighborhood * sobel_x)\n",
        "            edges_y[i, j] = np.sum(neighborhood * sobel_y)\n",
        "    \n",
        "    # Calculate magnitude of the gradient\n",
        "    edges_magnitude = np.sqrt(edges_x**2 + edges_y**2)\n",
        "    \n",
        "    # Normalize to 0-255 range\n",
        "    edges_magnitude = edges_magnitude / np.max(edges_magnitude) * 255\n",
        "    \n",
        "    return edges_magnitude\n",
        "\n",
        "# Apply edge detection to our image\n",
        "edges = sobel_edge_detection(large_image)\n",
        "\n",
        "# Print a small section of the edge-detected image\n",
        "print(\"Edge detection result (section):\")\n",
        "print(edges[section].astype(int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "financial-data"
      },
      "source": [
        "### 2.2 Financial Data Analysis\n",
        "\n",
        "NumPy is widely used in financial data analysis. Let's create a simple example of stock price analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "financial-data-code"
      },
      "outputs": [],
      "source": [
        "# Generate random stock prices for 5 days\n",
        "np.random.seed(42)  # For reproducibility\n",
        "days = 252  # Trading days in a year\n",
        "stocks = 5   # Number of stocks\n",
        "\n",
        "# Starting prices\n",
        "start_prices = np.array([100, 200, 50, 75, 300])\n",
        "\n",
        "# Daily returns (% change) - normal distribution with mean 0.0005 (0.05%) and std 0.01 (1%)\n",
        "daily_returns = np.random.normal(0.0005, 0.01, (days, stocks))\n",
        "\n",
        "# Calculate price series\n",
        "# Each day's price = previous day's price * (1 + daily return)\n",
        "price_series = np.zeros((days, stocks))\n",
        "price_series[0] = start_prices\n",
        "\n",
        "for day in range(1, days):\n",
        "    price_series[day] = price_series[day-1] * (1 + daily_returns[day])\n",
        "\n",
        "# Print first 5 days of prices\n",
        "print(\"First 5 days of stock prices:\")\n",
        "print(price_series[:5])\n",
        "\n",
        "# Calculate summary statistics\n",
        "final_prices = price_series[-1]\n",
        "overall_returns = (final_prices - start_prices) / start_prices * 100\n",
        "\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(f\"Starting prices: {start_prices}\")\n",
        "print(f\"Final prices: {final_prices}\")\n",
        "print(f\"Overall returns (%): {overall_returns}\")\n",
        "\n",
        "# Calculate daily returns from prices\n",
        "calculated_returns = np.diff(price_series, axis=0) / price_series[:-1] * 100\n",
        "\n",
        "# Calculate volatility (standard deviation of returns)\n",
        "volatility = np.std(calculated_returns, axis=0)\n",
        "print(f\"\\nVolatility (std of daily returns %): {volatility}\")\n",
        "\n",
        "# Find the best and worst performing stock\n",
        "best_stock = np.argmax(overall_returns)\n",
        "worst_stock = np.argmin(overall_returns)\n",
        "\n",
        "print(f\"\\nBest performing stock: Stock {best_stock+1} with {overall_returns[best_stock]:.2f}% return\")\n",
        "print(f\"Worst performing stock: Stock {worst_stock+1} with {overall_returns[worst_stock]:.2f}% return\")\n",
        "\n",
        "# Calculate correlation matrix between stocks\n",
        "correlation_matrix = np.corrcoef(calculated_returns.T)\n",
        "print(\"\\nCorrelation matrix between stocks:\")\n",
        "print(correlation_matrix)"
      ]
    }
  ]
}
